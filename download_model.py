#!/usr/bin/env python3
"""
Whisper ëª¨ë¸ ë‹¤ìš´ë¡œë“œ ìŠ¤í¬ë¦½íŠ¸
Hugging Faceì—ì„œ openai/whisper-large-v3-turbo ëª¨ë¸ì„ ë¡œì»¬ì— ë‹¤ìš´ë¡œë“œí•©ë‹ˆë‹¤.
"""

import os
import sys
from pathlib import Path
from huggingface_hub import snapshot_download
from transformers import AutoProcessor, AutoModelForSpeechSeq2Seq

def download_model(model_id: str, cache_dir: str) -> None:
    """
    ëª¨ë¸ì„ ë‹¤ìš´ë¡œë“œí•©ë‹ˆë‹¤.
    
    Args:
        model_id: Hugging Face ëª¨ë¸ ID
        cache_dir: ëª¨ë¸ì„ ì €ì¥í•  ë””ë ‰í† ë¦¬
    """
    print(f"ğŸ“¥ ëª¨ë¸ ë‹¤ìš´ë¡œë“œë¥¼ ì‹œì‘í•©ë‹ˆë‹¤: {model_id}")
    print(f"ğŸ’¾ ì €ì¥ ê²½ë¡œ: {cache_dir}")
    
    # ìºì‹œ ë””ë ‰í† ë¦¬ ìƒì„±
    os.makedirs(cache_dir, exist_ok=True)
    
    try:
        # ëª¨ë¸ ë‹¤ìš´ë¡œë“œ
        print("\n1ï¸âƒ£  ëª¨ë¸ íŒŒì¼ ë‹¤ìš´ë¡œë“œ ì¤‘...")
        model_path = snapshot_download(
            repo_id=model_id,
            cache_dir=cache_dir,
            resume_download=True,
            local_dir=os.path.join(cache_dir, model_id.replace("/", "_"))
        )
        print(f"âœ… ëª¨ë¸ íŒŒì¼ ë‹¤ìš´ë¡œë“œ ì™„ë£Œ: {model_path}")
        
        # Processor ë‹¤ìš´ë¡œë“œ
        print("\n2ï¸âƒ£  Processor ë‹¤ìš´ë¡œë“œ ì¤‘...")
        processor = AutoProcessor.from_pretrained(model_id)
        processor.save_pretrained(model_path)
        print(f"âœ… Processor ì €ì¥ ì™„ë£Œ")
        
        print("\nâœ¨ ëª¨ë“  ë‹¤ìš´ë¡œë“œê°€ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!")
        print(f"\nì‚¬ìš© ë°©ë²•:")
        print(f"  from transformers import AutoProcessor, AutoModelForSpeechSeq2Seq")
        print(f"  processor = AutoProcessor.from_pretrained('{model_path}')")
        print(f"  model = AutoModelForSpeechSeq2Seq.from_pretrained('{model_path}')")
        
    except Exception as e:
        print(f"âŒ ì˜¤ë¥˜ ë°œìƒ: {e}")
        sys.exit(1)

if __name__ == "__main__":
    model_id = "openai/whisper-large-v3-turbo"
    cache_dir = Path(__file__).parent / "models"
    
    download_model(str(model_id), str(cache_dir))
