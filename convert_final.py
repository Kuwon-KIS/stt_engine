#!/usr/bin/env python3
"""
ê°„ë‹¨í•œ ëª¨ë¸ ë³€í™˜: openai-whisperë¡œ ë¡œë“œ í›„ CTranslate2 ë³€í™˜
"""

import sys
import json
import torch
from pathlib import Path

print("=" * 80)
print("ğŸš€ ëª¨ë¸ ë³€í™˜: OpenAI Whisper â†’ CTranslate2")
print("=" * 80)
print()

try:
    import whisper
    from transformers import AutoConfig
    import ctranslate2
    
    print(f"âœ… OpenAI Whisper: {whisper.__version__}")
    print(f"âœ… CTranslate2: {ctranslate2.__version__}")
    print(f"âœ… PyTorch: {torch.__version__}")
    print()
    
except ImportError as e:
    print(f"âŒ íŒ¨í‚¤ì§€ ë¶€ì¡±: {e}")
    sys.exit(1)

model_path = Path(__file__).parent / "models" / "openai_whisper-large-v3-turbo"
model_safetensors = model_path / "model.safetensors"

print(f"ğŸ“‚ ëª¨ë¸ ê²½ë¡œ: {model_path}")
print()

if not model_safetensors.exists():
    print(f"âŒ model.safetensors ì—†ìŒ: {model_safetensors}")
    sys.exit(1)

size_gb = model_safetensors.stat().st_size / (1024 ** 3)
print(f"âœ… ëª¨ë¸ íŒŒì¼ í™•ì¸: {model_safetensors.name} ({size_gb:.2f}GB)")
print()

# Step 1: ëª¨ë¸ì„ PyTorchë¡œ ë¡œë“œ
print("1ï¸âƒ£  ëª¨ë¸ ë¡œë“œ ì¤‘...")
print("-" * 80)

try:
    from transformers import AutoModelForSpeechSeq2Seq, AutoProcessor, pipeline
    
    # ëª¨ë¸ ë¡œë“œ
    model = AutoModelForSpeechSeq2Seq.from_pretrained(
        str(model_path),
        local_files_only=True,
        trust_remote_code=True
    )
    print("âœ… PyTorch ëª¨ë¸ ë¡œë“œ ì™„ë£Œ")
    
    # state_dict ì €ì¥ (ì„ì‹œ)
    temp_model_pt = model_path / "model.pt"
    torch.save(model.state_dict(), temp_model_pt)
    print(f"âœ… ì„ì‹œ PyTorch ëª¨ë¸ ì €ì¥: {temp_model_pt.name}")
    
except Exception as e:
    print(f"âŒ ë¡œë“œ ì‹¤íŒ¨: {e}")
    sys.exit(1)

print()

# Step 2: CTranslate2 ëª¨ë¸ë¡œ ë³€í™˜
print("2ï¸âƒ£  CTranslate2ë¡œ ë³€í™˜ ì¤‘...")
print("-" * 80)
print("   (ì´ ê³¼ì •ì€ 2-5ë¶„ ì†Œìš”ë©ë‹ˆë‹¤)")
print()

try:
    # ë³€í™˜ ë©”ì»¤ë‹ˆì¦˜
    from ctranslate2.converters import TransformersConverter
    
    # Config íŒŒì¼ ì½ê¸°
    with open(model_path / "config.json") as f:
        config = json.load(f)
    
    print(f"   ëª¨ë¸ íƒ€ì…: {config.get('model_type', 'unknown')}")
    print(f"   ë³€í™˜ ì‹œì‘...")
    
    # CTranslate2 ë³€í™˜ ì‹œë„ (ì—¬ëŸ¬ ë°©ì‹)
    try:
        # ë°©ì‹ 1: ê¸°ë³¸ ë³€í™˜
        converter = TransformersConverter(str(model_path))
        converter.convert(str(model_path), force=True)
        print("   âœ… ë³€í™˜ ì™„ë£Œ (ë°©ì‹1)")
        
    except TypeError as te:
        # ë°©ì‹ 2: í˜¸í™˜ì„± íŒŒë¼ë¯¸í„° ì œê±°
        print(f"   ë°©ì‹1 ì‹¤íŒ¨, ëŒ€ì²´ ë°©ì‹ ì‹œë„...")
        
        # ìˆ˜ë™ ë³€í™˜: safetensorsë¥¼ PyTorch ë°”ì´ë„ˆë¦¬ë¡œ ë³€í™˜
        from safetensors.torch import load_file
        
        state_dict = load_file(str(model_safetensors))
        model_pt_file = model_path / "pytorch_model.bin"
        torch.save(state_dict, model_pt_file)
        print(f"   â€¢ safetensors â†’ pytorch ë³€í™˜: {model_pt_file.name}")
        
        # ì´ì œ PyTorch ëª¨ë¸ë¡œ ë³€í™˜
        converter = TransformersConverter(str(model_path))
        converter.convert(str(model_path), force=True)
        print("   âœ… ë³€í™˜ ì™„ë£Œ (ë°©ì‹2)")

except Exception as e:
    print(f"âŒ ë³€í™˜ ì‹¤íŒ¨: {e}")
    print()
    print("   í˜„ì¬ ìƒíƒœ íŒŒì¼:")
    for f in sorted(model_path.glob("*")):
        if f.is_file() and f.suffix in [".bin", ".pt", ".safetensors"]:
            size = f.stat().st_size / (1024**3)
            print(f"   - {f.name}: {size:.2f}GB")
    sys.exit(1)

print()

# Step 3: ì •ë¦¬ ë° í™•ì¸
print("3ï¸âƒ£  ìµœì¢… í™•ì¸...")
print("-" * 80)

# ì„ì‹œ íŒŒì¼ ì •ë¦¬
for temp_file in [model_path / "model.pt", model_path / "pytorch_model.bin"]:
    if temp_file.exists():
        temp_file.unlink()
        print(f"   â€¢ ì„ì‹œ íŒŒì¼ ì‚­ì œ: {temp_file.name}")

print()
print("   ğŸ“ ìµœì¢… íŒŒì¼ ëª©ë¡:")
for f in sorted(model_path.glob("*")):
    if f.is_file():
        size = f.stat().st_size
        if size > 1024 ** 3:
            size_str = f"{size / (1024**3):.2f}GB"
        elif size > 1024 ** 2:
            size_str = f"{size / (1024**2):.1f}MB"
        else:
            size_str = f"{size / 1024:.1f}KB"
        
        status = "âœ…" if f.name in ["model.bin", "model.safetensors"] else "  "
        print(f"   {status} {f.name:40s} {size_str:>10s}")

print()
model_bin = model_path / "model.bin"
if model_bin.exists():
    print("=" * 80)
    print("âœ… ëª¨ë¸ ë³€í™˜ ì„±ê³µ!")
    print("=" * 80)
else:
    print("=" * 80)
    print("âš ï¸  model.bin ìƒì„± í™•ì¸ í•„ìš”")
    print("=" * 80)

print()
print("ğŸ“ ë‹¤ìŒ ë‹¨ê³„:")
print("   scp models/openai_whisper-large-v3-turbo/model.bin user@server:/path/models/")
print()
