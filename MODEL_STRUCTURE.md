# Whisper ëª¨ë¸ í´ë” êµ¬ì¡° ë° GPU ì„œë²„ ì´ê´€ ê°€ì´ë“œ

## ğŸ“‚ ë‘ í´ë”ì˜ ì—­í• 

### 1ï¸âƒ£ `models--openai--whisper-large-v3-turbo` í´ë”
**ìš©ë„**: Hugging Face ìºì‹œ ë©”íƒ€ë°ì´í„°  
**í¬ê¸°**: ~100KB (ê±°ì˜ ë¹„ì–´ìˆìŒ)  
**íŒŒì¼**: 1ê°œ (`refs/main`)  

```
models--openai--whisper-large-v3-turbo/
â””â”€â”€ refs/
    â””â”€â”€ main  (ëª¨ë¸ ë²„ì „ ì •ë³´)
```

**ì„¤ëª…**:
- Hugging Face Hubì˜ **ìºì‹œ ì‹œìŠ¤í…œ**ì´ ìƒì„±
- ë‹¤ìš´ë¡œë“œí•œ ëª¨ë¸ì˜ **ë²„ì „ ì •ë³´, ë©”íƒ€ë°ì´í„°** ì €ì¥
- ëª¨ë¸ ì—…ë°ì´íŠ¸ í™•ì¸ ë“±ì— ì‚¬ìš©
- **ì‚­ì œí•´ë„ ê´œì°®ìŒ** (ë‹¤ì‹œ ë‹¤ìš´ë¡œë“œ ì‹œ ìë™ ìƒì„±)

---

### 2ï¸âƒ£ `openai_whisper-large-v3-turbo` í´ë” â­ (ì¤‘ìš”!)
**ìš©ë„**: ì‹¤ì œ Whisper ëª¨ë¸ íŒŒì¼  
**í¬ê¸°**: **~1.5GB**  
**íŒŒì¼**: 41ê°œ (ëª¨ë¸ ê°€ì¤‘ì¹˜, ì„¤ì •, í† í¬ë‚˜ì´ì € ë“±)  

```
openai_whisper-large-v3-turbo/
â”œâ”€â”€ model.safetensors           # ëª¨ë¸ ê°€ì¤‘ì¹˜ (1.5GB)
â”œâ”€â”€ config.json                 # ëª¨ë¸ ì„¤ì •
â”œâ”€â”€ preprocessor_config.json    # ìŒì„± ì „ì²˜ë¦¬ ì„¤ì •
â”œâ”€â”€ tokenizer.json              # í† í¬ë‚˜ì´ì €
â”œâ”€â”€ tokenizer_config.json       # í† í¬ë‚˜ì´ì € ì„¤ì •
â”œâ”€â”€ vocab.json                  # ì–´íœ˜ì§‘
â”œâ”€â”€ merges.txt                  # BPE ë¨¸ì§€ ê·œì¹™
â”œâ”€â”€ generation_config.json      # ìƒì„± ì„¤ì •
â”œâ”€â”€ special_tokens_map.json     # íŠ¹ìˆ˜ í† í°
â”œâ”€â”€ added_tokens.json           # ì¶”ê°€ í† í°
â”œâ”€â”€ normalizer.json             # ìŒì„± ì •ê·œí™”
â”œâ”€â”€ .gitattributes              # Git ì†ì„±
â”œâ”€â”€ README.md                   # ëª¨ë¸ ë¬¸ì„œ
â””â”€â”€ .cache/                     # ìºì‹œ ë””ë ‰í† ë¦¬
```

**ì„¤ëª…**:
- **ì‹¤ì œ STT ì¶”ë¡ ì— í•„ìš”í•œ ëª¨ë“  íŒŒì¼**
- `model.safetensors`: ëª¨ë¸ì˜ ì‹ ê²½ë§ ê°€ì¤‘ì¹˜ (1.5GB, ê°€ì¥ ì¤‘ìš”)
- ì„¤ì • íŒŒì¼ë“¤: ìŒì„± ì „ì²˜ë¦¬, í† í¬ë‚˜ì´ì € ë“± í•„ìš”í•œ ëª¨ë“  ì„¤ì •
- **ì´ í´ë”ê°€ ì—†ìœ¼ë©´ STTë¥¼ ì‚¬ìš©í•  ìˆ˜ ì—†ìŒ**

---

## ğŸ”„ GPU ì„œë²„ë¡œ ì´ê´€í•˜ê¸°

### ğŸ“‹ ì¤€ë¹„ ì‚¬í•­
```
Linux GPU ì„œë²„:
â”œâ”€â”€ Docker ë° NVIDIA Docker
â”œâ”€â”€ ì¶©ë¶„í•œ ë””ìŠ¤í¬ ê³µê°„ (ìµœì†Œ 2GB)
â””â”€â”€ ì¸í„°ë„· ì—°ê²° (ì´ˆê¸° ëª¨ë¸ ë‹¤ìš´ë¡œë“œ ì‹œ)
```

---

## ğŸš€ ë°©ë²• 1ï¸âƒ£: í´ë” í†µì§¸ë¡œ ë³µì‚¬ (ê¶Œì¥) â­

**ê°€ì¥ ë¹ ë¥´ê³  ê°„ë‹¨í•œ ë°©ë²•** - ì´ë¯¸ ë‹¤ìš´ë¡œë“œëœ ëª¨ë¸ì„ ê·¸ëŒ€ë¡œ ê°€ì ¸ê°

### ë¡œì»¬ macOS â†’ Linux ì„œë²„ë¡œ ë³µì‚¬

#### ì˜µì…˜ A: SCPë¡œ ë³µì‚¬ (ê¶Œì¥)
```bash
# ë¡œì»¬ macOS í„°ë¯¸ë„ì—ì„œ ì‹¤í–‰
scp -r /Users/a113211/workspace/stt_engine/models/openai_whisper-large-v3-turbo \
    username@linux-server:/opt/stt_engine/models/

# ì˜ˆì‹œ
scp -r /Users/a113211/workspace/stt_engine/models/openai_whisper-large-v3-turbo \
    user@192.168.1.100:/opt/stt_engine/models/
```

#### ì˜µì…˜ B: ì••ì¶•í•´ì„œ ë³µì‚¬ (ë¹ ë¦„)
```bash
# ë¡œì»¬ macOSì—ì„œ ì••ì¶•
cd /Users/a113211/workspace/stt_engine/models/
tar -czf whisper-model.tar.gz openai_whisper-large-v3-turbo/

# ì„œë²„ë¡œ ì „ì†¡
scp whisper-model.tar.gz username@linux-server:/tmp/

# ì„œë²„ì—ì„œ ì••ì¶• í•´ì œ
ssh username@linux-server
cd /opt/stt_engine/models/
tar -xzf /tmp/whisper-model.tar.gz
rm /tmp/whisper-model.tar.gz
```

#### ì˜µì…˜ C: USB ë˜ëŠ” ì™¸ì¥ ë“œë¼ì´ë¸Œ (ë¹ ë¥¸ ì¸í„°ë„· ì—†ì„ ë•Œ)
```bash
# 1. USBì— ë³µì‚¬
cp -r /Users/a113211/workspace/stt_engine/models/openai_whisper-large-v3-turbo \
    /Volumes/USB_Drive/

# 2. Linux ì„œë²„ì— ì—°ê²° í›„
cp -r /mnt/usb/openai_whisper-large-v3-turbo \
    /opt/stt_engine/models/
```

---

## ğŸ”§ ë°©ë²• 2ï¸âƒ£: ì„œë²„ì—ì„œ ì§ì ‘ ë‹¤ìš´ë¡œë“œ

**ì¸í„°ë„· ì†ë„ê°€ ë¹ ë¥¼ ë•Œ ê¶Œì¥** - ë” ê°„ë‹¨í•˜ê³  ê²€ì¦ ìë™í™”

### Linux ì„œë²„ì—ì„œ ë‹¤ìš´ë¡œë“œ

```bash
# 1. í”„ë¡œì íŠ¸ í´ë¡ 
git clone https://github.com/Kuwon-KIS/stt_engine.git
cd stt_engine

# 2. Dockerë¡œ ëª¨ë¸ ë‹¤ìš´ë¡œë“œ (ê¶Œì¥)
docker build -t stt-engine:with-model -f Dockerfile.gpu .

# ë˜ëŠ” ë¡œì»¬ì—ì„œ ë‹¤ìš´ë¡œë“œ
python3 -m venv venv
source venv/bin/activate
pip install -r requirements.txt
python download_model.py
```

**ì¥ì **:
- ìë™ìœ¼ë¡œ ì˜¬ë°”ë¥¸ ê²½ë¡œì— ì €ì¥
- ì²´í¬ì„¬ ê²€ì¦ í¬í•¨
- íŒŒì¼ ë¬´ê²°ì„± ë³´ì¥

**ë‹¨ì **:
- ì¸í„°ë„· ì†ë„ì— ë”°ë¼ 15-30ë¶„ ì†Œìš”
- ì„œë²„ ë¦¬ì†ŒìŠ¤ ì‚¬ìš©

---

## âœ… ìµœì ì˜ ë°©ì‹ (ê¶Œì¥)

### ğŸ˜Š ìƒí™© 1: ì´ë¯¸ ë¡œì»¬ì—ì„œ ë‹¤ìš´ë¡œë“œ ì™„ë£Œ
```bash
# ë¡œì»¬ì—ì„œ ì„ íƒì ìœ¼ë¡œ í•„ìš”í•œ í´ë”ë§Œ ë³µì‚¬
scp -r /Users/a113211/workspace/stt_engine/models/openai_whisper-large-v3-turbo \
    user@server:/opt/stt_engine/models/

# (openai_whisper-large-v3-turbo í´ë”ë§Œ í•„ìš”!)
```

### ğŸ˜Š ìƒí™© 2: GPU ì„œë²„ì—ì„œ ì²˜ìŒ ì„¤ì •
```bash
# ì„œë²„ì—ì„œ í•œ ë²ˆì— ì„¤ì •
git clone https://github.com/Kuwon-KIS/stt_engine.git
cd stt_engine
docker-compose up -d  # ìë™ìœ¼ë¡œ ëª¨ë¸ ë‹¤ìš´ë¡œë“œ (Dockerfile.gpu ì‚¬ìš© ì‹œ)
```

---

## ğŸ“Š íŒŒì¼ êµ¬ì¡° ë¹„êµ

| í•­ëª© | `models--openai...` | `openai_whisper...` |
|------|-------------------|-------------------|
| **ìš©ë„** | ìºì‹œ ë©”íƒ€ë°ì´í„° | **ì‹¤ì œ ëª¨ë¸ íŒŒì¼** â­ |
| **í¬ê¸°** | ~100KB | ~1.5GB |
| **íŒŒì¼ ìˆ˜** | 1 | 41 |
| **í•„ìˆ˜ ì—¬ë¶€** | âŒ No (ì„ íƒ) | âœ… Yes (í•„ìˆ˜) |
| **ì´ê´€ í•„ìš”** | âŒ No | âœ… Yes |
| **ì„œë²„ ì„¤ì • í›„** | ìë™ ìƒì„± | ë¯¸ë¦¬ ì¤€ë¹„ í•„ìš” |

---

## ğŸ³ Dockerë¥¼ ì‚¬ìš©í•œ ì™„ë²½í•œ ì´ê´€ ë°©ë²•

### ì´ë¯¸ ë‹¤ìš´ë¡œë“œëœ ëª¨ë¸ ì‚¬ìš©

#### 1ë‹¨ê³„: ë¡œì»¬ì—ì„œ ëª¨ë¸ë§Œ ë³µì‚¬
```bash
# ë¡œì»¬ì—ì„œ
scp -r /Users/a113211/workspace/stt_engine/models/openai_whisper-large-v3-turbo \
    user@server:/opt/stt_engine/models/
```

#### 2ë‹¨ê³„: ì„œë²„ì—ì„œ Docker Compose ì‹œì‘
```bash
# ì„œë²„ì—ì„œ
cd /opt/stt_engine
docker-compose up -d

# í™•ì¸
docker-compose logs -f stt-engine
curl http://localhost:8001/health
```

### ë˜ëŠ” ëª¨ë¸ í¬í•¨ ì´ë¯¸ì§€ ë¹Œë“œ

```bash
# ë¡œì»¬ macOSì—ì„œ ëª¨ë¸ í¬í•¨ ì´ë¯¸ì§€ ë¹Œë“œ
docker build -t stt-engine:with-model -f Dockerfile.gpu .

# Docker Hubì— í‘¸ì‹œ (ì„ íƒì‚¬í•­)
docker tag stt-engine:with-model username/stt-engine:latest
docker push username/stt-engine:latest

# ì„œë²„ì—ì„œ í’€
docker pull username/stt-engine:latest
docker-compose up -d
```

---

## ğŸ›¡ï¸ ê²€ì¦ ë° ë¬¸ì œ í•´ê²°

### ëª¨ë¸ ë‹¤ìš´ë¡œë“œ ì™„ë£Œ í™•ì¸
```bash
# ë¡œì»¬ì—ì„œ
ls -lah /Users/a113211/workspace/stt_engine/models/openai_whisper-large-v3-turbo/
# â†’ model.safetensorsê°€ 1.5GB í¬ê¸°ì—¬ì•¼ í•¨
```

### ì„œë²„ì—ì„œ ëª¨ë¸ ì¤€ë¹„ í™•ì¸
```bash
# Linux ì„œë²„ì—ì„œ
ls -lah /opt/stt_engine/models/openai_whisper-large-v3-turbo/
# â†’ model.safetensorsê°€ ìˆëŠ”ì§€ í™•ì¸

# ë˜ëŠ” Docker ì»¨í…Œì´ë„ˆ ë‚´ì—ì„œ
docker-compose exec stt-engine ls -lah /app/models/
```

### ëª¨ë¸ íŒŒì¼ ë¬´ê²°ì„± í™•ì¸
```bash
# ë¡œì»¬ê³¼ ì„œë²„ì˜ íŒŒì¼ í¬ê¸° ë¹„êµ
du -sh /Users/a113211/workspace/stt_engine/models/openai_whisper-large-v3-turbo/
# ë¡œì»¬: ~1.5GB

# ì„œë²„ì—ì„œ
du -sh /opt/stt_engine/models/openai_whisper-large-v3-turbo/
# ì„œë²„: ~1.5GB (ê°™ì•„ì•¼ í•¨)

# ë˜ëŠ” ì²´í¬ì„¬ ë¹„êµ
md5sum /Users/a113211/workspace/stt_engine/models/openai_whisper-large-v3-turbo/model.safetensors
md5sum /opt/stt_engine/models/openai_whisper-large-v3-turbo/model.safetensors
# ê°™ì•„ì•¼ í•¨
```

### STT ê¸°ëŠ¥ í…ŒìŠ¤íŠ¸
```bash
# ì„œë²„ì—ì„œ API í…ŒìŠ¤íŠ¸
curl http://localhost:8001/health

# ìŒì„± íŒŒì¼ë¡œ í…ŒìŠ¤íŠ¸
curl -X POST -F "file=@test_audio.wav" \
    http://localhost:8001/transcribe
```

---

## ğŸ“‹ ì²´í¬ë¦¬ìŠ¤íŠ¸: GPU ì„œë²„ ì´ê´€

### ì¤€ë¹„ ë‹¨ê³„
- [ ] GPU ì„œë²„ Docker í™˜ê²½ í™•ì¸
- [ ] ë””ìŠ¤í¬ ê³µê°„ í™•ì¸ (ìµœì†Œ 2GB)
- [ ] ì¸í„°ë„· ì—°ê²° í™•ì¸

### ì´ê´€ ë‹¨ê³„
- [ ] ë¡œì»¬ì—ì„œ ëª¨ë¸ ë‹¤ìš´ë¡œë“œ í™•ì¸
  ```bash
  ls -lah /Users/a113211/workspace/stt_engine/models/openai_whisper-large-v3-turbo/model.safetensors
  ```
- [ ] ëª¨ë¸ í´ë”ë§Œ ì„œë²„ë¡œ ë³µì‚¬ (openai_whisper-large-v3-turboë§Œ!)
  ```bash
  scp -r /Users/a113211/workspace/stt_engine/models/openai_whisper-large-v3-turbo \
      user@server:/opt/stt_engine/models/
  ```
- [ ] í”„ë¡œì íŠ¸ ì½”ë“œ ì„œë²„ì— í´ë¡ 
  ```bash
  git clone https://github.com/Kuwon-KIS/stt_engine.git /opt/stt_engine
  ```
- [ ] docker-compose.ymlì—ì„œ WHISPER_DEVICEë¥¼ cudaë¡œ ì„¤ì •
  ```bash
  nano /opt/stt_engine/docker-compose.yml
  # WHISPER_DEVICE=cudaë¡œ ë³€ê²½
  ```
- [ ] Docker Compose ì‹œì‘
  ```bash
  cd /opt/stt_engine
  docker-compose up -d
  ```
- [ ] í—¬ìŠ¤ ì²´í¬
  ```bash
  curl http://localhost:8001/health
  curl http://localhost:8000/health  # vLLM
  ```

### ê²€ì¦ ë‹¨ê³„
- [ ] ìŒì„± íŒŒì¼ ì¤€ë¹„
- [ ] STT ê¸°ëŠ¥ í…ŒìŠ¤íŠ¸
- [ ] vLLM í†µí•© í…ŒìŠ¤íŠ¸
- [ ] ë¡œê·¸ í™•ì¸

---

## ğŸ’¡ íŒ

### ëª¨ë¸ í´ë” ì •ë¦¬
```bash
# ì²«ë²ˆì§¸ í´ë”ëŠ” ì‚­ì œí•´ë„ ê´œì°®ìŒ
rm -rf /Users/a113211/workspace/stt_engine/models/models--openai--whisper-large-v3-turbo

# ë˜ëŠ” ìµœì í™”: ë‘ í´ë”ë¥¼ í•˜ë‚˜ë¡œ ì •ë¦¬
# (ê³ ê¸‰ ì‚¬ìš©ììš©)
```

### ëª¨ë¸ ì—…ë°ì´íŠ¸
```bash
# ìƒˆ ë²„ì „ ë‹¤ìš´ë¡œë“œ í•„ìš”í•  ë•Œ
rm -rf /Users/a113211/workspace/stt_engine/models/openai_whisper-large-v3-turbo
python download_model.py

# ìºì‹œ ì •ë¦¬ (ì„ íƒì‚¬í•­)
rm -rf /Users/a113211/workspace/stt_engine/models/models--openai--whisper-large-v3-turbo
```

### ë„¤íŠ¸ì›Œí¬ ì†ë„ê°€ ëŠë¦´ ë•Œ
```bash
# ë¡œì»¬ì—ì„œ ë¨¼ì € ë‹¤ìš´ë¡œë“œ ì™„ë£Œ í›„ ì´ê´€ ê¶Œì¥
# USB ë˜ëŠ” í´ë¼ìš°ë“œ ìŠ¤í† ë¦¬ì§€(Google Drive, S3 ë“±) ì‚¬ìš© ê³ ë ¤
```

---

## ğŸ¯ ìµœì¢… ì •ë¦¬

| í•­ëª© | ì„¤ëª… |
|------|------|
| **ì¦‰ì‹œ ì‚­ì œ ê°€ëŠ¥** | `models--openai--whisper-large-v3-turbo` |
| **ë°˜ë“œì‹œ ì´ê´€** | `openai_whisper-large-v3-turbo` (1.5GB) |
| **ê¶Œì¥ ë°©ë²•** | SCPë¡œ í´ë” ë³µì‚¬ í›„ ì„œë²„ì—ì„œ docker-compose up |
| **ì†Œìš” ì‹œê°„** | ë³µì‚¬: 5-10ë¶„, ì„œë²„ ì„¤ì •: 5ë¶„ |
| **ì£¼ì˜ì‚¬í•­** | model.safetensors íŒŒì¼ í¬ê¸°(1.5GB) í™•ì¸ í•„ìˆ˜ |
