#!/usr/bin/env python3
from faster_whisper import WhisperModel
import numpy as np

print("\n" + "="*60)
print("ğŸ” STT Engine ëª¨ë¸ ê²€ì¦")
print("="*60 + "\n")

print("ğŸ“Œ Step 1: ëª¨ë¸ ë¡œë“œ í…ŒìŠ¤íŠ¸\n")
print("â³ faster-whisperë¡œ ëª¨ë¸ ë¡œë“œ ì¤‘...")
print("   (ì´ ë‹¨ê³„ëŠ” 1-5ë¶„ ê±¸ë¦´ ìˆ˜ ìˆìŠµë‹ˆë‹¤)\n")

try:
    from pathlib import Path
    
    # ë‹¤ìš´ë¡œë“œëœ ëª¨ë¸ ê²½ë¡œ
    model_path = str(Path(__file__).parent / "models" / "openai_whisper-large-v3-turbo")
    
    model = WhisperModel(
        model_size_or_path=model_path,
        device="cpu",
        compute_type="int8"
    )
    print("âœ… faster-whisper ëª¨ë¸ ë¡œë“œ ì„±ê³µ!\n")
    
    print("ğŸ“‹ ëª¨ë¸ ì •ë³´:")
    print("   âœ“ ëª¨ë¸ íƒ€ì…: Whisper Large-v3-Turbo")
    print("   âœ“ ë””ë°”ì´ìŠ¤: CPU")
    print("   âœ“ ì–‘ìí™”: INT8\n")
    
    print("ğŸ“Œ Step 2: ì¶”ë¡  í…ŒìŠ¤íŠ¸\n")
    print("â³ ë”ë¯¸ ì˜¤ë””ì˜¤ë¡œ ì¶”ë¡  í…ŒìŠ¤íŠ¸ ì¤‘...\n")
    
    dummy_audio = np.zeros((16000,), dtype=np.float32)
    segments, info = model.transcribe(dummy_audio, language="ko")
    
    print("âœ… ì¶”ë¡  í…ŒìŠ¤íŠ¸ ì„±ê³µ!\n")
    
    print("ğŸ“Š ì¶”ë¡  ê²°ê³¼:")
    print(f"   âœ“ ê°ì§€ëœ ì–¸ì–´: {info.language}")
    print(f"   âœ“ ì–¸ì–´ ì‹ ë¢°ë„: {info.language_probability:.2%}")
    print(f"   âœ“ ì²˜ë¦¬ëœ ì˜¤ë””ì˜¤ ì‹œê°„: {info.duration:.2f}ì´ˆ\n")
    
    segment_list = list(segments)
    print(f"   âœ“ ê°ì§€ëœ ì„¸ê·¸ë¨¼íŠ¸: {len(segment_list)}ê°œ\n")
    
    print("="*60)
    print("âœ… ëª¨ë¸ ê²€ì¦ ì™„ë£Œ!")
    print("="*60)
    print("\nğŸ‰ ëª¨ë¸ì´ ì •ìƒì ìœ¼ë¡œ ì‘ë™í•©ë‹ˆë‹¤!\n")
    
except Exception as e:
    print(f"âŒ ì˜¤ë¥˜ ë°œìƒ: {e}\n")
    import traceback
    traceback.print_exc()
