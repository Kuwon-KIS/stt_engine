# Whisper ëª¨ë¸ ì••ì¶• ë° ì›ê²© ë¡œë“œ ë°©ì‹

## ðŸ“Œ ë¨¼ì € ëª…í™•ížˆ í•˜ê¸°

**vLLMê³¼ WhisperëŠ” ë‹¤ë¥¸ ëª¨ë¸ìž…ë‹ˆë‹¤:**
- **vLLM**: LLM (ëŒ€ê·œëª¨ ì–¸ì–´ ëª¨ë¸) ì¶”ë¡  ì—”ì§„ (ì˜ˆ: Llama, Mistral)
- **Whisper**: STT (ìŒì„±â†’í…ìŠ¤íŠ¸) ëª¨ë¸

ë”°ë¼ì„œ vLLMì—ì„œ ì§ì ‘ Whisperë¥¼ í˜¸ì¶œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. í•˜ì§€ë§Œ **STT ì—”ì§„**ì—ì„œ ì••ì¶•ëœ ëª¨ë¸ì„ ì‚¬ìš©í•˜ê±°ë‚˜, ì›ê²©ìœ¼ë¡œ ë¡œë“œí•˜ëŠ” ê²ƒì€ ì¶©ë¶„ížˆ ê°€ëŠ¥í•©ë‹ˆë‹¤!

---

## ðŸŽ¯ ê°€ëŠ¥í•œ 4ê°€ì§€ ë°©ì‹

### 1ï¸âƒ£ **TAR ì••ì¶• í›„ í•´ì œ ë°©ì‹** (ì €ìž¥ì†Œ ê³µê°„ ì ˆì•½)

#### ë¡œì»¬ì—ì„œ ì••ì¶•
```bash
# 1. ëª¨ë¸ í´ë” ì••ì¶• (ì•½ 1.5GB â†’ 1.2GB)
cd models/
tar -czf whisper-model.tar.gz openai_whisper-large-v3-turbo/

# 2. ì••ì¶• íŒŒì¼ í¬ê¸° í™•ì¸
ls -lh whisper-model.tar.gz  # ~1.2GB

# 3. ì›ë³¸ í´ë” ì‚­ì œ (ì„ íƒì‚¬í•­)
rm -rf openai_whisper-large-v3-turbo/
```

#### ì„œë²„ì—ì„œ ìžë™ í•´ì œ (Docker ë¹Œë“œ ì‹œ)
```dockerfile
# Dockerfileì— ì¶”ê°€
FROM python:3.11-slim
WORKDIR /app

# ì••ì¶• íŒŒì¼ ë³µì‚¬
COPY models/whisper-model.tar.gz /app/

# ëª¨ë¸ í•´ì œ
RUN tar -xzf /app/whisper-model.tar.gz -C /app/models/
RUN rm /app/whisper-model.tar.gz

# ... ë‚˜ë¨¸ì§€ ì„¤ì •
CMD ["python", "api_server.py"]
```

#### ë˜ëŠ” ì‹œìž‘ì‹œ ìžë™ í•´ì œ (Python)
```python
import tarfile
import os
from pathlib import Path

def extract_model_if_needed():
    model_path = Path("models/openai_whisper-large-v3-turbo")
    tar_path = Path("models/whisper-model.tar.gz")
    
    if tar_path.exists() and not model_path.exists():
        print("ðŸ“¦ ëª¨ë¸ ì••ì¶• í•´ì œ ì¤‘...")
        with tarfile.open(tar_path, "r:gz") as tar:
            tar.extractall(path="models/")
        print("âœ… í•´ì œ ì™„ë£Œ")
    
    return model_path

# ì„œë²„ ì‹œìž‘ ì „ì— í˜¸ì¶œ
model_path = extract_model_if_needed()
stt = WhisperSTT(str(model_path))
```

**ìž¥ì :** ì €ìž¥ì†Œ ê³µê°„ 15% ì ˆì•½, Gitì— ìš©ì´  
**ë‹¨ì :** í•´ì œ ì‹œê°„ í•„ìš” (~1ë¶„), ì¶”ê°€ ì½”ë“œ

---

### 2ï¸âƒ£ **AWS S3 ë˜ëŠ” GCSì—ì„œ ì›ê²© ë¡œë“œ** (ê¶Œìž¥, ì„œë²„ í™˜ê²½ì—ì„œ)

#### S3ì— ëª¨ë¸ ì—…ë¡œë“œ
```bash
# 1. AWS CLI ì„¤ì¹˜
pip install boto3

# 2. S3 ë²„í‚· ìƒì„±
aws s3 mb s3://stt-models-bucket

# 3. ëª¨ë¸ ì—…ë¡œë“œ
aws s3 cp models/whisper-model.tar.gz \
    s3://stt-models-bucket/whisper-model.tar.gz

# 4. ì§„í–‰ë¥  ë³´ê¸°
aws s3 cp models/whisper-model.tar.gz \
    s3://stt-models-bucket/whisper-model.tar.gz \
    --sse AES256
```

#### Pythonì—ì„œ S3ì—ì„œ ë¡œë“œ
```python
import boto3
import tarfile
from pathlib import Path
import tempfile

def download_model_from_s3(
    bucket_name: str = "stt-models-bucket",
    model_key: str = "whisper-model.tar.gz",
    local_path: str = "models"
):
    """S3ì—ì„œ ëª¨ë¸ ë‹¤ìš´ë¡œë“œ ë° ì¶”ì¶œ"""
    
    s3 = boto3.client('s3')
    tar_file = Path(local_path) / "whisper-model.tar.gz"
    model_dir = Path(local_path) / "openai_whisper-large-v3-turbo"
    
    # ì´ë¯¸ ì¡´ìž¬í•˜ë©´ ìŠ¤í‚µ
    if model_dir.exists():
        print("âœ… ëª¨ë¸ì´ ì´ë¯¸ ì¡´ìž¬í•©ë‹ˆë‹¤")
        return model_dir
    
    print(f"ðŸ“¥ S3ì—ì„œ ëª¨ë¸ ë‹¤ìš´ë¡œë“œ ì¤‘... ({bucket_name}/{model_key})")
    
    # ë‹¤ìš´ë¡œë“œ
    s3.download_file(bucket_name, model_key, str(tar_file))
    print("âœ… ë‹¤ìš´ë¡œë“œ ì™„ë£Œ")
    
    # ì¶”ì¶œ
    print("ðŸ“¦ ëª¨ë¸ ì••ì¶• í•´ì œ ì¤‘...")
    with tarfile.open(tar_file, "r:gz") as tar:
        tar.extractall(path=local_path)
    print("âœ… í•´ì œ ì™„ë£Œ")
    
    # ì••ì¶• íŒŒì¼ ì‚­ì œ
    tar_file.unlink()
    
    return model_dir

# Dockerì—ì„œ ì‚¬ìš©
from stt_engine import WhisperSTT

model_path = download_model_from_s3()
stt = WhisperSTT(str(model_path))
```

#### Docker Composeì— í™˜ê²½ ë³€ìˆ˜ ì¶”ê°€
```yaml
services:
  stt-engine:
    environment:
      - AWS_ACCESS_KEY_ID=${AWS_ACCESS_KEY_ID}
      - AWS_SECRET_ACCESS_KEY=${AWS_SECRET_ACCESS_KEY}
      - S3_BUCKET_NAME=stt-models-bucket
      - S3_MODEL_KEY=whisper-model.tar.gz
```

**ìž¥ì :** ì—¬ëŸ¬ ì„œë²„ì—ì„œ ê³µìœ  ê°€ëŠ¥, ë²„ì „ ê´€ë¦¬ ìš©ì´, ìžë™ ë°±ì—…  
**ë‹¨ì :** AWS ë¹„ìš© ë°œìƒ, ì´ˆê¸° ë‹¤ìš´ë¡œë“œ ì‹œê°„, ë„¤íŠ¸ì›Œí¬ ì˜ì¡´

---

### 3ï¸âƒ£ **Google Driveì—ì„œ ì›ê²© ë¡œë“œ** (ê°œì¸/ì†Œê·œëª¨ í”„ë¡œì íŠ¸ìš©)

```python
from google.colab import drive
from googleapiclient.discovery import build
import tarfile

def download_from_google_drive(file_id: str, destination: str):
    """Google Driveì—ì„œ íŒŒì¼ ë‹¤ìš´ë¡œë“œ"""
    
    import urllib.request
    
    url = f"https://drive.google.com/uc?export=download&id={file_id}"
    
    print(f"ðŸ“¥ Google Driveì—ì„œ ë‹¤ìš´ë¡œë“œ ì¤‘...")
    urllib.request.urlretrieve(url, destination)
    print("âœ… ë‹¤ìš´ë¡œë“œ ì™„ë£Œ")
    
    # ì••ì¶• í•´ì œ
    print("ðŸ“¦ ì••ì¶• í•´ì œ ì¤‘...")
    with tarfile.open(destination, "r:gz") as tar:
        tar.extractall(path="models/")
    print("âœ… ì™„ë£Œ")

# ì‚¬ìš©ë²•
# 1. Google Driveì— whisper-model.tar.gz ì—…ë¡œë“œ
# 2. íŒŒì¼ ID ë³µì‚¬ (URL: https://drive.google.com/file/d/{FILE_ID}/view)
# 3. ë‹¤ìŒ ì½”ë“œ ì‹¤í–‰

download_from_google_drive(
    file_id="YOUR_FILE_ID_HERE",
    destination="models/whisper-model.tar.gz"
)
```

**ìž¥ì :** ë¬´ë£Œ, ê°„ë‹¨  
**ë‹¨ì :** ëŠë¦¼, ëŒ€ì—­í­ ì œí•œ, ì‹ ë¢°ì„± ë‚®ìŒ

---

### 4ï¸âƒ£ **Hugging Face Hubì— ì§ì ‘ ì—…ë¡œë“œ** (ìµœê³  ê¶Œìž¥! ðŸŒŸ)

ì´ë¯¸ Hugging Faceì—ì„œ ëª¨ë¸ì„ ë‹¤ìš´ë¡œë“œ ì¤‘ì´ë¯€ë¡œ, ì§ì ‘ Hubì— ì˜¬ë ¤ì„œ ì‚¬ìš©í•˜ë©´ ê°€ìž¥ ê¹”ë”í•©ë‹ˆë‹¤!

#### ìžì‹ ì˜ Hugging Face ëª¨ë¸ ì €ìž¥ì†Œ ìƒì„±
```bash
# 1. Hugging Face ê³„ì • ìƒì„± (https://huggingface.co)

# 2. í† í° ì„¤ì •
huggingface-cli login
# â†’ token ìž…ë ¥

# 3. ì €ìž¥ì†Œ ìƒì„± (ì›¹ì—ì„œ ë˜ëŠ” CLI)
huggingface-cli repo create --repo-type=model \
    --private stt-whisper-custom

# 4. ë¡œì»¬ì— í´ë¡ 
git clone https://huggingface.co/your-username/stt-whisper-custom
cd stt-whisper-custom

# 5. ëª¨ë¸ íŒŒì¼ ë³µì‚¬
cp -r ../models/openai_whisper-large-v3-turbo/* .

# 6. í‘¸ì‹œ
git add .
git commit -m "Add Whisper model"
git push
```

#### Pythonì—ì„œ ì§ì ‘ ë¡œë“œ
```python
from transformers import AutoProcessor, AutoModelForSpeechSeq2Seq

# Hugging Faceì—ì„œ ì§ì ‘ ë¡œë“œ (ìºì‹œë¨)
model = AutoModelForSpeechSeq2Seq.from_pretrained(
    "your-username/stt-whisper-custom"
)
processor = AutoProcessor.from_pretrained(
    "your-username/stt-whisper-custom"
)

# ë˜ëŠ” ë¡œì»¬ ê²½ë¡œ ì§€ì •
model = AutoModelForSpeechSeq2Seq.from_pretrained(
    "./models/openai_whisper-large-v3-turbo"
)
```

**ìž¥ì :** ìµœê³ ì˜ í†µí•©ì„±, ë²„ì „ ê´€ë¦¬, ìžë™ ìºì‹±, ì»¤ë®¤ë‹ˆí‹° ê³µìœ   
**ë‹¨ì :** ì¸í„°ë„· í•„ìš” (ì´ˆê¸°ì—ë§Œ)

---

## ðŸ“Š ë°©ì‹ë³„ ë¹„êµ

| ë°©ì‹ | ì €ìž¥ì†Œ | ì†ë„ | ê´€ë¦¬ | ì¶”ì²œ |
|------|--------|------|------|------|
| TAR ì••ì¶• | ìµœì†Œ (1.2GB) | ë¹ ë¦„ | ë³´í†µ | ë¡œì»¬ ê°œë°œ |
| AWS S3 | ì¤‘ê°„ | ë³´í†µ | ìµœê³  | í”„ë¡œë•ì…˜ |
| Google Drive | ì¤‘ê°„ | ëŠë¦¼ | ë³´í†µ | ì†Œê·œëª¨ |
| Hugging Face | ìµœì†Œ | ë¹ ë¦„ | ìµœê³  | ìµœìš°ìˆ˜ |

---

## ðŸš€ ì‹¤ì „ ì˜ˆì œ: TAR ì••ì¶• + Docker ìžë™ í•´ì œ

### 1ë‹¨ê³„: ë¡œì»¬ì—ì„œ ì••ì¶•
```bash
cd /Users/a113211/workspace/stt_engine
tar -czf models/whisper-model.tar.gz -C models openai_whisper-large-v3-turbo/
```

### 2ë‹¨ê³„: Dockerfile ìˆ˜ì •
```dockerfile
FROM python:3.11-slim

WORKDIR /app

RUN apt-get update && apt-get install -y \
    ffmpeg libsndfile1 git tar gzip \
    && rm -rf /var/lib/apt/lists/*

RUN pip install --upgrade pip setuptools wheel

COPY requirements.txt .
RUN pip install --no-cache-dir -r requirements.txt

COPY . .

# ëª¨ë¸ ì••ì¶• íŒŒì¼ì´ ìžˆìœ¼ë©´ ìžë™ í•´ì œ
RUN if [ -f models/whisper-model.tar.gz ]; then \
        echo "ðŸ“¦ ëª¨ë¸ ì••ì¶• í•´ì œ ì¤‘..."; \
        tar -xzf models/whisper-model.tar.gz -C models/; \
        rm models/whisper-model.tar.gz; \
        echo "âœ… ì™„ë£Œ"; \
    fi

RUN mkdir -p audio logs

EXPOSE 8001

HEALTHCHECK --interval=30s --timeout=10s --start-period=40s --retries=3 \
    CMD curl -f http://localhost:8001/health || exit 1

CMD ["python", "api_server.py"]
```

### 3ë‹¨ê³„: Docker Compose ì‹¤í–‰
```bash
# ì••ì¶•ëœ ëª¨ë¸ë¡œ ì´ë¯¸ì§€ ë¹Œë“œ
docker build -t stt-engine:compressed .

# ì‹¤í–‰
docker-compose up -d
```

**ê²°ê³¼:**
- âœ… ì´ë¯¸ì§€ í¬ê¸° ì•½ê°„ ê°ì†Œ
- âœ… ë¹Œë“œ ì‹œê°„ ì•½ê°„ ì¦ê°€ (ì••ì¶• í•´ì œ)
- âœ… ëŸ°íƒ€ìž„ ì‹œê°„ ë™ì¼

---

## ðŸ’¾ Gitì— TAR íŒŒì¼ ì¶”ê°€ (í° íŒŒì¼ ê´€ë¦¬)

### Git LFS ì‚¬ìš© (ê¶Œìž¥)
```bash
# 1. Git LFS ì„¤ì¹˜
brew install git-lfs  # macOS
apt-get install git-lfs  # Ubuntu

# 2. Git LFS ì´ˆê¸°í™”
git lfs install

# 3. TAR íŒŒì¼ì„ LFSë¡œ ì¶”ì 
git lfs track "models/whisper-model.tar.gz"

# 4. .gitattributes ì»¤ë°‹
git add .gitattributes
git commit -m "Add git-lfs tracking for model"

# 5. ëª¨ë¸ íŒŒì¼ ì¶”ê°€
git add models/whisper-model.tar.gz
git commit -m "Add compressed Whisper model"

# 6. í‘¸ì‹œ (ìžë™ìœ¼ë¡œ LFSë¡œ ì—…ë¡œë“œ)
git push
```

---

## ðŸŽ¯ ê¶Œìž¥ ì„ íƒ

### ðŸ“ ìƒí™©ë³„ ì¶”ì²œ

**ë¡œì»¬ ê°œë°œ (macOS/Linux):**
```bash
# í˜„ìž¬ ìƒíƒœ ìœ ì§€ (ì••ì¶• ì•ˆ í•¨)
# â†’ ë¹ ë¦„, ê°„íŽ¸
```

**Docker ë°°í¬ (ìžì²´ ì„œë²„):**
```bash
# TAR ì••ì¶• ë°©ì‹
# â†’ ì €ìž¥ì†Œ ê³µê°„ ì ˆì•½, ë¹Œë“œ ìžë™í™”
```

**í´ë¼ìš°ë“œ ë°°í¬ (AWS/GCP):**
```bash
# S3/GCSì—ì„œ ë¡œë“œ
# â†’ ìœ ì—°í•¨, í™•ìž¥ì„±, ë²„ì „ ê´€ë¦¬
```

**ê³µê°œ ë°°í¬ ë˜ëŠ” íŒ€ í˜‘ì—…:**
```bash
# Hugging Face Hub
# â†’ ìµœê³ ì˜ í†µí•©ì„±, ì»¤ë®¤ë‹ˆí‹° í™œìš©
```

---

## ðŸ“ ê°„ë‹¨í•œ êµ¬í˜„: ì••ì¶• í›„ ìžë™ í•´ì œ

### í•œ ì¤„ ëª…ë ¹ì–´ë¡œ ì„¤ì •
```bash
# 1. ì••ì¶•
tar -czf models/whisper-model.tar.gz -C models openai_whisper-large-v3-turbo/

# 2. Dockerfile ìžë™ ìƒì„± (ì••ì¶• í•´ì œ í¬í•¨)
cat > Dockerfile.compressed << 'EOF'
FROM python:3.11-slim
WORKDIR /app
RUN apt-get update && apt-get install -y ffmpeg libsndfile1 git && rm -rf /var/lib/apt/lists/*
RUN pip install --upgrade pip setuptools wheel
COPY requirements.txt .
RUN pip install --no-cache-dir -r requirements.txt
COPY . .
RUN mkdir -p audio logs && \
    test -f models/whisper-model.tar.gz && \
    tar -xzf models/whisper-model.tar.gz -C models/ && \
    rm models/whisper-model.tar.gz || true
EXPOSE 8001
CMD ["python", "api_server.py"]
EOF

# 3. ë¹Œë“œ
docker build -t stt-engine:compressed -f Dockerfile.compressed .

# 4. ì‹¤í–‰
docker run -p 8001:8001 stt-engine:compressed
```

---

## ê²°ë¡ 

| ë°©ì‹ | ê°€ëŠ¥ ì—¬ë¶€ | ë‚œì´ë„ | ì¶”ì²œë„ |
|------|---------|--------|--------|
| TAR ì••ì¶• ìžë™ í•´ì œ | âœ… ê°€ëŠ¥ | ì‰¬ì›€ | â­â­â­â­ |
| S3 ì›ê²© ë¡œë“œ | âœ… ê°€ëŠ¥ | ì¤‘ê°„ | â­â­â­â­ |
| Hugging Face ë¡œë“œ | âœ… ê°€ëŠ¥ | ì‰¬ì›€ | â­â­â­â­â­ |
| Google Drive ë¡œë“œ | âœ… ê°€ëŠ¥ | ì‰¬ì›€ | â­â­â­ |

**vLLMê³¼ëŠ” ë³„ê°œì´ì§€ë§Œ, STT ì—”ì§„ì—ì„œëŠ” ëª¨ë‘ ê°€ëŠ¥í•©ë‹ˆë‹¤!** ðŸš€
