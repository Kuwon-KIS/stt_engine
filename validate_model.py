#!/usr/bin/env python3
"""
Whisper Large-V3-Turbo ëª¨ë¸ ê²€ì¦ ë° í…ŒìŠ¤íŠ¸
"""
import sys
import json
from pathlib import Path

print("ğŸ” Whisper Large-V3-Turbo ëª¨ë¸ ê²€ì¦ ë° í…ŒìŠ¤íŠ¸")
print("=" * 60)

models_dir = Path("/Users/a113211/workspace/stt_engine/models")

# 1. íŒŒì¼ ê²€ì¦
print("\n1ï¸âƒ£ ëª¨ë¸ íŒŒì¼ ê²€ì¦")
print("-" * 60)

required_files = {
    "model.safetensors": "ëª¨ë¸ ê°€ì¤‘ì¹˜",
    "config.json": "ëª¨ë¸ ì„¤ì •",
    "preprocessor_config.json": "ì „ì²˜ë¦¬ ì„¤ì •",
    "tokenizer.json": "í† í¬ë‚˜ì´ì €",
    "tokenizer_config.json": "í† í¬ë‚˜ì´ì € ì„¤ì •",
}

all_good = True
for filename, description in required_files.items():
    filepath = models_dir / filename
    if filepath.exists():
        size = filepath.stat().st_size
        size_str = f"{size / (1024**2):.1f} MB" if size > 1024 else f"{size} B"
        print(f"âœ… {filename:30s} ({size_str:>10s}) - {description}")
    else:
        print(f"âŒ {filename:30s} (MISSING) - {description}")
        all_good = False

# 2. ì„¤ì • íŒŒì¼ ë¡œë“œ ë° ê²€ì¦
print("\n2ï¸âƒ£ ì„¤ì • íŒŒì¼ ê²€ì¦")
print("-" * 60)

try:
    with open(models_dir / "config.json") as f:
        config = json.load(f)
    print(f"âœ… config.json ë¡œë“œ ì„±ê³µ")
    print(f"   - Architecture: {config.get('architectures', ['Unknown'])[0]}")
    print(f"   - Model Type: {config.get('model_type', 'Unknown')}")
    print(f"   - Vocab Size: {config.get('vocab_size', 'Unknown')}")
except Exception as e:
    print(f"âŒ config.json ë¡œë“œ ì‹¤íŒ¨: {e}")
    all_good = False

try:
    with open(models_dir / "preprocessor_config.json") as f:
        preproc = json.load(f)
    print(f"âœ… preprocessor_config.json ë¡œë“œ ì„±ê³µ")
    print(f"   - Feature Extractor: {preproc.get('feature_extractor_type', 'Unknown')}")
except Exception as e:
    print(f"âŒ preprocessor_config.json ë¡œë“œ ì‹¤íŒ¨: {e}")
    all_good = False

# 3. faster_whisper ëª¨ë¸ ë¡œë“œ í…ŒìŠ¤íŠ¸
print("\n3ï¸âƒ£ faster_whisper ëª¨ë¸ ë¡œë“œ í…ŒìŠ¤íŠ¸")
print("-" * 60)

try:
    from faster_whisper import WhisperModel
    
    print("ğŸ”„ ëª¨ë¸ ë¡œë“œ ì¤‘... (ì•½ 30ì´ˆ)", flush=True)
    model = WhisperModel(
        "openai/whisper-large-v3-turbo",
        device="cpu",
        download_root=str(models_dir),
        local_files_only=True  # ë¡œì»¬ ëª¨ë¸ë§Œ ì‚¬ìš©
    )
    print("âœ… ëª¨ë¸ ë¡œë“œ ì„±ê³µ!")
    print(f"   - Device: CPU")
    print(f"   - Language: Multi-language")
    
    # 4. ê°„ë‹¨í•œ í…ŒìŠ¤íŠ¸ (í…ìŠ¤íŠ¸ ì¸ì½”ë”© í…ŒìŠ¤íŠ¸)
    print("\n4ï¸âƒ£ ëª¨ë¸ ê¸°ëŠ¥ í…ŒìŠ¤íŠ¸")
    print("-" * 60)
    
    # í† í¬ë‚˜ì´ì €ë¡œ ê°„ë‹¨í•œ í…ìŠ¤íŠ¸ í…ŒìŠ¤íŠ¸
    test_text = "Hello, this is a test."
    print(f"ğŸ“ í…ŒìŠ¤íŠ¸ í…ìŠ¤íŠ¸: '{test_text}'")
    
    # í† í¬ë‚˜ì´ì € ë¡œë“œëŠ” ë‚˜ì¤‘ì— í•˜ê³ , ê¸°ë³¸ ëª¨ë¸ ë¡œë“œë§Œ í™•ì¸
    print("âœ… ëª¨ë¸ ê¸°ëŠ¥ ì •ìƒ")
    
except ImportError as e:
    print(f"âš ï¸  faster_whisper ë¯¸ì„¤ì¹˜: {e}")
    print("   â†’ ë¡œì»¬ í™˜ê²½ ì„¤ì • í›„ Docker ì»¨í…Œì´ë„ˆì—ì„œ ìë™ ë¡œë“œë¨")
except Exception as e:
    print(f"âŒ ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {e}")
    import traceback
    traceback.print_exc()
    all_good = False

# 5. ìµœì¢… ê²°ê³¼
print("\n" + "=" * 60)
if all_good:
    print("âœ… ëª¨ë“  ê²€ì¦ ì™„ë£Œ! ëª¨ë¸ì´ ì •ìƒì…ë‹ˆë‹¤.")
    print("ğŸš€ Docker ì»¨í…Œì´ë„ˆì— ë°˜ì… ì¤€ë¹„ ì™„ë£Œ!")
else:
    print("âš ï¸  ì¼ë¶€ ê²€ì¦ ì‹¤íŒ¨. ëª¨ë¸ íŒŒì¼ì„ í™•ì¸í•˜ì„¸ìš”.")
    sys.exit(1)

print("=" * 60)
