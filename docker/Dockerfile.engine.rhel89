# ============================================================================
# STT Engine - RHEL 8.9 Optimized with CUDA 12.9 + cuDNN
# 
# Build Platform: RHEL 8.9 AMI EC2
# Build Environment: Online (requires internet)
# Target Server: RHEL 8.9 with CUDA 12.9 + NVIDIA Driver 575.57.08
# Base Image: ubi8/python-311 (Red Hat Universal Base Image)
# glibc: 2.28 (RHEL 8.9 ê¸°ë³¸ê°’ - í˜¸í™˜ì„± 100%)
# cuDNN: wheel íŒ¨í‚¤ì§€ ì„¤ì¹˜
# Final Size: ~1.5GB (compressed tar.gz ~500MB)
#
# ë¹Œë“œ ëª…ë ¹ì–´:
#   docker build --platform linux/amd64 -t stt-engine:cuda129-rhel89-v1.2 -f docker/Dockerfile.engine.rhel89 .
# ============================================================================

FROM --platform=linux/amd64 registry.access.redhat.com/ubi8/python-311:latest

LABEL maintainer="STT Engine Team"
LABEL description="STT Engine RHEL 8.9 Optimized with CUDA 12.9"
LABEL os="RHEL 8.9"
LABEL glibc="2.28"
LABEL cuda.version="12.9"
LABEL cudnn.version="9.0.0.312"
LABEL pytorch.version="2.6.0"

# ============================================================================
# Step 1: ì‹œìŠ¤í…œ ì˜ì¡´ì„± ì„¤ì¹˜ (RHEL/yum ê¸°ë°˜)
# ============================================================================

# ğŸ’¡ UBI 8 subscription-manager ì™„ì „ ë¹„í™œì„±í™”
# RHEL subscription ê´€ë¦¬ ë¹„í™œì„±í™” + ì €ì¥ì†Œ ì„¤ì •
RUN rm -f /etc/rhsm/rhsm.conf && \
    subscription-manager unregister 2>/dev/null || true && \
    subscription-manager clean all 2>/dev/null || true && \
    yum clean all 2>/dev/null || true

# yum ìºì‹œ ë¹„í™œì„±í™” ì„¤ì •
RUN yum-config-manager --save --setopt=tsflags=nodocs 2>/dev/null || true

RUN yum install -y \
    # CA ì¸ì¦ì„œ (SSL/TLS)
    ca-certificates \
    openssl \
    curl \
    wget \
    \
    # Audio/Media ì²˜ë¦¬
    libsndfile \
    ffmpeg \
    sox \
    \
    # ê°œë°œ ë„êµ¬
    make \
    gcc \
    gcc-c++ \
    && yum clean all \
    && rm -rf /var/cache/yum/*

# ============================================================================
# Step 2: cuDNN wheel ì„¤ì¹˜ (nvidia-cudnn-cu12)
# 
# RHEL 8.9ì—ì„œ pipë¥¼ í†µí•œ cuDNN ì„¤ì¹˜
# ë²„ì „: 9.0.0.312 (CUDA 12.x í˜¸í™˜)
# ============================================================================

RUN python3.11 -m pip install --upgrade nvidia-cudnn-cu12==9.0.0.312

# ============================================================================
# Step 3: LD_LIBRARY_PATH ì„¤ì • (cuDNN ë¼ì´ë¸ŒëŸ¬ë¦¬ ê²½ë¡œ)
# ============================================================================

ENV LD_LIBRARY_PATH=/usr/local/lib/python3.11/site-packages/nvidia/cudnn/lib:${LD_LIBRARY_PATH}

# ============================================================================
# Step 4: Python íŒ¨í‚¤ì§€ ë§¤ë‹ˆì € ì—…ê·¸ë ˆì´ë“œ
# ============================================================================

RUN python3.11 -m pip install --upgrade \
    --trusted-host pypi.org \
    --trusted-host files.pythonhosted.org \
    pip setuptools wheel

# ============================================================================
# Step 5: Whisper ë° ì˜ì¡´ì„± ì„¤ì¹˜ (PyTorch ì œì™¸)
# 
# RHEL 8.9 í˜¸í™˜ ë²„ì „ ì‚¬ìš©:
# - faster-whisper: CTranslate2 ê¸°ë°˜ ë¹ ë¥¸ ì¶”ë¡ 
# - openai-whisper: fallback (ëŠë¦¼)
# ============================================================================

RUN python3.11 -m pip install --trusted-host files.pythonhosted.org \
    # Whisper implementations
    faster-whisper==1.2.1 \
    ctranslate2==4.7.1 \
    openai-whisper==20231117 \
    \
    # Audio processing
    librosa==0.10.0 \
    scipy==1.12.0 \
    numpy==1.24.3 \
    \
    # Model management & transformers
    huggingface-hub==0.21.4 \
    transformers==5.0.0 \
    \
    # Web framework
    fastapi==0.109.0 \
    uvicorn==0.27.0 \
    requests==2.31.0 \
    pydantic==2.5.3 \
    python-multipart==0.0.6 \
    \
    # Configuration
    python-dotenv==1.0.0 \
    pyyaml==6.0.1

# ============================================================================
# Step 6: PyTorch ì„¤ì¹˜ (ë§ˆì§€ë§‰)
# 
# CUDA 12.4 ê³µì‹ ì§€ì› ë²„ì „ ì‚¬ìš©
# RHEL 8.9ì˜ CUDA 12.9 Runtimeê³¼ forward compatible
# torchaudioë„ í¬í•¨ (whisperì—ì„œ í•„ìˆ˜)
# ============================================================================

RUN python3.11 -m pip install --no-deps \
    --index-url https://download.pytorch.org/whl/cu124 \
    torch==2.6.0 \
    torchaudio==2.6.0

# ============================================================================
# Step 7: ì• í”Œë¦¬ì¼€ì´ì…˜ ì„¤ì •
# ============================================================================

WORKDIR /app

# ì• í”Œë¦¬ì¼€ì´ì…˜ íŒŒì¼ ë³µì‚¬
COPY api_server.py /app/
COPY stt_engine.py /app/
COPY requirements.txt /app/

# í•„ìˆ˜ ë””ë ‰í† ë¦¬ ìƒì„±
RUN mkdir -p /app/models /app/logs /app/audio

# Python í™˜ê²½ ë³€ìˆ˜
ENV PYTHONUNBUFFERED=1
ENV HF_HOME=/app/models
ENV STT_DEVICE=cpu

# ============================================================================
# Step 8: í—¬ìŠ¤ ì²´í¬ ë° í¬íŠ¸ ë…¸ì¶œ
# ============================================================================

# Health check: 30ì´ˆë§ˆë‹¤ ì²´í¬, 10ì´ˆ íƒ€ì„ì•„ì›ƒ, 3ë²ˆ ì‹¤íŒ¨ ì‹œ unhealthy
HEALTHCHECK --interval=30s --timeout=10s --start-period=5s --retries=3 \
    CMD curl -f http://localhost:8003/health || exit 1

# STT API í¬íŠ¸
EXPOSE 8003

# ============================================================================
# Step 9: ì‹œì‘ ëª…ë ¹ì–´
# ============================================================================

CMD ["python3.11", "api_server.py"]
