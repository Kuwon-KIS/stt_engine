version: '3.8'

services:
  whisper-api:
    build:
      context: .
      dockerfile: Dockerfile.gpu  # GPU 최적화 버전
      # dockerfile: Dockerfile    # CPU 버전 (더 가볍지만 느림)
    image: whisper-stt:latest
    container_name: whisper-stt
    
    ports:
      - "8003:8003"
    
    volumes:
      - ./models:/app/models              # 로컬 모델 마운트
      - ./audio:/app/audio                # 음성 파일
      - ./logs:/app/logs                  # 로그
    
    environment:
      - WHISPER_DEVICE=cuda               # GPU 사용
      - SERVER_HOST=0.0.0.0
      - SERVER_PORT=8003
    
    restart: unless-stopped
    
    # GPU 사용 설정 (NVIDIA Docker)
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]
    
    # 헬스 체크
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8003/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 60s

networks:
  default:
    name: stt-network
    #     reservations:
    #       devices:
    #         - driver: nvidia
    #           count: 1
    #           capabilities: [gpu]

volumes:
  vllm-cache:

networks:
  stt-network:
    driver: bridge
