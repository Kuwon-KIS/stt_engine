# STT Engine ì½”ë“œ ê²€í†  ê²°ê³¼

## ğŸ” ë°œê²¬ëœ ì´ìŠˆë“¤

### ğŸ”´ **ì¤‘ìš” ì´ìŠˆ 1: auto_extract_model_if_needed() í•¨ìˆ˜ì˜ ê²½ë¡œ ë¡œì§ ë¬¸ì œ**

**ìœ„ì¹˜:** `stt_engine.py` ë¼ì¸ 68-71

```python
# ëª¨ë¸ì´ ì••ì¶•ë˜ì–´ ìˆìœ¼ë©´ ìë™ í•´ì œ
model_path = str(auto_extract_model_if_needed(
    Path(model_path).parent  # âŒ ë¬¸ì œ: "models" ë””ë ‰í† ë¦¬ ë°˜í™˜
))
```

**ë¬¸ì œì :**
- `model_path`ê°€ `models/openai_whisper-large-v3-turbo`ì¼ ë•Œ
- `Path(model_path).parent` â†’ `models` í´ë”
- ê·¸ëŸ¬ë‚˜ `auto_extract_model_if_needed()` í•¨ìˆ˜ ë‚´ë¶€ì—ì„œ ë‹¤ì‹œ `models_path / "openai_whisper-large-v3-turbo"` ì¶”ê°€
- ê²°ê³¼: ë°˜í™˜ëœ ê²½ë¡œê°€ ì˜¬ë°”ë¥´ì§€ë§Œ, í˜¸ì¶œ ë°©ì‹ì´ í˜¼ë€ìŠ¤ëŸ¬ì›€

**ìˆ˜ì • ê¶Œì¥:**
```python
# ë°©ë²• 1: ì „ì²´ models_dir ê²½ë¡œ ì „ë‹¬
model_path = str(auto_extract_model_if_needed("models"))

# ë°©ë²• 2: í•¨ìˆ˜ ì¸í„°í˜ì´ìŠ¤ ëª…í™•í™”
# auto_extract_model_if_needed(model_folder_path) ë¡œ ë³€ê²½
```

---

### ğŸ”´ **ì¤‘ìš” ì´ìŠˆ 2: transcribe() í•¨ìˆ˜ì—ì„œ audio ì²˜ë¦¬ í›„ GPU ë©”ëª¨ë¦¬ ëˆ„ìˆ˜**

**ìœ„ì¹˜:** `stt_engine.py` ë¼ì¸ 100-120

```python
def transcribe(self, audio_path: str, language: Optional[str] = None) -> Dict:
    try:
        audio, sr = torchaudio.load(audio_path)
        
        if sr != 16000:
            resampler = torchaudio.transforms.Resample(sr, 16000)
            audio = resampler(audio)  # âŒ GPU ë©”ëª¨ë¦¬ ë¯¸ì •ë¦¬
        
        # ...
        
        inputs = self.processor(
            audio.squeeze().numpy(),  # âŒ ë©”ëª¨ë¦¬ ë¬¸ì œ
            sampling_rate=16000,
            return_tensors="pt"
        )
```

**ë¬¸ì œì :**
1. `audio` Tensorê°€ GPUì— ì˜¬ë¼ê°”ì„ ìˆ˜ ìˆìŒ
2. `.numpy()` í˜¸ì¶œ ì‹œ GPU TensorëŠ” CPUë¡œ ì´ë™ í•„ìˆ˜
3. ë©”ëª¨ë¦¬ ì •ë¦¬ ì—†ìŒ

**ìˆ˜ì • ê¶Œì¥:**
```python
# GPU Tensorë¥¼ CPUë¡œ ëª…ì‹œì ìœ¼ë¡œ ì´ë™
audio_np = audio.squeeze().cpu().numpy()
inputs = self.processor(
    audio_np,
    sampling_rate=16000,
    return_tensors="pt"
)
```

---

### ğŸŸ¡ **ì¤‘ê°„ ì´ìŠˆ 3: ê²½ë¡œ ë¬¸ìì—´ vs Path ê°ì²´ í˜¼ìš©**

**ìœ„ì¹˜:** `stt_engine.py` ë¼ì¸ 68-71, `api_server.py` ë¼ì¸ 19

```python
# api_server.py
model_path = Path(__file__).parent / "models" / "openai_whisper-large-v3-turbo"
stt = WhisperSTT(str(model_path), device=device)  # Pathë¥¼ ë¬¸ìì—´ë¡œ ë³€í™˜

# stt_engine.py
def __init__(self, model_path: str, device: str = "cpu"):
    model_path = str(auto_extract_model_if_needed(  # ë‹¤ì‹œ Pathë¡œ ë³€í™˜ í›„ ë¬¸ìì—´ë¡œ
        Path(model_path).parent
    ))
```

**ë¬¸ì œì :**
- Path â†” str ë³€í™˜ì´ ë°˜ë³µë¨
- í•¨ìˆ˜ ì¸í„°í˜ì´ìŠ¤ê°€ ì¼ê´€ì„± ì—†ìŒ

**ê¶Œì¥:**
- í•¨ìˆ˜ ì‹œê·¸ë‹ˆì²˜ë¥¼ `Union[str, Path]` íƒ€ì…íŒíŠ¸ë¡œ ëª…ì‹œ
- ë˜ëŠ” Path ê°ì²´ë¡œ í†µì¼

---

### ğŸŸ¡ **ì¤‘ê°„ ì´ìŠˆ 4: resampler Tensor ë©”ëª¨ë¦¬ ìœ„ì¹˜ ë¶ˆëª…í™•**

**ìœ„ì¹˜:** `stt_engine.py` ë¼ì¸ 103-105

```python
if sr != 16000:
    print(f"ğŸ”„ ìƒ˜í”Œë§ ë ˆì´íŠ¸ ë³€í™˜: {sr}Hz -> 16000Hz")
    resampler = torchaudio.transforms.Resample(sr, 16000)  # âŒ device ëª…ì‹œ ì—†ìŒ
    audio = resampler(audio)  # audioê°€ ì–´ë””ì—? GPU? CPU?
```

**ë¬¸ì œì :**
- `Resample` transformì´ ì–´ëŠ deviceì—ì„œ ì‹¤í–‰ë ì§€ ëª…í™•í•˜ì§€ ì•ŠìŒ
- audioê°€ GPUì— ìˆìœ¼ë©´ resamplerë„ ê°™ì€ device í•„ìš”

**ìˆ˜ì • ê¶Œì¥:**
```python
if sr != 16000:
    resampler = torchaudio.transforms.Resample(sr, 16000).to(self.device)
    audio = resampler(audio.to(self.device))
```

---

### ğŸŸ¡ **ì¤‘ê°„ ì´ìŠˆ 5: model_manager.pyì—ì„œ import ìœ„ì¹˜ ë¬¸ì œ**

**ìœ„ì¹˜:** `model_manager.py` ë¼ì¸ 194

```python
def download_from_s3(self, bucket: str, ...):
    try:
        import boto3  # âŒ í•¨ìˆ˜ ë‚´ë¶€ import
```

**ë¬¸ì œì :**
- boto3ë¥¼ í•¨ìˆ˜ ë‚´ë¶€ì—ì„œ import
- ëª¨ë“ˆ ë¡œë“œ ì‹œê°„ ì§€ì—°
- ì½”ë“œ ìƒë‹¨ì—ì„œ ì„ íƒì  importê°€ ë” ë‚˜ìŒ

**ê¶Œì¥:**
```python
try:
    import boto3
    HAS_BOTO3 = True
except ImportError:
    HAS_BOTO3 = False

# í•¨ìˆ˜ì—ì„œ:
if not HAS_BOTO3:
    print("âŒ boto3ê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤")
    return False
```

---

### ğŸŸ¢ **ê²½ë¯¸í•œ ì´ìŠˆ: vllm_client.py ì„ íƒì  ì„í¬íŠ¸ ëˆ„ë½**

**ìœ„ì¹˜:** `api_server.py` ë¼ì¸ 11-12

```python
from vllm_client import VLLMClient, VLLMConfig

try:
    # ...
    vllm_client = VLLMClient(VLLMConfig())  # requests ì„í¬íŠ¸ ì˜¤ë¥˜ ì‹œ ì‹¤íŒ¨
except Exception as e:
```

**ê¶Œì¥:** vllm_client.pyì—ì„œ requests ì„í¬íŠ¸ë¥¼ ì„ íƒì ìœ¼ë¡œ ì²˜ë¦¬

---

## ğŸ“‹ ìˆ˜ì • ì²´í¬ë¦¬ìŠ¤íŠ¸

### ìš°ì„ ìˆœìœ„: ë†’ìŒ
- [ ] auto_extract_model_if_needed() ê²½ë¡œ ë¡œì§ ì •ë¦¬
- [ ] transcribe()ì—ì„œ audio.cpu().numpy() ëª…ì‹œ
- [ ] Resample transformì˜ device ëª…ì‹œ

### ìš°ì„ ìˆœìœ„: ì¤‘ê°„
- [ ] Path/str íƒ€ì…íŒíŠ¸ í†µì¼
- [ ] boto3 ì„ íƒì  import ìœ„ì¹˜ ë³€ê²½
- [ ] vllm_client requests import ì˜¤ë¥˜ ì²˜ë¦¬

### ìš°ì„ ìˆœìœ„: ë‚®ìŒ
- [ ] ì½”ë“œ ì£¼ì„ ë³´ì¶©
- [ ] Error ë©”ì‹œì§€ ëª…í™•í™”

---

## âœ… ì •ìƒì¸ ë¶€ë¶„

âœ… íŒŒì¼ ì„ì‹œ ì €ì¥ ë° ì‚­ì œ ë¡œì§ (api_server.py)
âœ… ìŒì„± í¬ë§· ì§€ì› ë£¨í”„ (test_stt í•¨ìˆ˜)
âœ… ëª¨ë¸ ì´ˆê¸°í™” try-except ì²˜ë¦¬
âœ… ìŒì„± ëª¨ë…¸ ë³€í™˜ ë¡œì§
âœ… tar ì••ì¶•/í•´ì œ ë¡œì§
âœ… Model Manager CLI êµ¬ì¡°

---

## ğŸ”§ ê¶Œì¥ ìˆ˜ì •ì‚¬í•­ (ìš°ì„ ìˆœìœ„ ìˆœ)
