#!/usr/bin/env python3
"""
EC2 ëª¨ë¸ ë¬¸ì œ ì§„ë‹¨ ë° ìë™ ìˆ˜ì • ë„êµ¬

ì˜¤ë¥˜: RuntimeError: Unable to open file 'model.bin' in model '/app/models/openai_whisper-large-v3-turbo'

ì´ ìŠ¤í¬ë¦½íŠ¸ëŠ”:
1. ëª¨ë¸ ë””ë ‰í† ë¦¬ êµ¬ì¡° í™•ì¸
2. model.bin íŒŒì¼ ìœ„ì¹˜ íŒŒì•…
3. í•„ìš”í•˜ë©´ ìë™ìœ¼ë¡œ ì‹¬ë§í¬/ë³µì‚¬ ìƒì„±
4. faster-whisper ë¡œë“œ í…ŒìŠ¤íŠ¸
"""

import sys
from pathlib import Path
import shutil

def diagnose_model(model_dir):
    """ëª¨ë¸ ë””ë ‰í† ë¦¬ ì§„ë‹¨"""
    
    print("=" * 70)
    print("ğŸ” ëª¨ë¸ ë””ë ‰í† ë¦¬ ì§„ë‹¨")
    print("=" * 70)
    print()
    
    model_path = Path(model_dir)
    
    if not model_path.exists():
        print(f"âŒ ëª¨ë¸ ë””ë ‰í† ë¦¬ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {model_dir}")
        return False
    
    print(f"ğŸ“ ëª¨ë¸ ë””ë ‰í† ë¦¬: {model_path}")
    print()
    
    # 1. ìµœìƒìœ„ íŒŒì¼ í™•ì¸
    print("ğŸ“‚ ìµœìƒìœ„ íŒŒì¼:")
    top_files = list(model_path.glob("*"))
    if not top_files:
        print("   (íŒŒì¼ ì—†ìŒ)")
    else:
        for f in sorted(top_files):
            if f.is_file():
                size_mb = f.stat().st_size / (1024**2)
                if f.name == "model.bin" or f.is_symlink():
                    target = f.resolve() if f.is_symlink() else "íŒŒì¼"
                    print(f"   {'ğŸ”—' if f.is_symlink() else 'ğŸ“„'} {f.name} ({size_mb:.2f}MB)")
                    if f.is_symlink():
                        print(f"      â†’ {target.name}")
                else:
                    print(f"   ğŸ“„ {f.name} ({size_mb:.2f}MB)")
            elif f.is_dir():
                item_count = len(list(f.iterdir()))
                print(f"   ğŸ“ {f.name}/ ({item_count} items)")
    
    # 2. model.bin ìœ„ì¹˜ íŒŒì•…
    print()
    print("ğŸ” model.bin íŒŒì¼ ê²€ìƒ‰:")
    
    model_bins = list(model_path.rglob("model.bin"))
    if model_bins:
        print(f"   âœ… {len(model_bins)}ê°œ ë°œê²¬:")
        for bin_file in model_bins:
            rel_path = bin_file.relative_to(model_path)
            size_mb = bin_file.stat().st_size / (1024**2)
            print(f"      - {rel_path} ({size_mb:.2f}MB)")
    else:
        print("   âŒ model.bin íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
        
        # ë‹¤ë¥¸ .bin íŒŒì¼ í™•ì¸
        other_bins = list(model_path.rglob("*.bin"))
        if other_bins:
            print()
            print(f"   ë‹¤ë¥¸ .bin íŒŒì¼ ë°œê²¬ ({len(other_bins)}ê°œ):")
            for bin_file in other_bins:
                rel_path = bin_file.relative_to(model_path)
                size_mb = bin_file.stat().st_size / (1024**2)
                print(f"      - {rel_path} ({size_mb:.2f}MB)")
            
            return False  # ìˆ˜ì • í•„ìš”
    
    # 3. ctranslate2_model ë””ë ‰í† ë¦¬ í™•ì¸
    print()
    print("ğŸ” ctranslate2_model ë””ë ‰í† ë¦¬:")
    
    ct2_dir = model_path / "ctranslate2_model"
    if ct2_dir.exists():
        ct2_files = list(ct2_dir.glob("*"))
        print(f"   âœ… ë°œê²¬ ({len(ct2_files)} items):")
        for f in sorted(ct2_files)[:10]:  # ì²˜ìŒ 10ê°œë§Œ í‘œì‹œ
            if f.is_file():
                size_mb = f.stat().st_size / (1024**2)
                print(f"      - {f.name} ({size_mb:.2f}MB)")
            else:
                print(f"      ğŸ“ {f.name}/")
        if len(ct2_files) > 10:
            print(f"      ... and {len(ct2_files) - 10} more")
    else:
        print("   âŒ ctranslate2_model ë””ë ‰í† ë¦¬ê°€ ì—†ìŠµë‹ˆë‹¤")
        print("   ë³€í™˜ì´ í•„ìš”í•©ë‹ˆë‹¤. ìœ„ì˜ ìŠ¤í¬ë¦½íŠ¸ë¥¼ ì‹¤í–‰í•˜ì„¸ìš”.")
    
    print()
    return True

def fix_model(model_dir):
    """model.bin ìë™ ìˆ˜ì • (ìƒëŒ€ ê²½ë¡œ ì‹¬ë§í¬ ì‚¬ìš©)"""
    
    print("=" * 70)
    print("ğŸ”§ model.bin íŒŒì¼ ìë™ ìˆ˜ì •")
    print("=" * 70)
    print()
    
    model_path = Path(model_dir)
    
    # 1. ê¸°ì¡´ model.bin ì œê±°
    existing_bin = model_path / "model.bin"
    if existing_bin.exists() or existing_bin.is_symlink():
        try:
            existing_bin.unlink()
            print(f"âœ… ê¸°ì¡´ model.bin ì œê±°ë¨")
        except Exception as e:
            print(f"âš ï¸  ê¸°ì¡´ íŒŒì¼ ì‚­ì œ ì‹¤íŒ¨: {e}")
    
    # 2. ctranslate2_modelì—ì„œ .bin íŒŒì¼ ì°¾ê¸°
    ct2_dir = model_path / "ctranslate2_model"
    bin_files = list(ct2_dir.glob("*.bin")) if ct2_dir.exists() else []
    
    if not bin_files:
        print("âŒ ctranslate2_model ë””ë ‰í† ë¦¬ì—ì„œ .bin íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
        return False
    
    # 3. ì²« ë²ˆì§¸ .bin íŒŒì¼ì„ model.binìœ¼ë¡œ ìƒì„± (ìƒëŒ€ ê²½ë¡œ ì‚¬ìš©)
    src_bin = sorted(bin_files)[0]
    
    try:
        # ìƒëŒ€ ê²½ë¡œ ì‹¬ë§í¬ ìƒì„± (Docker/ìš´ì˜ ì„œë²„ í˜¸í™˜)
        relative_path = src_bin.relative_to(model_path)
        existing_bin.symlink_to(relative_path)
        print(f"âœ… ìƒëŒ€ ê²½ë¡œ ì‹¬ë§í¬ ìƒì„± ì„±ê³µ")
        print(f"   ìƒëŒ€ ê²½ë¡œ: {relative_path}")
        print(f"   ëŒ€ìƒ: model.bin")
        print(f"   (Docker: /app/models â†’ ìš´ì˜: /data/modelsì—ì„œë„ ì‘ë™)")
    except Exception as e:
        # ì‹¬ë§í¬ ì‹¤íŒ¨ ì‹œ íŒŒì¼ ë³µì‚¬
        print(f"âš ï¸  ì‹¬ë§í¬ ì‹¤íŒ¨: {e}")
        print(f"   íŒŒì¼ ë³µì‚¬ë¡œ ëŒ€ì²´í•©ë‹ˆë‹¤...")
        
        try:
            shutil.copy2(src_bin, existing_bin)
            print(f"âœ… íŒŒì¼ ë³µì‚¬ ì™„ë£Œ")
            size_mb = existing_bin.stat().st_size / (1024**2)
            print(f"   í¬ê¸°: {size_mb:.2f}MB")
        except Exception as copy_e:
            print(f"âŒ íŒŒì¼ ë³µì‚¬ ì‹¤íŒ¨: {copy_e}")
            return False
    
    print()
    return True

def test_model_load(model_dir):
    """model.bin íŒŒì¼ë¡œ faster-whisper ë¡œë“œ í…ŒìŠ¤íŠ¸"""
    
    print("=" * 70)
    print("âœ… faster-whisper ëª¨ë¸ ë¡œë“œ í…ŒìŠ¤íŠ¸")
    print("=" * 70)
    print()
    
    try:
        from faster_whisper import WhisperModel
        
        model_path = Path(model_dir) / "ctranslate2_model"
        
        print(f"â³ ëª¨ë¸ ë¡œë“œ ì¤‘... (ì´ ë‹¨ê³„ëŠ” 1-2ë¶„ ê±¸ë¦´ ìˆ˜ ìˆìŠµë‹ˆë‹¤)")
        print()
        
        model = WhisperModel(
            model_size_or_path=str(model_path),
            device="cpu",
            compute_type="float32"
        )
        
        print("âœ… ëª¨ë¸ ë¡œë“œ ì„±ê³µ!")
        print()
        print("ğŸ“‹ ëª¨ë¸ ì •ë³´:")
        print(f"   íƒ€ì…: Whisper Large-v3-Turbo (CTranslate2)")
        print(f"   ë””ë°”ì´ìŠ¤: CPU")
        print(f"   Compute Type: FP32")
        print()
        
        # ìƒ˜í”Œ ì˜¤ë””ì˜¤ í…ŒìŠ¤íŠ¸
        sample_dir = Path(model_dir).parent / "audio" / "samples"
        if sample_dir.exists():
            sample_file = sample_dir / "short_0.5s.wav"
            if sample_file.exists():
                print(f"â³ ìƒ˜í”Œ ì˜¤ë””ì˜¤ ì¶”ë¡  í…ŒìŠ¤íŠ¸... ({sample_file.name})")
                segments, info = model.transcribe(str(sample_file), language="ko")
                list(segments)  # consume generator
                print(f"âœ… ì¶”ë¡  ì„±ê³µ")
                print()
        
        return True
        
    except ImportError:
        print("âŒ faster-whisperë¥¼ ì„¤ì¹˜í•˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤")
        print("   ì„¤ì¹˜: pip install faster-whisper")
        return False
    except Exception as e:
        print(f"âŒ ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {e}")
        return False

def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    
    if len(sys.argv) > 1:
        model_dir = sys.argv[1]
    else:
        # ê¸°ë³¸ ê²½ë¡œ
        model_dir = Path(__file__).parent / "models" / "openai_whisper-large-v3-turbo"
    
    print()
    print("ğŸ” EC2 STT Engine ëª¨ë¸ ì§„ë‹¨ ë° ìë™ ìˆ˜ì •")
    print()
    
    # 1. ì§„ë‹¨
    if not diagnose_model(model_dir):
        print()
        print("âš ï¸  ì§„ë‹¨ ì™„ë£Œ - ëª¨ë¸ êµ¬ì¡° ë¬¸ì œ ë°œê²¬")
        print()
        
        # 2. ìë™ ìˆ˜ì • ì‹œë„
        if fix_model(model_dir):
            print()
            print("âœ… model.bin íŒŒì¼ì´ ìˆ˜ì •ë˜ì—ˆìŠµë‹ˆë‹¤")
        else:
            print()
            print("âŒ ìë™ ìˆ˜ì • ì‹¤íŒ¨")
            print()
            print("ğŸ’¡ ìˆ˜ë™ í•´ê²° ë°©ë²•:")
            print("   1. ëª¨ë¸ ì¬ë‹¤ìš´ë¡œë“œ:")
            print("      python download_model_hf.py")
            print()
            print("   2. ë˜ëŠ” CTranslate2 ìˆ˜ë™ ë³€í™˜:")
            print("      ct2-transformers-converter --model openai/whisper-large-v3-turbo \\")
            print("        --output_dir models/openai_whisper-large-v3-turbo/ctranslate2_model --force")
            print()
            return 1
    
    print()
    
    # 3. ëª¨ë¸ ë¡œë“œ í…ŒìŠ¤íŠ¸
    if test_model_load(model_dir):
        print()
        print("=" * 70)
        print("âœ¨ ëª¨ë“  í…ŒìŠ¤íŠ¸ ì™„ë£Œ! ëª¨ë¸ ì¤€ë¹„ ì™„ë£Œ!")
        print("=" * 70)
        print()
        return 0
    else:
        print()
        print("=" * 70)
        print("âŒ ëª¨ë¸ ë¡œë“œ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨")
        print("=" * 70)
        print()
        return 1

if __name__ == "__main__":
    sys.exit(main())
