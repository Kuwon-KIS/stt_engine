#!/bin/bash

################################################################################
#
# ğŸ“¦ STT Engine ëª¨ë¸ ë‹¤ìš´ë¡œë“œ & ê²€ì¦ ìŠ¤í¬ë¦½íŠ¸ (AWS EC2 RHEL 8.9)
#
# ëª©ì : ëª¨ë¸ ë‹¤ìš´ë¡œë“œ, CTranslate2 ë³€í™˜, ë¡œë“œ í…ŒìŠ¤íŠ¸ (Docker ì´ë¯¸ì§€ ë¹Œë“œ ì œì™¸)
# ì‚¬ìš©: bash scripts/build-server-models.sh
# ê²°ê³¼: models/ ë””ë ‰í† ë¦¬ (2.5GB), ê²€ì¦ ì™„ë£Œ
#
# ì†Œìš”ì‹œê°„: 50~90ë¶„ (Python í™˜ê²½ í¬í•¨)
#
# ì„ í–‰ì¡°ê±´:
#   1. Docker ì´ë¯¸ì§€ ë¹Œë“œ ì™„ë£Œ: stt-engine:cuda129-rhel89-v1.2
#   2. RHEL 8.9 EC2 ì¸ìŠ¤í„´ìŠ¤
#   3. ì¸í„°ë„· ì—°ê²°
#
################################################################################

set -e

# ============================================================================
# ì„¤ì •
# ============================================================================

WORKSPACE="${PWD}"
OUTPUT_DIR="${WORKSPACE}/build/output"
BUILD_LOG="/tmp/build-models-$(date +%Y%m%d-%H%M%S).log"

# ë²„ì „ ì •ë³´
IMAGE_TAG="stt-engine:cuda129-rhel89-v1.2"
PYTHON_BIN="python3.11"

# íƒ€ì´ë¨¸
START_TIME=$(date +%s)

# ============================================================================
# ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜
# ============================================================================

log_header() {
    local msg="$1"
    echo ""
    echo "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"
    echo "  $msg"
    echo "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"
    echo "$msg" >> "$BUILD_LOG"
}

log_step() {
    local step_num="$1"
    local step_name="$2"
    echo ""
    echo "ğŸ“Œ Step $step_num: $step_name"
    echo "[$(date '+%Y-%m-%d %H:%M:%S')] Step $step_num: $step_name" >> "$BUILD_LOG"
}

log_success() {
    echo "âœ… $1"
    echo "[SUCCESS] $1" >> "$BUILD_LOG"
}

log_warn() {
    echo "âš ï¸  $1"
    echo "[WARN] $1" >> "$BUILD_LOG"
}

log_error() {
    echo "âŒ $1"
    echo "[ERROR] $1" >> "$BUILD_LOG"
    exit 1
}

log_info() {
    echo "â„¹ï¸  $1"
    echo "[INFO] $1" >> "$BUILD_LOG"
}

print_elapsed() {
    local end_time=$(date +%s)
    local elapsed=$((end_time - START_TIME))
    local hours=$((elapsed / 3600))
    local minutes=$(((elapsed % 3600) / 60))
    local seconds=$((elapsed % 60))
    printf "â±ï¸  ê²½ê³¼ì‹œê°„: %02dh %02dm %02ds\n" $hours $minutes $seconds
}

# ============================================================================
# í™˜ê²½ í™•ì¸
# ============================================================================

check_prerequisites() {
    log_step 0 "ì‚¬ì „ í™•ì¸"
    
    # Docker í™•ì¸
    if ! command -v docker &> /dev/null; then
        log_error "Dockerê°€ ì„¤ì¹˜ë˜ì–´ ìˆì§€ ì•ŠìŠµë‹ˆë‹¤"
    fi
    log_success "Docker ì„¤ì¹˜ í™•ì¸"
    
    # Docker ì´ë¯¸ì§€ í™•ì¸
    if ! docker images --format "{{.Repository}}:{{.Tag}}" | grep -q "^$IMAGE_TAG$"; then
        log_error "Docker ì´ë¯¸ì§€ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: $IMAGE_TAG"
    fi
    log_success "Docker ì´ë¯¸ì§€ í™•ì¸: $IMAGE_TAG"
    
    # ë””ìŠ¤í¬ ê³µê°„ í™•ì¸ (50GB)
    available=$(df "$WORKSPACE" | tail -1 | awk '{print $4}')
    if [ "$available" -lt 51200000 ]; then
        log_warn "ë””ìŠ¤í¬ ê³µê°„ ë¶€ì¡± (í•„ìš”: 50GB, í˜„ì¬: $(($available / 1024 / 1024))GB)"
    else
        log_success "ë””ìŠ¤í¬ ê³µê°„ í™•ì¸: $(($available / 1024 / 1024))GB"
    fi
    
    # ì¸í„°ë„· ì—°ê²° í™•ì¸
    if ! ping -c 1 8.8.8.8 &> /dev/null 2>&1; then
        log_error "ì¸í„°ë„· ì—°ê²°ì´ ì—†ìŠµë‹ˆë‹¤"
    fi
    log_success "ì¸í„°ë„· ì—°ê²° í™•ì¸: OK"
}

# ============================================================================
# Python í™˜ê²½ ì„¤ì • (í™˜ê²½ ì²´í¬ í¬í•¨)
# ============================================================================

setup_python_environment() {
    log_step 1 "Python í™˜ê²½ ì„¤ì • (5~15ë¶„)"
    
    # Python í™•ì¸
    if ! command -v $PYTHON_BIN &> /dev/null; then
        log_error "Python 3.11ì´ ì„¤ì¹˜ë˜ì–´ ìˆì§€ ì•ŠìŠµë‹ˆë‹¤"
    fi
    log_success "Python 3.11 í™•ì¸"
    
    # ============================================================================
    # 1. pip í™•ì¸ ë° ì„¤ì¹˜
    # ============================================================================
    
    log_info "pip í™•ì¸ ì¤‘..."
    if ! $PYTHON_BIN -m pip --version &>/dev/null; then
        log_warn "pipì´ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ì„¤ì¹˜ ì¤‘..."
        
        # RHEL/CentOS ì‹œë„
        if command -v yum &> /dev/null; then
            log_info "yumìœ¼ë¡œ python3.11-pip ì„¤ì¹˜ ì¤‘..."
            sudo yum install -y python3.11-pip || true
        fi
        
        # ì—¬ì „íˆ ì—†ìœ¼ë©´ ensurepip ì‚¬ìš©
        if ! $PYTHON_BIN -m pip --version &>/dev/null; then
            log_info "ensurepipë¡œ pip ì„¤ì¹˜ ì¤‘..."
            $PYTHON_BIN -m ensurepip --upgrade
        fi
    fi
    
    pip_version=$($PYTHON_BIN -m pip --version | awk '{print $2}')
    log_success "pip í™•ì¸: v$pip_version"
    
    # ============================================================================
    # 2. ì´ë¯¸ ì„¤ì¹˜ëœ íŒ¨í‚¤ì§€ í™•ì¸
    # ============================================================================
    
    log_info "ì„¤ì¹˜ëœ íŒ¨í‚¤ì§€ í™•ì¸ ì¤‘..."
    
    # í•µì‹¬ íŒ¨í‚¤ì§€ ëª©ë¡ (í˜¸í™˜ì„± ë²„ì „)
    declare -A packages=(
        ["torch"]="torch==2.6.0"
        ["torchaudio"]="torchaudio==2.6.0"
        ["transformers"]="transformers>=4.37.0"
        ["ctranslate2"]="ctranslate2>=4.0.0,<5.0.0"
        ["faster_whisper"]="faster-whisper>=0.10.0,<1.0.0"
        ["huggingface_hub"]="huggingface-hub>=0.20.0"
    )
    
    missing_packages=()
    
    for pkg_import in "${!packages[@]}"; do
        if ! $PYTHON_BIN -c "import $pkg_import" 2>/dev/null; then
            missing_packages+=("${packages[$pkg_import]}")
        fi
    done
    
    if [ ${#missing_packages[@]} -eq 0 ]; then
        log_success "ëª¨ë“  í•„ìˆ˜ íŒ¨í‚¤ì§€ ì´ë¯¸ ì„¤ì¹˜ë¨"
        return 0
    fi
    
    # ============================================================================
    # 3. pip ì—…ê·¸ë ˆì´ë“œ
    # ============================================================================
    
    log_info "pip ì—…ê·¸ë ˆì´ë“œ ì¤‘..."
    $PYTHON_BIN -m pip install --upgrade pip setuptools wheel -q 2>&1 | grep -v "already satisfied" || true
    
    # ============================================================================
    # 4. ëˆ„ë½ëœ íŒ¨í‚¤ì§€ ì„¤ì¹˜
    # ============================================================================
    
    log_warn "ëˆ„ë½ëœ íŒ¨í‚¤ì§€: ${missing_packages[*]}"
    log_info "íŒ¨í‚¤ì§€ ì„¤ì¹˜ ì¤‘... (5~15ë¶„ ì†Œìš”)"
    
    # í•µì‹¬ ë¼ì´ë¸ŒëŸ¬ë¦¬ ë¨¼ì € ì„¤ì¹˜
    $PYTHON_BIN -m pip install --upgrade -q \
        setuptools wheel urllib3 requests
    
    # PyTorch ì„¤ì¹˜ (ì˜¤ë˜ ê±¸ë¦¼)
    log_info "PyTorch ì„¤ì¹˜ ì¤‘... (3~8ë¶„)"
    $PYTHON_BIN -m pip install --upgrade -q \
        torch==2.6.0 torchaudio==2.6.0
    
    # ëª¨ë¸ ì²˜ë¦¬ ë¼ì´ë¸ŒëŸ¬ë¦¬
    log_info "ëª¨ë¸ ì²˜ë¦¬ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„¤ì¹˜ ì¤‘..."
    $PYTHON_BIN -m pip install --upgrade -q \
        'transformers>=4.37.0' 'ctranslate2>=4.0.0,<5.0.0' 'faster-whisper>=0.10.0,<1.0.0' \
        'huggingface-hub>=0.20.0' scipy numpy librosa pydantic 2>&1 | tail -3
    
    log_success "Python íŒ¨í‚¤ì§€ ì„¤ì¹˜ ì™„ë£Œ"
}

# ============================================================================
# Step 2: ëª¨ë¸ ë‹¤ìš´ë¡œë“œ ë° ë³€í™˜ (20~30ë¶„)
# ============================================================================

download_models() {
    log_step 2 "ëª¨ë¸ ë‹¤ìš´ë¡œë“œ ë° CTranslate2 ë³€í™˜ (20~30ë¶„)"
    
    if [ ! -f "$WORKSPACE/download_model_hf.py" ]; then
        log_error "download_model_hf.pyë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤"
    fi
    
    # ëª¨ë¸ ë””ë ‰í† ë¦¬ ì´ˆê¸°í™” (ì„ íƒì‚¬í•­)
    if [ -d "$WORKSPACE/models" ]; then
        log_warn "ê¸°ì¡´ ëª¨ë¸ ë””ë ‰í† ë¦¬ê°€ ìˆìŠµë‹ˆë‹¤"
        log_info "ì˜µì…˜:"
        log_info "  1. ê¸°ì¡´ ëª¨ë¸ ì‚¬ìš© (ì—”í„° ëˆ„ë¥´ê¸°)"
        log_info "  2. ìƒˆë¡œ ë‹¤ìš´ë¡œë“œ (rebuild ì…ë ¥)"
        
        read -p "ì„ íƒ (ê¸°ë³¸: ì‚¬ìš©): " choice
        
        if [ "$choice" = "rebuild" ]; then
            log_info "ê¸°ì¡´ ëª¨ë¸ ë””ë ‰í† ë¦¬ ì‚­ì œ ì¤‘..."
            rm -rf "$WORKSPACE/models" || true
        else
            log_info "ê¸°ì¡´ ëª¨ë¸ ì‚¬ìš©"
            # ëª¨ë¸ ê²€ì¦ë§Œ ìˆ˜í–‰
            validate_models
            return 0
        fi
    fi
    
    mkdir -p "$WORKSPACE/models"
    
    # ëª¨ë¸ ë‹¤ìš´ë¡œë“œ ë° ë³€í™˜ ì‹¤í–‰
    log_info "ëª¨ë¸ ë‹¤ìš´ë¡œë“œ ë° ë³€í™˜ ì‹¤í–‰ ì¤‘..."
    cd "$WORKSPACE"
    $PYTHON_BIN download_model_hf.py 2>&1 | tee -a "$BUILD_LOG"
    
    # ëª¨ë¸ ë””ë ‰í† ë¦¬ ê²€ì¦
    if [ ! -d "$WORKSPACE/models/ctranslate2_model" ]; then
        log_error "CTranslate2 ëª¨ë¸ ë³€í™˜ ì‹¤íŒ¨"
    fi
    
    if [ ! -d "$WORKSPACE/models/openai_whisper-large-v3-turbo" ]; then
        log_warn "OpenAI Whisper ëª¨ë¸ ë‹¤ìš´ë¡œë“œ ì™„ë£Œë˜ì§€ ì•ŠìŒ (ê³„ì† ì§„í–‰)"
    fi
    
    local models_size=$(du -sh "$WORKSPACE/models" | awk '{print $1}')
    log_success "ëª¨ë¸ ë‹¤ìš´ë¡œë“œ ë° ë³€í™˜ ì™„ë£Œ (í¬ê¸°: $models_size)"
    print_elapsed
}

# ============================================================================
# Step 3: ëª¨ë¸ ê²€ì¦
# ============================================================================

validate_models() {
    log_step 3 "ëª¨ë¸ êµ¬ì¡° ê²€ì¦"
    
    log_info "ëª¨ë¸ íŒŒì¼ êµ¬ì¡° í™•ì¸ ì¤‘..."
    $PYTHON_BIN << 'PYTHON_TEST'
from pathlib import Path
import sys

models_base = Path("models")
all_valid = True

print("\n" + "=" * 70)
print("ğŸ” ëª¨ë¸ êµ¬ì¡° ê²€ì¦")
print("=" * 70)

# CTranslate2 ëª¨ë¸ í™•ì¸
print("\nğŸ“‚ CTranslate2 ëª¨ë¸")
ct2_model = models_base / "ctranslate2_model"
required_files = {
    "config.json": "ì„¤ì • íŒŒì¼",
    "model.bin": "ëª¨ë¸ ê°€ì¤‘ì¹˜",
    "vocabulary.json": "í† í¬ë‚˜ì´ì € ì–´íœ˜"
}

for fname, desc in required_files.items():
    fpath = ct2_model / fname
    if fpath.exists():
        size = fpath.stat().st_size / (1024 * 1024)
        print(f"   âœ… {fname:20} ({size:6.1f} MB) - {desc}")
    else:
        print(f"   âŒ {fname:20} NOT FOUND")
        all_valid = False

# OpenAI Whisper ëª¨ë¸ í™•ì¸
print("\nğŸ“‚ OpenAI Whisper ëª¨ë¸")
whisper_model = models_base / "openai_whisper-large-v3-turbo"
required_whisper_files = {
    "config.json": "ì„¤ì • íŒŒì¼",
    "pytorch_model.bin": "ëª¨ë¸ ê°€ì¤‘ì¹˜",
    "tokenizer.json": "í† í¬ë‚˜ì´ì €"
}

for fname, desc in required_whisper_files.items():
    fpath = whisper_model / fname
    if fpath.exists():
        size = fpath.stat().st_size / (1024 * 1024)
        print(f"   âœ… {fname:25} ({size:6.1f} MB) - {desc}")
    else:
        print(f"   âŒ {fname:25} NOT FOUND")
        all_valid = False

print("\n" + "=" * 70)

if all_valid:
    print("âœ… ëª¨ë“  ëª¨ë¸ íŒŒì¼ ê²€ì¦ ì™„ë£Œ!")
    sys.exit(0)
else:
    print("âŒ ì¼ë¶€ ëª¨ë¸ íŒŒì¼ì´ ëˆ„ë½ë˜ì—ˆìŠµë‹ˆë‹¤")
    sys.exit(1)

PYTHON_TEST
    
    if [ $? -ne 0 ]; then
        log_error "ëª¨ë¸ ê²€ì¦ ì‹¤íŒ¨"
    fi
    
    log_success "ëª¨ë¸ êµ¬ì¡° ê²€ì¦ ì™„ë£Œ"
}

# ============================================================================
# Step 4: ëª¨ë¸ ë¡œë“œ í…ŒìŠ¤íŠ¸ (20~30ë¶„)
# ============================================================================

test_model_loading() {
    log_step 4 "Docker ì»¨í…Œì´ë„ˆì—ì„œ ëª¨ë¸ ë¡œë“œ í…ŒìŠ¤íŠ¸ (20~30ë¶„)"
    
    log_info "í…ŒìŠ¤íŠ¸ìš© ì»¨í…Œì´ë„ˆ ì‹œì‘ ì¤‘..."
    
    # ê¸°ì¡´ ì»¨í…Œì´ë„ˆ ì •ë¦¬
    docker rm stt-test-engine 2>/dev/null || true
    
    # ì»¨í…Œì´ë„ˆ ì‹œì‘
    docker run -d \
        --name stt-test-engine \
        -v "$WORKSPACE/models:/app/models" \
        -e CUDA_VISIBLE_DEVICES=0 \
        "$IMAGE_TAG" \
        sleep 3600 2>&1 | tee -a "$BUILD_LOG"
    
    if ! docker ps | grep -q "stt-test-engine"; then
        log_error "í…ŒìŠ¤íŠ¸ ì»¨í…Œì´ë„ˆ ì‹œì‘ ì‹¤íŒ¨"
    fi
    
    log_success "í…ŒìŠ¤íŠ¸ ì»¨í…Œì´ë„ˆ ì‹œì‘ë¨"
    
    # ì ì‹œ ëŒ€ê¸° (ì»¨í…Œì´ë„ˆ ì´ˆê¸°í™”)
    sleep 3
    
    # CUDA & PyTorch ê²€ì¦
    log_info "CUDA & PyTorch ê²€ì¦ ì¤‘..."
    docker exec stt-test-engine python3.11 << 'PYTHON_TEST' 2>&1 | tee -a "$BUILD_LOG"
import torch
import torchaudio
import os

print("\n=== CUDA & PyTorch ê²€ì¦ ===")
print(f"âœ… PyTorch: {torch.__version__}")
print(f"âœ… torchaudio: {torchaudio.__version__}")
print(f"âœ… CUDA Available: {torch.cuda.is_available()}")
if torch.cuda.is_available():
    print(f"âœ… CUDA Device: {torch.cuda.get_device_name(0)}")
print(f"âœ… LD_LIBRARY_PATH: {bool(os.environ.get('LD_LIBRARY_PATH'))}")
PYTHON_TEST
    
    # Faster-Whisper ëª¨ë¸ ë¡œë“œ í…ŒìŠ¤íŠ¸
    log_info "Faster-Whisper ëª¨ë¸ ë¡œë“œ í…ŒìŠ¤íŠ¸ ì¤‘..."
    docker exec stt-test-engine python3.11 << 'PYTHON_TEST' 2>&1 | tee -a "$BUILD_LOG"
import sys
sys.path.insert(0, '/app')

print("\n=== Faster-Whisper ëª¨ë¸ ë¡œë“œ ===")
try:
    from faster_whisper import WhisperModel
    model = WhisperModel(
        "/app/models/ctranslate2_model",
        device="auto",
        compute_type="float32",
        local_files_only=True
    )
    print("âœ… Faster-Whisper ëª¨ë¸ ë¡œë“œ ì„±ê³µ!")
except Exception as e:
    print(f"âŒ Faster-Whisper ì˜¤ë¥˜: {type(e).__name__}: {e}")
    import traceback
    traceback.print_exc()
PYTHON_TEST
    
    # OpenAI Whisper ëª¨ë¸ ë¡œë“œ í…ŒìŠ¤íŠ¸
    log_info "OpenAI Whisper ëª¨ë¸ ë¡œë“œ í…ŒìŠ¤íŠ¸ ì¤‘..."
    docker exec stt-test-engine python3.11 << 'PYTHON_TEST' 2>&1 | tee -a "$BUILD_LOG"
import sys
sys.path.insert(0, '/app')

print("\n=== OpenAI Whisper ëª¨ë¸ ë¡œë“œ ===")
try:
    from transformers import AutoModelForSpeechSeq2Seq, AutoProcessor
    processor = AutoProcessor.from_pretrained(
        "/app/models/openai_whisper-large-v3-turbo",
        local_files_only=True
    )
    model = AutoModelForSpeechSeq2Seq.from_pretrained(
        "/app/models/openai_whisper-large-v3-turbo",
        local_files_only=True
    )
    print("âœ… OpenAI Whisper ëª¨ë¸ ë¡œë“œ ì„±ê³µ!")
except Exception as e:
    print(f"âš ï¸  OpenAI Whisper: {type(e).__name__}: {e}")
PYTHON_TEST
    
    # ì»¨í…Œì´ë„ˆ ì¢…ë£Œ
    log_info "í…ŒìŠ¤íŠ¸ ì»¨í…Œì´ë„ˆ ì¢…ë£Œ ì¤‘..."
    docker rm -f stt-test-engine 2>/dev/null || true
    
    log_success "ëª¨ë¸ ë¡œë“œ í…ŒìŠ¤íŠ¸ ì™„ë£Œ"
    print_elapsed
}

# ============================================================================
# Step 5: ê²°ê³¼ ì €ì¥ ë° ìš”ì•½
# ============================================================================

print_summary() {
    log_step "Final" "ëª¨ë¸ ì¤€ë¹„ ì™„ë£Œ"
    
    echo ""
    echo "âœ… ëª¨ë¸ ë‹¤ìš´ë¡œë“œ ë° ê²€ì¦ ì™„ë£Œ!"
    echo ""
    echo "ğŸ“Š ê²°ê³¼:"
    
    # ëª¨ë¸ í™•ì¸
    if [ -d "$WORKSPACE/models" ]; then
        local models_size=$(du -sh "$WORKSPACE/models" | awk '{print $1}')
        echo "   ëª¨ë¸ ë””ë ‰í† ë¦¬: $WORKSPACE/models"
        echo "   í¬ê¸°: $models_size"
        
        if [ -d "$WORKSPACE/models/ctranslate2_model" ]; then
            echo "   âœ… CTranslate2 ëª¨ë¸"
        fi
        
        if [ -d "$WORKSPACE/models/openai_whisper-large-v3-turbo" ]; then
            echo "   âœ… OpenAI Whisper ëª¨ë¸"
        fi
    fi
    
    echo ""
    echo "ğŸ“ ë¡œê·¸ íŒŒì¼: $BUILD_LOG"
    echo ""
    
    echo "ğŸ¯ ë‹¤ìŒ ë‹¨ê³„:"
    echo "   1. ì´ë¯¸ì§€ì™€ ëª¨ë¸ì„ ìš´ì˜ ì„œë²„ë¡œ ì „ì†¡"
    echo "   2. ìš´ì˜ ì„œë²„ì—ì„œ Docker ì´ë¯¸ì§€ ë¡œë“œ"
    echo "   3. ëª¨ë¸ ë””ë ‰í† ë¦¬ ë§ˆìš´íŠ¸í•˜ì—¬ ì»¨í…Œì´ë„ˆ ì‹¤í–‰"
    echo ""
    
    print_elapsed
}

# ============================================================================
# ì—ëŸ¬ ì²˜ë¦¬
# ============================================================================

trap 'log_error "ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜ ë°œìƒ. ë¡œê·¸ë¥¼ í™•ì¸í•˜ì„¸ìš”: $BUILD_LOG"' ERR

# ============================================================================
# ë©”ì¸ ì‹¤í–‰
# ============================================================================

main() {
    log_header "ğŸ“¦ STT Engine ëª¨ë¸ ë‹¤ìš´ë¡œë“œ & ê²€ì¦ (RHEL 8.9)"
    
    log_info "ì‘ì—…ê³µê°„: $WORKSPACE"
    log_info "ë¡œê·¸ íŒŒì¼: $BUILD_LOG"
    
    # ì‚¬ì „ í™•ì¸
    check_prerequisites
    
    # Python í™˜ê²½ ì„¤ì •
    setup_python_environment
    
    # ëª¨ë¸ ë‹¤ìš´ë¡œë“œ
    download_models
    
    # ëª¨ë¸ ê²€ì¦
    validate_models
    
    # ëª¨ë¸ ë¡œë“œ í…ŒìŠ¤íŠ¸
    test_model_loading
    
    # ìµœì¢… ìš”ì•½
    print_summary
}

# ìŠ¤í¬ë¦½íŠ¸ ì‹¤í–‰
main "$@"
