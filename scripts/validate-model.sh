#!/bin/bash

################################################################################
#
# ğŸ” STT Engine ëª¨ë¸ ê²€ì¦ ìŠ¤í¬ë¦½íŠ¸
#
# ëª©ì : Docker ì´ë¯¸ì§€ì™€ ë…ë¦½ì ìœ¼ë¡œ ëª¨ë¸ ë¡œë“œ ë° ê²€ì¦
# ì‚¬ìš©: bash scripts/validate-model.sh [ëª¨ë¸_ê²½ë¡œ] [ë²„ì „ ë˜ëŠ” ì´ë¯¸ì§€_íƒœê·¸]
# ì˜ˆì‹œ:
#   bash scripts/validate-model.sh models                      # ê¸°ë³¸: models, v1.4
#   bash scripts/validate-model.sh models v1.5                 # ë²„ì „ ì§€ì •
#   bash scripts/validate-model.sh models stt-engine:my-tag    # ì „ì²´ íƒœê·¸ ì§€ì •
#
# íŠ¹ì§•:
#   - ì´ë¯¸ì§€ ë¹Œë“œì™€ ë…ë¦½ì ìœ¼ë¡œ ì‹¤í–‰ ê°€ëŠ¥
#   - ë™ì¼í•œ ê²€ì¦ ë¡œì§ ì‚¬ìš© (ëª¨ë¸ ì¤€ë¹„, Docker í…ŒìŠ¤íŠ¸, ë¡œì»¬ í…ŒìŠ¤íŠ¸)
#   - ì»¨í…Œì´ë„ˆ ê¸°ë°˜ ë° ë¡œì»¬ ê¸°ë°˜ ê²€ì¦ ëª¨ë‘ ì§€ì›
#
################################################################################

set -e

# ============================================================================
# ì„¤ì •
# ============================================================================

WORKSPACE="${PWD}"
MODELS_PATH="${1:-.models}"

# ì´ë¯¸ì§€ íƒœê·¸ ì²˜ë¦¬ (ë²„ì „ ë˜ëŠ” ì „ì²´ íƒœê·¸)
DEFAULT_VERSION="v1.4"
VERSION_OR_TAG="${2:-$DEFAULT_VERSION}"

# ë§Œì•½ ":" í¬í•¨ì´ë©´ ì „ì²´ íƒœê·¸, ì•„ë‹ˆë©´ ë²„ì „ ë²ˆí˜¸ë¡œ ì·¨ê¸‰
if [[ "$VERSION_OR_TAG" == *":"* ]]; then
    IMAGE_TAG="$VERSION_OR_TAG"
else
    IMAGE_TAG="stt-engine:cuda129-rhel89-${VERSION_OR_TAG}"
fi

PYTHON_BIN="python3.11"

# ============================================================================
# ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜
# ============================================================================

log_header() {
    echo ""
    echo "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"
    echo "  $1"
    echo "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"
}

log_step() {
    echo ""
    echo "ğŸ“Œ $1"
}

log_success() {
    echo "âœ… $1"
}

log_error() {
    echo "âŒ $1"
    exit 1
}

log_info() {
    echo "â„¹ï¸  $1"
}

log_warn() {
    echo "âš ï¸  $1"
}

# ============================================================================
# Step 1: í™˜ê²½ í™•ì¸
# ============================================================================

check_prerequisites() {
    log_step "Step 1: ëª¨ë¸ ê²€ì¦ í™˜ê²½ í™•ì¸"
    
    # ëª¨ë¸ ë””ë ‰í† ë¦¬ í™•ì¸
    if [ ! -d "$MODELS_PATH" ]; then
        log_error "ëª¨ë¸ ë””ë ‰í† ë¦¬ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: $MODELS_PATH"
    fi
    log_success "ëª¨ë¸ ë””ë ‰í† ë¦¬ í™•ì¸: $MODELS_PATH"
    
    # Docker í™•ì¸
    if ! command -v docker &> /dev/null; then
        log_error "Dockerê°€ ì„¤ì¹˜ë˜ì–´ ìˆì§€ ì•ŠìŠµë‹ˆë‹¤"
    fi
    log_success "Docker ì„¤ì¹˜ í™•ì¸"
    
    # ì´ë¯¸ì§€ í™•ì¸
    if ! docker images --format "{{.Repository}}:{{.Tag}}" | grep -q "^$IMAGE_TAG$"; then
        log_warn "Docker ì´ë¯¸ì§€ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: $IMAGE_TAG"
        log_info "ë¡œì»¬ Pythonìœ¼ë¡œ ê²€ì¦ ì‹œë„í•©ë‹ˆë‹¤"
        USE_LOCAL_PYTHON=true
    else
        log_success "Docker ì´ë¯¸ì§€ í™•ì¸: $IMAGE_TAG"
        USE_LOCAL_PYTHON=false
    fi
}

# ============================================================================
# Step 2: ëª¨ë¸ êµ¬ì¡° ê²€ì¦
# ============================================================================

validate_model_structure() {
    log_step "Step 2: ëª¨ë¸ íŒŒì¼ êµ¬ì¡° ê²€ì¦"
    
    $PYTHON_BIN << 'PYTHON_TEST'
from pathlib import Path
import sys

models_base = Path("models")
all_valid = True

print("\n" + "=" * 70)
print("ğŸ“‚ ëª¨ë¸ êµ¬ì¡° ê²€ì¦")
print("=" * 70)

# CTranslate2 ëª¨ë¸ í™•ì¸
print("\nğŸ“‚ CTranslate2 ëª¨ë¸ (faster-whisper ì‚¬ìš©)")
ct2_model = models_base / "ctranslate2_model"
required_files = {
    "config.json": "ì„¤ì • íŒŒì¼",
    "model.bin": "ëª¨ë¸ ê°€ì¤‘ì¹˜",
    "vocabulary.json": "í† í¬ë‚˜ì´ì € ì–´íœ˜"
}

if ct2_model.exists():
    for fname, desc in required_files.items():
        fpath = ct2_model / fname
        if fpath.exists():
            size = fpath.stat().st_size / (1024 * 1024)
            print(f"   âœ… {fname:20} ({size:7.1f} MB) - {desc}")
        else:
            print(f"   âŒ {fname:20} NOT FOUND")
            all_valid = False
else:
    print(f"   âš ï¸  ctranslate2_model ë””ë ‰í† ë¦¬ ì—†ìŒ")

# OpenAI Whisper ëª¨ë¸ í™•ì¸
print("\nğŸ“‚ OpenAI Whisper ëª¨ë¸ (fallback)")
whisper_model = models_base / "openai_whisper-large-v3-turbo"
required_whisper_files = {
    "config.json": "ì„¤ì • íŒŒì¼",
    "pytorch_model.bin": "ëª¨ë¸ ê°€ì¤‘ì¹˜",
    "tokenizer.json": "í† í¬ë‚˜ì´ì €"
}

if whisper_model.exists():
    for fname, desc in required_whisper_files.items():
        fpath = whisper_model / fname
        if fpath.exists():
            size = fpath.stat().st_size / (1024 * 1024)
            print(f"   âœ… {fname:25} ({size:7.1f} MB) - {desc}")
        else:
            print(f"   âŒ {fname:25} NOT FOUND")
            all_valid = False
else:
    print(f"   âš ï¸  openai_whisper-large-v3-turbo ë””ë ‰í† ë¦¬ ì—†ìŒ")

print("\n" + "=" * 70)

if all_valid:
    print("âœ… ëª¨ë“  ëª¨ë¸ íŒŒì¼ ê²€ì¦ ì™„ë£Œ!")
    sys.exit(0)
else:
    print("âš ï¸  ì¼ë¶€ ëª¨ë¸ íŒŒì¼ì´ ëˆ„ë½ë˜ì—ˆìŠµë‹ˆë‹¤")
    sys.exit(1)

PYTHON_TEST
    
    if [ $? -ne 0 ]; then
        log_warn "ëª¨ë¸ íŒŒì¼ ê²€ì¦ ì™„ë£Œ (ëˆ„ë½ëœ íŒŒì¼ ìˆìŒ)"
    else
        log_success "ëª¨ë¸ íŒŒì¼ ê²€ì¦ ì™„ë£Œ"
    fi
}

# ============================================================================
# Step 3: Docker ì»¨í…Œì´ë„ˆ ê²€ì¦
# ============================================================================

validate_with_docker() {
    log_step "Step 3: Docker ì»¨í…Œì´ë„ˆ ê¸°ë°˜ ëª¨ë¸ ê²€ì¦"
    
    log_info "í…ŒìŠ¤íŠ¸ ì»¨í…Œì´ë„ˆ ì‹œì‘ ì¤‘..."
    
    # ê¸°ì¡´ ì»¨í…Œì´ë„ˆ ì •ë¦¬
    docker rm stt-validate 2>/dev/null || true
    
    # ì»¨í…Œì´ë„ˆ ì‹œì‘
    docker run -d \
        --name stt-validate \
        -v "$(pwd)/$MODELS_PATH:/app/models" \
        -e CUDA_VISIBLE_DEVICES=0 \
        "$IMAGE_TAG" \
        sleep 3600 >/dev/null 2>&1
    
    sleep 2
    
    if ! docker ps | grep -q "stt-validate"; then
        log_error "í…ŒìŠ¤íŠ¸ ì»¨í…Œì´ë„ˆ ì‹œì‘ ì‹¤íŒ¨"
    fi
    
    log_success "í…ŒìŠ¤íŠ¸ ì»¨í…Œì´ë„ˆ ì‹œì‘ë¨"
    
    # CUDA & PyTorch ê²€ì¦
    log_info "CUDA & PyTorch ê²€ì¦ ì¤‘..."
    docker exec stt-validate python3.11 << 'PYTHON_TEST' 2>&1 | grep -E '(PyTorch|torchaudio|CUDA|LD_)' || true
import torch
import torchaudio
import os

print(f"âœ… PyTorch: {torch.__version__}")
print(f"âœ… torchaudio: {torchaudio.__version__}")
print(f"âœ… CUDA Available: {torch.cuda.is_available()}")
if torch.cuda.is_available():
    print(f"âœ… CUDA Device: {torch.cuda.get_device_name(0)}")
print(f"âœ… LD_LIBRARY_PATH: {bool(os.environ.get('LD_LIBRARY_PATH'))}")
PYTHON_TEST
    
    # Faster-Whisper ëª¨ë¸ ë¡œë“œ í…ŒìŠ¤íŠ¸
    log_info "Faster-Whisper ëª¨ë¸ ë¡œë“œ í…ŒìŠ¤íŠ¸ ì¤‘..."
    docker exec stt-validate python3.11 << 'PYTHON_TEST' 2>&1 | tail -20
import sys
sys.path.insert(0, '/app')
import numpy as np

print("\n=== Faster-Whisper ëª¨ë¸ ê²€ì¦ ===\n")

try:
    from faster_whisper import WhisperModel
    
    print("â³ ëª¨ë¸ ë¡œë“œ ì¤‘...")
    model = WhisperModel(
        "/app/models/ctranslate2_model",
        device="auto",
        compute_type="float32",
        local_files_only=True
    )
    print("âœ… ëª¨ë¸ ë¡œë“œ ì„±ê³µ!")
    
    # ë‹¤ì–‘í•œ ê¸¸ì´ì˜ ì˜¤ë””ì˜¤ë¡œ í…ŒìŠ¤íŠ¸
    test_cases = [
        (8000, "ì§§ì€ (0.5ì´ˆ)"),
        (48000, "ì¤‘ê°„ (3ì´ˆ)"),
        (160000, "ê¸´ (10ì´ˆ)")
    ]
    
    for audio_len, desc in test_cases:
        try:
            dummy_audio = np.zeros((audio_len,), dtype=np.float32)
            segments, info = model.transcribe(dummy_audio, language="ko")
            list(segments)
            print(f"âœ… ì¶”ë¡  í…ŒìŠ¤íŠ¸ ì„±ê³µ ({desc})")
        except Exception as e:
            print(f"âš ï¸  ì¶”ë¡  í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨ ({desc}): {str(e)[:80]}")
    
    print("\nâœ… Faster-Whisper ê²€ì¦ ì™„ë£Œ!")
    
except Exception as e:
    print(f"âŒ ì˜¤ë¥˜: {type(e).__name__}: {str(e)[:200]}")
    import traceback
    traceback.print_exc()

PYTHON_TEST
    
    # ì»¨í…Œì´ë„ˆ ì¢…ë£Œ
    log_info "í…ŒìŠ¤íŠ¸ ì»¨í…Œì´ë„ˆ ì¢…ë£Œ ì¤‘..."
    docker rm -f stt-validate 2>/dev/null || true
    
    log_success "Docker ê²€ì¦ ì™„ë£Œ"
}

# ============================================================================
# Step 4: ë¡œì»¬ Python ê²€ì¦ (ì„ íƒì‚¬í•­)
# ============================================================================

validate_with_local_python() {
    log_step "Step 4: ë¡œì»¬ Python ê¸°ë°˜ ëª¨ë¸ ê²€ì¦"
    
    # pip í™•ì¸
    if ! $PYTHON_BIN -m pip --version &>/dev/null; then
        log_warn "pipê°€ ì„¤ì¹˜ë˜ì–´ ìˆì§€ ì•ŠìŠµë‹ˆë‹¤. Docker ê²€ì¦ë§Œ ìˆ˜í–‰í•©ë‹ˆë‹¤."
        return 0
    fi
    
    # faster-whisper í™•ì¸
    if ! $PYTHON_BIN -c "import faster_whisper" 2>/dev/null; then
        log_warn "faster-whisperê°€ ì„¤ì¹˜ë˜ì–´ ìˆì§€ ì•ŠìŠµë‹ˆë‹¤. ì„¤ì¹˜ ì¤‘..."
        $PYTHON_BIN -m pip install -q faster-whisper==1.2.1 2>/dev/null || true
    fi
    
    log_info "ë¡œì»¬ Faster-Whisper ëª¨ë¸ ê²€ì¦ ì¤‘..."
    
    $PYTHON_BIN << 'PYTHON_TEST' 2>&1 | tail -20
import sys
import numpy as np
from pathlib import Path

print("\n=== ë¡œì»¬ Faster-Whisper ëª¨ë¸ ê²€ì¦ ===\n")

try:
    from faster_whisper import WhisperModel
    
    models_path = Path("models")
    ct2_model = models_path / "ctranslate2_model"
    
    if not ct2_model.exists():
        print(f"âš ï¸  ëª¨ë¸ ë””ë ‰í† ë¦¬ ì—†ìŒ: {ct2_model}")
        sys.exit(0)
    
    print("â³ ëª¨ë¸ ë¡œë“œ ì¤‘...")
    model = WhisperModel(
        str(ct2_model),
        device="cpu",
        compute_type="float32",
        local_files_only=True
    )
    print("âœ… ëª¨ë¸ ë¡œë“œ ì„±ê³µ!")
    
    # ë‹¤ì–‘í•œ ê¸¸ì´ì˜ ì˜¤ë””ì˜¤ë¡œ í…ŒìŠ¤íŠ¸
    test_cases = [
        (8000, "ì§§ì€ (0.5ì´ˆ)"),
        (48000, "ì¤‘ê°„ (3ì´ˆ)"),
        (160000, "ê¸´ (10ì´ˆ)")
    ]
    
    for audio_len, desc in test_cases:
        try:
            dummy_audio = np.zeros((audio_len,), dtype=np.float32)
            segments, info = model.transcribe(dummy_audio, language="ko")
            list(segments)
            print(f"âœ… ì¶”ë¡  í…ŒìŠ¤íŠ¸ ì„±ê³µ ({desc})")
        except Exception as e:
            print(f"âš ï¸  ì¶”ë¡  í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨ ({desc}): {str(e)[:80]}")
    
    print("\nâœ… ë¡œì»¬ ê²€ì¦ ì™„ë£Œ!")
    
except Exception as e:
    print(f"âŒ ì˜¤ë¥˜: {type(e).__name__}: {str(e)[:200]}")
    import traceback
    traceback.print_exc()

PYTHON_TEST
    
    log_success "ë¡œì»¬ ê²€ì¦ ì™„ë£Œ"
}

# ============================================================================
# Step 5: ìµœì¢… ìš”ì•½
# ============================================================================

print_summary() {
    log_header "âœ… ëª¨ë¸ ê²€ì¦ ì™„ë£Œ!"
    
    echo ""
    echo "ğŸ“Š ê²€ì¦ ê²°ê³¼:"
    echo "   âœ… ëª¨ë¸ íŒŒì¼ êµ¬ì¡° ê²€ì¦ ì™„ë£Œ"
    
    if [ "$USE_LOCAL_PYTHON" = "false" ]; then
        echo "   âœ… Docker ì»¨í…Œì´ë„ˆ ê¸°ë°˜ ê²€ì¦ ì™„ë£Œ"
        echo "   â„¹ï¸  ì´ë¯¸ì§€: $IMAGE_TAG"
    else
        echo "   â„¹ï¸  Docker ì´ë¯¸ì§€ ì—†ìŒ (ë¡œì»¬ Pythonìœ¼ë¡œ ê²€ì¦)"
    fi
    
    echo ""
    echo "ğŸ“ ëª¨ë¸ ìœ„ì¹˜:"
    echo "   CTranslate2: $MODELS_PATH/ctranslate2_model"
    echo "   OpenAI Whisper: $MODELS_PATH/openai_whisper-large-v3-turbo"
    echo ""
    echo "ğŸ¯ ë‹¤ìŒ ë‹¨ê³„:"
    echo "   1. Docker ì´ë¯¸ì§€ ì‹¤í–‰:"
    echo "      docker run -v $MODELS_PATH:/app/models $IMAGE_TAG"
    echo ""
    echo "   2. ë˜ëŠ” Python ìŠ¤í¬ë¦½íŠ¸ ì‚¬ìš©:"
    echo "      python3.11 stt_engine.py"
    echo ""
}

# ============================================================================
# ë©”ì¸ ì‹¤í–‰
# ============================================================================

main() {
    log_header "ğŸ” STT Engine ëª¨ë¸ ê²€ì¦ ì‹œì‘"
    
    check_prerequisites
    validate_model_structure
    
    if [ "$USE_LOCAL_PYTHON" = "false" ]; then
        validate_with_docker
    else
        validate_with_local_python
    fi
    
    print_summary
}

main
