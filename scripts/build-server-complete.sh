#!/bin/bash

################################################################################
#
# ğŸš€ STT Engine ì™„ì „ ë¹Œë“œ & í…ŒìŠ¤íŠ¸ ìŠ¤í¬ë¦½íŠ¸ (AWS EC2 RHEL 8.9)
#
# ëª©ì : EC2 ë¹Œë“œ ì„œë²„ì—ì„œ Docker ì´ë¯¸ì§€ + ëª¨ë¸ ë‹¤ìš´ë¡œë“œ + í…ŒìŠ¤íŠ¸ ì™„ë£Œ
# ì‚¬ìš©: bash scripts/build-server-complete.sh
# ê²°ê³¼: 
#   - Docker ì´ë¯¸ì§€: stt-engine:cuda129-rhel89-v1.2 (7.3GB)
#   - ëª¨ë¸ ë””ë ‰í† ë¦¬: models/ (2.5GB)
#   - í…ŒìŠ¤íŠ¸ ì™„ë£Œ ë° ê²€ì¦
#
# ì†Œìš”ì‹œê°„: 90~155ë¶„ (1.5~2.5ì‹œê°„)
#
# ì£¼ì˜ì‚¬í•­:
#   1. RHEL 8.9 EC2 ì¸ìŠ¤í„´ìŠ¤ì—ì„œë§Œ ì‹¤í–‰
#   2. t3.large ì´ìƒ ì¸ìŠ¤í„´ìŠ¤ í•„ìš”
#   3. 100GB ì´ìƒ ìŠ¤í† ë¦¬ì§€ í•„ìš”
#   4. Dockerì™€ git ì‚¬ì „ ì„¤ì¹˜ í•„ìˆ˜
#
################################################################################

set -e

# ============================================================================
# ì„¤ì •
# ============================================================================

WORKSPACE="${PWD}"
SCRIPTS_DIR="${WORKSPACE}/scripts"
DOCKER_DIR="${WORKSPACE}/docker"
OUTPUT_DIR="${WORKSPACE}/build/output"
BUILD_LOG="/tmp/build-complete-$(date +%Y%m%d-%H%M%S).log"

# ë²„ì „ ì •ë³´
IMAGE_TAG="stt-engine:cuda129-rhel89-v1.2"
IMAGE_NAME="stt-engine"
IMAGE_VERSION="cuda129-rhel89-v1.2"

# íƒ€ì´ë¨¸
START_TIME=$(date +%s)

# ============================================================================
# ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜
# ============================================================================

log_header() {
    local msg="$1"
    echo ""
    echo "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"
    echo "  $msg"
    echo "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"
    echo "$msg" >> "$BUILD_LOG"
}

log_step() {
    local step_num="$1"
    local step_name="$2"
    echo ""
    echo "ğŸ“Œ Step $step_num: $step_name"
    echo "[$(date '+%Y-%m-%d %H:%M:%S')] Step $step_num: $step_name" >> "$BUILD_LOG"
}

log_success() {
    echo "âœ… $1"
    echo "[SUCCESS] $1" >> "$BUILD_LOG"
}

log_warn() {
    echo "âš ï¸  $1"
    echo "[WARN] $1" >> "$BUILD_LOG"
}

log_error() {
    echo "âŒ $1"
    echo "[ERROR] $1" >> "$BUILD_LOG"
    exit 1
}

log_info() {
    echo "â„¹ï¸  $1"
    echo "[INFO] $1" >> "$BUILD_LOG"
}

print_elapsed() {
    local end_time=$(date +%s)
    local elapsed=$((end_time - START_TIME))
    local hours=$((elapsed / 3600))
    local minutes=$(((elapsed % 3600) / 60))
    local seconds=$((elapsed % 60))
    printf "â±ï¸  ê²½ê³¼ì‹œê°„: %02dh %02dm %02ds\n" $hours $minutes $seconds
}

# ============================================================================
# ì‚¬ì „ í™•ì¸
# ============================================================================

check_prerequisites() {
    log_step 0 "ì‚¬ì „ í™•ì¸"
    
    # Docker í™•ì¸
    if ! command -v docker &> /dev/null; then
        log_error "Dockerê°€ ì„¤ì¹˜ë˜ì–´ ìˆì§€ ì•ŠìŠµë‹ˆë‹¤."
    fi
    log_success "Docker ì„¤ì¹˜ í™•ì¸: $(docker --version)"
    
    # git í™•ì¸
    if ! command -v git &> /dev/null; then
        log_error "gitì´ ì„¤ì¹˜ë˜ì–´ ìˆì§€ ì•ŠìŠµë‹ˆë‹¤."
    fi
    log_success "git ì„¤ì¹˜ í™•ì¸: $(git --version)"
    
    # Python í™•ì¸
    if ! command -v python3.11 &> /dev/null; then
        log_error "Python 3.11ì´ ì„¤ì¹˜ë˜ì–´ ìˆì§€ ì•ŠìŠµë‹ˆë‹¤."
    fi
    log_success "Python í™•ì¸: $(python3.11 --version)"
    
    # ë””ìŠ¤í¬ ê³µê°„ í™•ì¸ (100GB)
    available=$(df "$WORKSPACE" | tail -1 | awk '{print $4}')
    if [ "$available" -lt 102400000 ]; then
        log_warn "ë””ìŠ¤í¬ ê³µê°„ ë¶€ì¡± (í•„ìš”: 100GB, í˜„ì¬: $(($available / 1024 / 1024))GB)"
    else
        log_success "ë””ìŠ¤í¬ ê³µê°„ í™•ì¸: $(($available / 1024 / 1024))GB"
    fi
    
    # ì¸í„°ë„· ì—°ê²° í™•ì¸
    if ! ping -c 1 8.8.8.8 &> /dev/null 2>&1; then
        log_error "ì¸í„°ë„· ì—°ê²°ì´ ì—†ìŠµë‹ˆë‹¤. ì˜¨ë¼ì¸ ë¹Œë“œ í•„ìˆ˜"
    fi
    log_success "ì¸í„°ë„· ì—°ê²° í™•ì¸: OK"
}

# ============================================================================
# Step 1: Docker ì´ë¯¸ì§€ ë¹Œë“œ (20~40ë¶„)
# ============================================================================

build_docker_image() {
    log_step 1 "Docker ì´ë¯¸ì§€ ë¹Œë“œ (20~40ë¶„)"
    
    if [ ! -f "$DOCKER_DIR/Dockerfile.engine.rhel89" ]; then
        log_error "Dockerfile.engine.rhel89ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤"
    fi
    
    log_info "ë¹Œë“œ ì‹œì‘: $IMAGE_TAG"
    
    # ê¸°ì¡´ ì´ë¯¸ì§€ ì œê±° (ì„ íƒì‚¬í•­)
    if docker images --format "{{.Repository}}:{{.Tag}}" | grep -q "^$IMAGE_TAG$"; then
        log_info "ê¸°ì¡´ ì´ë¯¸ì§€ ì œê±° ì¤‘..."
        docker rmi "$IMAGE_TAG" || true
    fi
    
    # Docker ë¹Œë“œ ì‹¤í–‰
    cd "$WORKSPACE"
    docker build \
        --platform linux/amd64 \
        -t "$IMAGE_TAG" \
        -f "$DOCKER_DIR/Dockerfile.engine.rhel89" \
        --progress=plain \
        . 2>&1 | tee -a "$BUILD_LOG"
    
    if [ ${PIPESTATUS[0]} -ne 0 ]; then
        log_error "Docker ë¹Œë“œ ì‹¤íŒ¨"
    fi
    
    # ì´ë¯¸ì§€ í™•ì¸
    if ! docker images --format "{{.Repository}}:{{.Tag}}" | grep -q "^$IMAGE_TAG$"; then
        log_error "Docker ì´ë¯¸ì§€ ë¹Œë“œ ì™„ë£Œë˜ì§€ ì•ŠìŒ"
    fi
    
    local image_size=$(docker images "$IMAGE_TAG" --format "{{.Size}}")
    log_success "Docker ì´ë¯¸ì§€ ë¹Œë“œ ì™„ë£Œ (í¬ê¸°: $image_size)"
    print_elapsed
}

# ============================================================================
# Step 2: ëª¨ë¸ ë‹¤ìš´ë¡œë“œ ë° ë³€í™˜ (25~45ë¶„)
# ============================================================================

download_models() {
    log_step 2 "ëª¨ë¸ ë‹¤ìš´ë¡œë“œ ë° CTranslate2 ë³€í™˜ (25~45ë¶„)"
    
    if [ ! -f "$WORKSPACE/download_model_hf.py" ]; then
        log_error "download_model_hf.pyë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤"
    fi
    
    # ëª¨ë¸ ë””ë ‰í† ë¦¬ ì´ˆê¸°í™”
    log_info "ê¸°ì¡´ ëª¨ë¸ ë””ë ‰í† ë¦¬ ì •ë¦¬..."
    rm -rf "$WORKSPACE/models" || true
    mkdir -p "$WORKSPACE/models"
    
    # Python ì˜ì¡´ì„± ì„¤ì¹˜
    log_info "í•„ìˆ˜ Python íŒ¨í‚¤ì§€ ì„¤ì¹˜..."
    python3.11 -m pip install -q --upgrade \
        huggingface-hub \
        transformers \
        ctranslate2 \
        faster-whisper || log_warn "ì¼ë¶€ íŒ¨í‚¤ì§€ ì„¤ì¹˜ ì‹¤íŒ¨ (ê³„ì† ì§„í–‰)"
    
    # ëª¨ë¸ ë‹¤ìš´ë¡œë“œ ë° ë³€í™˜
    log_info "ëª¨ë¸ ë‹¤ìš´ë¡œë“œ ë° ë³€í™˜ ì‹¤í–‰ ì¤‘..."
    cd "$WORKSPACE"
    python3.11 download_model_hf.py 2>&1 | tee -a "$BUILD_LOG"
    
    # ëª¨ë¸ ë””ë ‰í† ë¦¬ ê²€ì¦
    if [ ! -d "$WORKSPACE/models/ctranslate2_model" ]; then
        log_error "CTranslate2 ëª¨ë¸ ë³€í™˜ ì‹¤íŒ¨"
    fi
    
    if [ ! -d "$WORKSPACE/models/openai_whisper-large-v3-turbo" ]; then
        log_warn "OpenAI Whisper ëª¨ë¸ ë‹¤ìš´ë¡œë“œ ì™„ë£Œë˜ì§€ ì•ŠìŒ (ê³„ì† ì§„í–‰)"
    fi
    
    local models_size=$(du -sh "$WORKSPACE/models" | awk '{print $1}')
    log_success "ëª¨ë¸ ë‹¤ìš´ë¡œë“œ ë° ë³€í™˜ ì™„ë£Œ (í¬ê¸°: $models_size)"
    print_elapsed
}

# ============================================================================
# Step 3: ëª¨ë¸ ë¡œë“œ í…ŒìŠ¤íŠ¸ (20~30ë¶„)
# ============================================================================

test_model_loading() {
    log_step 3 "ëª¨ë¸ ë¡œë“œ í…ŒìŠ¤íŠ¸ (20~30ë¶„)"
    
    log_info "í…ŒìŠ¤íŠ¸ìš© ì»¨í…Œì´ë„ˆ ì‹œì‘..."
    
    # ì»¨í…Œì´ë„ˆ ì‹œì‘
    docker run -d \
        --name stt-test-engine \
        --rm \
        -v "$WORKSPACE/models:/app/models" \
        -e CUDA_VISIBLE_DEVICES=0 \
        "$IMAGE_TAG" \
        sleep 3600 2>&1 | tee -a "$BUILD_LOG"
    
    if ! docker ps | grep -q "stt-test-engine"; then
        log_error "í…ŒìŠ¤íŠ¸ ì»¨í…Œì´ë„ˆ ì‹œì‘ ì‹¤íŒ¨"
    fi
    
    log_success "í…ŒìŠ¤íŠ¸ ì»¨í…Œì´ë„ˆ ì‹œì‘ë¨"
    
    # CUDA & PyTorch ê²€ì¦
    log_info "CUDA & PyTorch ê²€ì¦..."
    docker exec stt-test-engine python3.11 << 'PYTHON_TEST' 2>&1 | tee -a "$BUILD_LOG"
import torch
import torchaudio
import os

print("\n=== CUDA & PyTorch ê²€ì¦ ===")
print(f"âœ… PyTorch: {torch.__version__}")
print(f"âœ… torchaudio: {torchaudio.__version__}")
print(f"âœ… CUDA Available: {torch.cuda.is_available()}")
if torch.cuda.is_available():
    print(f"âœ… CUDA Device: {torch.cuda.get_device_name(0)}")
print(f"âœ… LD_LIBRARY_PATH: {bool(os.environ.get('LD_LIBRARY_PATH'))}")
PYTHON_TEST
    
    # Faster-Whisper ëª¨ë¸ ë¡œë“œ í…ŒìŠ¤íŠ¸
    log_info "Faster-Whisper ëª¨ë¸ ë¡œë“œ í…ŒìŠ¤íŠ¸..."
    docker exec stt-test-engine python3.11 << 'PYTHON_TEST' 2>&1 | tee -a "$BUILD_LOG"
import sys
sys.path.insert(0, '/app')

print("\n=== Faster-Whisper ëª¨ë¸ ë¡œë“œ ===")
try:
    from faster_whisper import WhisperModel
    model = WhisperModel(
        "/app/models/ctranslate2_model",
        device="auto",
        compute_type="float32",
        local_files_only=True
    )
    print("âœ… Faster-Whisper ëª¨ë¸ ë¡œë“œ ì„±ê³µ!")
except Exception as e:
    print(f"âŒ Faster-Whisper ì˜¤ë¥˜: {type(e).__name__}: {e}")
    import traceback
    traceback.print_exc()
PYTHON_TEST
    
    # OpenAI Whisper ëª¨ë¸ ë¡œë“œ í…ŒìŠ¤íŠ¸
    log_info "OpenAI Whisper ëª¨ë¸ ë¡œë“œ í…ŒìŠ¤íŠ¸..."
    docker exec stt-test-engine python3.11 << 'PYTHON_TEST' 2>&1 | tee -a "$BUILD_LOG"
import sys
sys.path.insert(0, '/app')

print("\n=== OpenAI Whisper ëª¨ë¸ ë¡œë“œ ===")
try:
    from transformers import AutoModelForSpeechSeq2Seq, AutoProcessor
    processor = AutoProcessor.from_pretrained(
        "/app/models/openai_whisper-large-v3-turbo",
        local_files_only=True
    )
    model = AutoModelForSpeechSeq2Seq.from_pretrained(
        "/app/models/openai_whisper-large-v3-turbo",
        local_files_only=True
    )
    print("âœ… OpenAI Whisper ëª¨ë¸ ë¡œë“œ ì„±ê³µ!")
except Exception as e:
    print(f"âš ï¸  OpenAI Whisper: {type(e).__name__}: {e}")
PYTHON_TEST
    
    # ì»¨í…Œì´ë„ˆ ì¢…ë£Œ
    log_info "í…ŒìŠ¤íŠ¸ ì»¨í…Œì´ë„ˆ ì¢…ë£Œ..."
    docker stop stt-test-engine 2>/dev/null || true
    
    log_success "ëª¨ë¸ ë¡œë“œ í…ŒìŠ¤íŠ¸ ì™„ë£Œ"
    print_elapsed
}

# ============================================================================
# Step 4: ì´ë¯¸ì§€ ë° ëª¨ë¸ ì €ì¥ (5~10ë¶„)
# ============================================================================

save_artifacts() {
    log_step 4 "ì´ë¯¸ì§€ ë° ëª¨ë¸ ì €ì¥ (5~10ë¶„)"
    
    mkdir -p "$OUTPUT_DIR"
    
    # Docker ì´ë¯¸ì§€ ì €ì¥
    log_info "Docker ì´ë¯¸ì§€ ì €ì¥ ì¤‘... (5~10ë¶„ ì†Œìš”)"
    docker save "$IMAGE_TAG" | gzip > "$OUTPUT_DIR/stt-engine-${IMAGE_VERSION}.tar.gz"
    
    local image_tar_size=$(du -sh "$OUTPUT_DIR/stt-engine-${IMAGE_VERSION}.tar.gz" | awk '{print $1}')
    log_success "Docker ì´ë¯¸ì§€ ì €ì¥ ì™„ë£Œ (í¬ê¸°: $image_tar_size)"
    
    # ëª¨ë¸ ë””ë ‰í† ë¦¬ í™•ì¸
    local models_size=$(du -sh "$WORKSPACE/models" | awk '{print $1}')
    log_info "ëª¨ë¸ ë””ë ‰í† ë¦¬: $models_size"
    
    # ë¹Œë“œ ì •ë³´ ì €ì¥
    cat > "$OUTPUT_DIR/BUILD_INFO.txt" << EOF
# STT Engine Build Information
# Generated: $(date)

## Image Information
- Name: $IMAGE_TAG
- Size: $image_tar_size
- Archive: stt-engine-${IMAGE_VERSION}.tar.gz

## Model Information
- Location: models/
- Size: $models_size
- Models:
  * OpenAI Whisper: models/openai_whisper-large-v3-turbo/
  * CTranslate2: models/ctranslate2_model/

## Files
- stt-engine-${IMAGE_VERSION}.tar.gz (Docker image)
- models/ (Model directory - 2.5GB)
- build.log (Build log)

## Next Steps
1. Transfer image and models to production server
2. Load image: docker load < stt-engine-${IMAGE_VERSION}.tar.gz
3. Mount models: -v /path/to/models:/app/models
4. Run container: docker run -d -v models:/app/models $IMAGE_TAG

## Timeline
- Start: $(date -r "$BUILD_LOG" 2>/dev/null || echo "N/A")
- End: $(date)

EOF
    
    log_success "ë¹Œë“œ ì •ë³´ ì €ì¥ë¨"
    
    # ìµœì¢… íŒŒì¼ ëª©ë¡
    log_info "ìƒì„±ëœ íŒŒì¼:"
    ls -lh "$OUTPUT_DIR/" | tail -10
    
    print_elapsed
}

# ============================================================================
# ìµœì¢… ìš”ì•½
# ============================================================================

print_summary() {
    log_step "5" "ìµœì¢… ìš”ì•½ ë° ê²€ì¦"
    
    echo ""
    echo "ğŸ“Š ìµœì¢… ë¹Œë“œ ê²°ê³¼:"
    echo ""
    
    # Docker ì´ë¯¸ì§€ í™•ì¸
    if docker images --format "{{.Repository}}:{{.Tag}}" | grep -q "^$IMAGE_TAG$"; then
        local image_size=$(docker images "$IMAGE_TAG" --format "{{.Size}}")
        echo "âœ… Docker ì´ë¯¸ì§€: $IMAGE_TAG"
        echo "   í¬ê¸°: $image_size"
    else
        echo "âŒ Docker ì´ë¯¸ì§€ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤"
    fi
    
    echo ""
    
    # ëª¨ë¸ í™•ì¸
    if [ -d "$WORKSPACE/models" ]; then
        local models_size=$(du -sh "$WORKSPACE/models" | awk '{print $1}')
        echo "âœ… ëª¨ë¸ ë””ë ‰í† ë¦¬: models/"
        echo "   í¬ê¸°: $models_size"
        
        if [ -d "$WORKSPACE/models/ctranslate2_model" ]; then
            echo "   âœ… CTranslate2 ëª¨ë¸"
        fi
        
        if [ -d "$WORKSPACE/models/openai_whisper-large-v3-turbo" ]; then
            echo "   âœ… OpenAI Whisper ëª¨ë¸"
        fi
    else
        echo "âŒ ëª¨ë¸ ë””ë ‰í† ë¦¬ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤"
    fi
    
    echo ""
    
    # ì•„ì¹´ì´ë¸Œ í™•ì¸
    if [ -f "$OUTPUT_DIR/stt-engine-${IMAGE_VERSION}.tar.gz" ]; then
        local tar_size=$(du -sh "$OUTPUT_DIR/stt-engine-${IMAGE_VERSION}.tar.gz" | awk '{print $1}')
        echo "âœ… ì•„ì¹´ì´ë¸Œ: stt-engine-${IMAGE_VERSION}.tar.gz"
        echo "   í¬ê¸°: $tar_size"
    fi
    
    echo ""
    
    # ë¡œê·¸ íŒŒì¼
    echo "ğŸ“ ë¡œê·¸ íŒŒì¼: $BUILD_LOG"
    echo ""
    
    # ë‹¤ìŒ ë‹¨ê³„
    echo "ğŸ“Œ ë‹¤ìŒ ë‹¨ê³„:"
    echo "   1. ìš´ì˜ ì„œë²„ë¡œ ì´ë¯¸ì§€ ë° ëª¨ë¸ ì „ì†¡"
    echo "   2. docker load < stt-engine-${IMAGE_VERSION}.tar.gz"
    echo "   3. docker run -d -v models:/app/models $IMAGE_TAG"
    echo ""
    
    print_elapsed
    
    log_success "ë¹Œë“œ ì™„ë£Œ!"
}

# ============================================================================
# ì—ëŸ¬ ì²˜ë¦¬
# ============================================================================

trap 'log_error "ë¹Œë“œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ. ë¡œê·¸ë¥¼ í™•ì¸í•˜ì„¸ìš”: $BUILD_LOG"' ERR

# ============================================================================
# ë©”ì¸ ì‹¤í–‰
# ============================================================================

main() {
    log_header "ğŸš€ STT Engine ì™„ì „ ë¹Œë“œ (AWS EC2 RHEL 8.9)"
    
    log_info "ì‘ì—…ê³µê°„: $WORKSPACE"
    log_info "ì¶œë ¥ ë””ë ‰í† ë¦¬: $OUTPUT_DIR"
    log_info "ë¡œê·¸ íŒŒì¼: $BUILD_LOG"
    
    # ë‹¨ê³„ë³„ ì‹¤í–‰
    check_prerequisites
    build_docker_image
    download_models
    test_model_loading
    save_artifacts
    print_summary
}

# ìŠ¤í¬ë¦½íŠ¸ ì‹¤í–‰
main "$@"
