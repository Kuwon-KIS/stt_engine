# STT Engine - Speech-to-Text ì—”ì§„

ìŒì„± íŒŒì¼ì„ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜í•˜ê³ , vLLMì„ ì‚¬ìš©í•˜ì—¬ ì¶”ê°€ ì²˜ë¦¬ë¥¼ ìˆ˜í–‰í•˜ëŠ” ì—”ì§„ì…ë‹ˆë‹¤.

## ğŸ¯ ì£¼ìš” ê¸°ëŠ¥

- **Whisper ê¸°ë°˜ STT**: OpenAIì˜ whisper-large-v3-turbo ëª¨ë¸ ì‚¬ìš©
- **ë‹¤êµ­ì–´ ì§€ì›**: í•œêµ­ì–´, ì˜ì–´ ë“± ë‹¤ì–‘í•œ ì–¸ì–´ ì§€ì›
- **vLLM í†µí•©**: STT ê²°ê³¼ë¥¼ ëŒ€ê·œëª¨ ì–¸ì–´ ëª¨ë¸ë¡œ ì¶”ê°€ ì²˜ë¦¬
- **Docker í™˜ê²½**: ì»¨í…Œì´ë„ˆí™”ëœ ë°°í¬ í™˜ê²½
- **FastAPI ì„œë²„**: REST APIë¥¼ í†µí•œ ì‰¬ìš´ ì ‘ê·¼

## ğŸ“‹ ì¤€ë¹„ ì‚¬í•­

- Python 3.11+
- CUDA 11.0+ (GPU ì‚¬ìš© ì‹œ)
- Docker & Docker Compose (ì»¨í…Œì´ë„ˆ ì‚¬ìš© ì‹œ)

## ğŸš€ ë¹ ë¥¸ ì‹œì‘

### 1. ë¡œì»¬ í™˜ê²½ ì„¤ì •

```bash
# ê°€ìƒ í™˜ê²½ ìƒì„±
python3 -m venv venv
source venv/bin/activate  # macOS/Linux
# Windowsì˜ ê²½ìš°: venv\Scripts\activate

# ì˜ì¡´ì„± ì„¤ì¹˜
pip install -r requirements.txt
```

### 2. Whisper ëª¨ë¸ ë‹¤ìš´ë¡œë“œ

```bash
python download_model.py
```

ì´ ìŠ¤í¬ë¦½íŠ¸ëŠ” Hugging Faceì—ì„œ `openai/whisper-large-v3-turbo` ëª¨ë¸ì„ ë‹¤ìš´ë¡œë“œí•©ë‹ˆë‹¤.

### 3. í™˜ê²½ ë³€ìˆ˜ ì„¤ì •

```bash
cp .env.example .env
# .env íŒŒì¼ì„ í•„ìš”ì— ë”°ë¼ ìˆ˜ì •
```

### 4. STT í…ŒìŠ¤íŠ¸

```bash
# audio/ ë””ë ‰í† ë¦¬ì— ìŒì„± íŒŒì¼ì„ ì¶”ê°€í•œ í›„
python stt_engine.py
```

### 5. API ì„œë²„ ì‹¤í–‰

```bash
python api_server.py
```

API ì„œë²„ê°€ `http://localhost:8001`ì—ì„œ ì‹¤í–‰ë©ë‹ˆë‹¤.

## ğŸ³ Docker í™˜ê²½ ì„¤ì •

### 1. Docker ì´ë¯¸ì§€ ë¹Œë“œ

```bash
docker build -t stt-engine:latest .
```

### 2. Docker Composeë¡œ ì‹¤í–‰

```bash
docker-compose up -d
```

ì´ ëª…ë ¹ì–´ë¡œ STT ì—”ì§„ê³¼ vLLM ì„œë²„ê°€ ë™ì‹œì— ì‹¤í–‰ë©ë‹ˆë‹¤.

### 3. ì„œë²„ ìƒíƒœ í™•ì¸

```bash
# STT ì—”ì§„ ë¡œê·¸ í™•ì¸
docker-compose logs -f stt-engine

# vLLM ì„œë²„ ë¡œê·¸ í™•ì¸
docker-compose logs -f vllm-server
```

## ğŸ“¡ API ì—”ë“œí¬ì¸íŠ¸

### í—¬ìŠ¤ ì²´í¬
```bash
curl http://localhost:8001/health
```

### ìŒì„± íŒŒì¼ ë³€í™˜ (STTë§Œ)
```bash
curl -X POST -F "file=@audio.wav" http://localhost:8001/transcribe
```

### ìŒì„± íŒŒì¼ ë³€í™˜ ë° vLLM ì²˜ë¦¬
```bash
curl -X POST -F "file=@audio.wav" \
  -F "instruction=ë‹¤ìŒ í…ìŠ¤íŠ¸ë¥¼ ìš”ì•½í•´ì£¼ì„¸ìš”:" \
  http://localhost:8001/transcribe-and-process
```

## ğŸ“ í”„ë¡œì íŠ¸ êµ¬ì¡°

```
stt_engine/
â”œâ”€â”€ download_model.py          # ëª¨ë¸ ë‹¤ìš´ë¡œë“œ ìŠ¤í¬ë¦½íŠ¸
â”œâ”€â”€ stt_engine.py             # STT í•µì‹¬ ëª¨ë“ˆ
â”œâ”€â”€ vllm_client.py            # vLLM í´ë¼ì´ì–¸íŠ¸
â”œâ”€â”€ api_server.py             # FastAPI ì„œë²„
â”œâ”€â”€ Dockerfile                # Docker ì´ë¯¸ì§€ ì •ì˜
â”œâ”€â”€ docker-compose.yml        # Docker Compose ì„¤ì •
â”œâ”€â”€ requirements.txt          # Python ì˜ì¡´ì„±
â”œâ”€â”€ .env.example              # í™˜ê²½ ë³€ìˆ˜ ì˜ˆì œ
â”œâ”€â”€ README.md                 # ì´ íŒŒì¼
â”œâ”€â”€ models/                   # Whisper ëª¨ë¸ ì €ì¥ ìœ„ì¹˜
â”œâ”€â”€ audio/                    # í…ŒìŠ¤íŠ¸ ìŒì„± íŒŒì¼ ìœ„ì¹˜
â””â”€â”€ logs/                     # ë¡œê·¸ íŒŒì¼ ìœ„ì¹˜
```

## ğŸ”§ ê³ ê¸‰ ì„¤ì •

### GPU ì‚¬ìš© ì„¤ì •

#### docker-compose.ymlì—ì„œ GPU í™œì„±í™”:
```yaml
deploy:
  resources:
    reservations:
      devices:
        - driver: nvidia
          count: 1
          capabilities: [gpu]
```

#### í™˜ê²½ ë³€ìˆ˜ì—ì„œ GPU ì„¤ì •:
```bash
WHISPER_DEVICE=cuda
```

### vLLM ëª¨ë¸ ë³€ê²½

docker-compose.ymlì—ì„œ ëª¨ë¸ ì´ë¦„ ë³€ê²½:
```yaml
environment:
  - MODEL_NAME=meta-llama/Llama-2-13b-hf  # ë‹¤ë¥¸ ëª¨ë¸ë¡œ ë³€ê²½
```

## ğŸ§ª í…ŒìŠ¤íŠ¸

### ë¡œì»¬ í…ŒìŠ¤íŠ¸
```bash
# STT ì—”ì§„ í…ŒìŠ¤íŠ¸
python stt_engine.py

# vLLM ì—°ê²° í…ŒìŠ¤íŠ¸
python vllm_client.py
```

### Docker í™˜ê²½ì—ì„œ í…ŒìŠ¤íŠ¸
```bash
# ì»¨í…Œì´ë„ˆ ë‚´ì—ì„œ í…ŒìŠ¤íŠ¸ ì‹¤í–‰
docker-compose exec stt-engine python stt_engine.py
```

## ğŸ“Š ëª¨ë‹ˆí„°ë§

### ë¡œê·¸ í™•ì¸
```bash
# ìµœê·¼ 100ì¤„ ë¡œê·¸
tail -100f logs/*.log

# íŠ¹ì • ë¡œê·¸ ë³´ê¸°
docker-compose logs -f stt-engine
```

### ë¦¬ì†ŒìŠ¤ ì‚¬ìš©ëŸ‰ í™•ì¸
```bash
docker stats stt-engine vllm-server
```

## âš ï¸ ì£¼ì˜ì‚¬í•­

1. **ëª¨ë¸ ë‹¤ìš´ë¡œë“œ**: ì²« ì‹¤í–‰ ì‹œ ëª¨ë¸ì´ ìƒë‹¹íˆ í¼ (ìˆ˜ GB)ì´ë¯€ë¡œ ì‹œê°„ì´ ê±¸ë¦´ ìˆ˜ ìˆìŠµë‹ˆë‹¤.
2. **GPU ë©”ëª¨ë¦¬**: GPUë¥¼ ì‚¬ìš©í•  ê²½ìš° ì¶©ë¶„í•œ VRAMì´ í•„ìš”í•©ë‹ˆë‹¤ (ìµœì†Œ 8GB ê¶Œì¥).
3. **vLLM ì„œë²„**: STTì™€ vLLMì„ í•¨ê»˜ ì‚¬ìš©í•˜ë ¤ë©´ vLLM ì„œë²„ê°€ ë°˜ë“œì‹œ ì‹¤í–‰ ì¤‘ì´ì–´ì•¼ í•©ë‹ˆë‹¤.

## ğŸ› ï¸ ë¬¸ì œ í•´ê²°

### ëª¨ë¸ ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨
```bash
# Hugging Face í† í° ì„¤ì •
export HUGGINGFACE_HUB_TOKEN=your_token_here
python download_model.py
```

### ë©”ëª¨ë¦¬ ë¶€ì¡±
```bash
# CPU ëª¨ë“œë¡œ ì‹¤í–‰
export WHISPER_DEVICE=cpu
python stt_engine.py
```

### vLLM ì„œë²„ ì—°ê²° ì‹¤íŒ¨
```bash
# vLLM ì„œë²„ê°€ ì‹¤í–‰ ì¤‘ì¸ì§€ í™•ì¸
curl http://localhost:8000/health

# ì„œë²„ ì¬ì‹œì‘
docker-compose restart vllm-server
```

## ğŸ“ ë¼ì´ì„ ìŠ¤

ì´ í”„ë¡œì íŠ¸ëŠ” MIT ë¼ì´ì„ ìŠ¤ë¥¼ ë”°ë¦…ë‹ˆë‹¤.

## ğŸ‘¥ ê¸°ì—¬

ì´ìŠˆ ë° í’€ ë¦¬í€˜ìŠ¤íŠ¸ëŠ” ì–¸ì œë“  í™˜ì˜í•©ë‹ˆë‹¤!
