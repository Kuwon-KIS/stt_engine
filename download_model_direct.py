#!/usr/bin/env python3
import os
import sys
import ssl
import urllib.request
import json
from pathlib import Path

# SSL ì¸ì¦ì„œ ê²€ì¦ ì™„ì „ ë¹„í™œì„±í™”
ssl._create_default_https_context = ssl._create_unverified_context

print("ğŸ”„ Whisper Large-V3-Turbo ëª¨ë¸ íŒŒì¼ ë‹¤ìš´ë¡œë“œ...")
print("=" * 60)

models_dir = Path("/Users/a113211/workspace/stt_engine/models")
models_dir.mkdir(exist_ok=True)

try:
    # í•„ìš”í•œ ëª¨ë¸ íŒŒì¼ë“¤
    files = {
        "model.safetensors": "https://huggingface.co/openai/whisper-large-v3-turbo/resolve/main/model.safetensors",
        "config.json": "https://huggingface.co/openai/whisper-large-v3-turbo/resolve/main/config.json",
        "preprocessor_config.json": "https://huggingface.co/openai/whisper-large-v3-turbo/resolve/main/preprocessor_config.json",
        "tokenizer.json": "https://huggingface.co/openai/whisper-large-v3-turbo/resolve/main/tokenizer.json",
        "vocab.json": "https://huggingface.co/openai/whisper-large-v3-turbo/resolve/main/vocab.json",
        "merges.txt": "https://huggingface.co/openai/whisper-large-v3-turbo/resolve/main/merges.txt",
        "tokenizer_config.json": "https://huggingface.co/openai/whisper-large-v3-turbo/resolve/main/tokenizer_config.json",
        "generation_config.json": "https://huggingface.co/openai/whisper-large-v3-turbo/resolve/main/generation_config.json",
    }
    
    print(f"ğŸ“ ì €ì¥ ê²½ë¡œ: {models_dir}")
    print(f"ğŸ“¦ ë‹¤ìš´ë¡œë“œ íŒŒì¼: {len(files)}ê°œ")
    print()
    
    for filename, url in files.items():
        filepath = models_dir / filename
        
        # ì´ë¯¸ ë‹¤ìš´ë¡œë“œëœ íŒŒì¼ í™•ì¸
        if filepath.exists():
            size = filepath.stat().st_size
            print(f"âœ… {filename} (ì´ë¯¸ ì¡´ì¬: {size:,} bytes)")
            continue
            
        print(f"â³ {filename} ë‹¤ìš´ë¡œë“œ ì¤‘...", end=" ", flush=True)
        
        try:
            urllib.request.urlretrieve(url, filepath)
            size = filepath.stat().st_size
            print(f"âœ… ({size:,} bytes)")
        except Exception as e:
            print(f"âŒ ì‹¤íŒ¨: {e}")
            # ëª¨ë¸ íŒŒì¼(model.safetensors)ëŠ” í•„ìˆ˜, ë‚˜ë¨¸ì§€ëŠ” ì„ íƒ
            if filename == "model.safetensors":
                raise
    
    print()
    print("=" * 60)
    print("âœ… ëª¨ë¸ ë‹¤ìš´ë¡œë“œ ì™„ë£Œ!")
    print("=" * 60)
    
    # í™•ì¸
    files_list = list(models_dir.glob("*"))
    print(f"\nğŸ“Š ì¤€ë¹„ëœ íŒŒì¼: {len(files_list)}ê°œ")
    
    total_size = sum(f.stat().st_size for f in files_list if f.is_file())
    print(f"ğŸ“ ì´ í¬ê¸°: {total_size / (1024**3):.2f} GB")
    
    print("\nğŸ“ íŒŒì¼ ëª©ë¡:")
    for f in sorted(files_list):
        if f.is_file():
            size = f.stat().st_size
            print(f"   - {f.name}: {size:,} bytes")
    
    print("\nâœ… Docker ì»¨í…Œì´ë„ˆì— ë°˜ì… ì¤€ë¹„ ì™„ë£Œ!")
    print(f"ë§ˆìš´íŠ¸ ê²½ë¡œ: /Users/a113211/workspace/stt_engine/models:/app/models")
    
except Exception as e:
    print(f"âŒ ì˜¤ë¥˜ ë°œìƒ: {e}", file=sys.stderr)
    import traceback
    traceback.print_exc()
    sys.exit(1)
