# ğŸš€ STT Engine - Linux ì„œë²„ ë°°í¬ í›„ ì„¤ì • ê°€ì´ë“œ

## ğŸ“‹ ë°°í¬ í›„ ì²´í¬ë¦¬ìŠ¤íŠ¸

### Phase 1ï¸âƒ£: ì„œë²„ ì¤€ë¹„ (5ë¶„)
```bash
# 1. íŒŒì¼ ì „ì†¡ í™•ì¸
ls -lh /tmp/stt_engine_deployment_slim.tar.gz

# 2. ì••ì¶• í•´ì œ
cd /tmp
tar -xzf stt_engine_deployment_slim.tar.gz
cd stt_engine

# 3. í˜„ì¬ ë””ë ‰í† ë¦¬ í™•ì¸
pwd
ls -la
```

### Phase 2ï¸âƒ£: Python í™˜ê²½ ì„¤ì • (5ë¶„)

**RHEL 8.9ì—ì„œ:**
```bash
# 1. Python 3.11 ì„¤ì¹˜ í™•ì¸
python3.11 --version
# ì¶œë ¥: Python 3.11.5

# 2. Python ê°œë°œ íŒ¨í‚¤ì§€ ì„¤ì¹˜ (í•„ìš”ì‹œ)
sudo yum install -y python3.11-devel

# 3. venv ìƒì„±
python3.11 -m venv venv

# 4. ê°€ìƒí™˜ê²½ í™œì„±í™”
source venv/bin/activate

# 5. pip ì—…ê·¸ë ˆì´ë“œ
pip install --upgrade pip setuptools wheel
```

### Phase 3ï¸âƒ£: wheels ì„¤ì¹˜ (10-15ë¶„)

```bash
# 1. deployment_package ì´ë™
cd deployment_package

# 2. ëª¨ë“  wheels ì„¤ì¹˜
pip install wheels/*.whl

# 3. ì„¤ì¹˜ í™•ì¸
pip list | grep -E "(torch|transformers|librosa)"

# 4. CUDA ì§€ì› í™•ì¸
python3 -c "import torch; print(f'CUDA Available: {torch.cuda.is_available()}')"

# ì˜ˆìƒ ì¶œë ¥:
# CUDA Available: True
# Device: cuda:0 (GPU ì´ë¦„)

# 5. í”„ë¡œì íŠ¸ ë””ë ‰í† ë¦¬ë¡œ ì´ë™
cd ..
```

### Phase 4ï¸âƒ£: ëª¨ë¸ ë‹¤ìš´ë¡œë“œ (10-20ë¶„, ë„¤íŠ¸ì›Œí¬ ì†ë„ì— ë”°ë¼ ë‹¤ë¦„)

**âš ï¸ ë§¤ìš° ì¤‘ìš”: ì´ ë‹¨ê³„ëŠ” ì¸í„°ë„· ì—°ê²°ì´ í•„ìš”í•©ë‹ˆë‹¤!**

```bash
# 1. ëª¨ë¸ ë‹¤ìš´ë¡œë“œ ìŠ¤í¬ë¦½íŠ¸ ì‹¤í–‰
python3 download_model.py

# ì˜ˆìƒ ì¶œë ¥:
# ğŸ“¥ ëª¨ë¸ ë‹¤ìš´ë¡œë“œë¥¼ ì‹œì‘í•©ë‹ˆë‹¤: openai/whisper-large-v3-turbo
# ğŸ’¾ ì €ì¥ ê²½ë¡œ: /path/to/stt_engine/models
# 1ï¸âƒ£  ëª¨ë¸ íŒŒì¼ ë‹¤ìš´ë¡œë“œ ì¤‘...
# â¬‡ï¸  Downloading (ì§„í–‰ìƒí™©)
# âœ… ëª¨ë¸ íŒŒì¼ ë‹¤ìš´ë¡œë“œ ì™„ë£Œ
# 2ï¸âƒ£  Processor ë‹¤ìš´ë¡œë“œ ì¤‘...
# âœ… Processor ì €ì¥ ì™„ë£Œ
# âœ¨ ëª¨ë“  ë‹¤ìš´ë¡œë“œê°€ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!

# 2. ëª¨ë¸ íŒŒì¼ í™•ì¸
ls -lh models/
# ì˜ˆìƒ: ì•½ 3-5GB íŒŒì¼ë“¤

# 3. ëª¨ë¸ ë¡œë“œ í…ŒìŠ¤íŠ¸ (ì„ íƒì‚¬í•­)
python3 -c "from transformers import pipeline; print('âœ… ëª¨ë¸ ë¡œë“œ ì„±ê³µ')"
```

### Phase 5ï¸âƒ£: STT Engine ì„¤ì¹˜ (2-3ë¶„)

```bash
# 1. í”„ë¡œì íŠ¸ íŒ¨í‚¤ì§€ ì„¤ì¹˜
pip install -e .

# 2. ì„¤ì¹˜ í™•ì¸
python3 -c "import stt_engine; print('âœ… STT Engine ì„¤ì¹˜ ì™„ë£Œ')"
```

### Phase 6ï¸âƒ£: API ì„œë²„ ì‹¤í–‰ ë° í…ŒìŠ¤íŠ¸ (5ë¶„)

**ì˜µì…˜ A: ê¸°ë³¸ ì‹¤í–‰**
```bash
# 1. API ì„œë²„ ì‹œì‘
python3 api_server.py

# ì˜ˆìƒ ì¶œë ¥:
# INFO:     Uvicorn running on http://0.0.0.0:8001
# INFO:     Application startup complete

# 2. ë‹¤ë¥¸ í„°ë¯¸ë„ì—ì„œ í…ŒìŠ¤íŠ¸ (ë˜ëŠ” curlë¡œ)
curl -X GET http://localhost:8001/health

# ì˜ˆìƒ ì‘ë‹µ:
# {"status": "ok", "model": "whisper-large-v3-turbo"}
```

**ì˜µì…˜ B: Uvicornìœ¼ë¡œ ì§ì ‘ ì‹¤í–‰ (ê¶Œì¥)**
```bash
# 1. ë°±ê·¸ë¼ìš´ë“œì—ì„œ ì‹¤í–‰
nohup uvicorn api_server:app --host 0.0.0.0 --port 8001 > api.log 2>&1 &

# 2. ë¡œê·¸ ëª¨ë‹ˆí„°ë§
tail -f api.log

# 3. í”„ë¡œì„¸ìŠ¤ í™•ì¸
ps aux | grep uvicorn
```

**ì˜µì…˜ C: Systemd Serviceë¡œ ë“±ë¡ (í”„ë¡œë•ì…˜)**
```bash
# 1. service íŒŒì¼ ìƒì„±
sudo tee /etc/systemd/system/stt-engine.service > /dev/null << 'EOF'
[Unit]
Description=STT Engine API Server
After=network.target

[Service]
Type=simple
User=<your-user>
WorkingDirectory=/path/to/stt_engine
Environment="PATH=/path/to/stt_engine/venv/bin"
ExecStart=/path/to/stt_engine/venv/bin/python3 api_server.py
Restart=always
RestartSec=10

[Install]
WantedBy=multi-user.target
EOF

# 2. ì„œë¹„ìŠ¤ í™œì„±í™” ë° ì‹œì‘
sudo systemctl daemon-reload
sudo systemctl enable stt-engine
sudo systemctl start stt-engine

# 3. ìƒíƒœ í™•ì¸
sudo systemctl status stt-engine
```

### Phase 7ï¸âƒ£: API ê¸°ë³¸ í…ŒìŠ¤íŠ¸

```bash
# 1. í—¬ìŠ¤ì²´í¬
curl http://localhost:8001/health

# 2. ëª¨ë¸ ì •ë³´ ì¡°íšŒ
curl http://localhost:8001/info

# 3. ìŒì„± íŒŒì¼ ì „ì†¡ í…ŒìŠ¤íŠ¸ (audio.wav í•„ìš”)
curl -X POST \
  -H "Content-Type: multipart/form-data" \
  -F "file=@audio.wav" \
  http://localhost:8001/transcribe

# ì˜ˆìƒ ì‘ë‹µ:
# {
#   "text": "ì¸ì‹ëœ ìŒì„± í…ìŠ¤íŠ¸",
#   "language": "ko",
#   "duration": 5.2
# }
```

---

## ğŸ”§ ë¬¸ì œ í•´ê²°

### Q: ImportError: No module named 'torch'
```bash
# A: wheels ì„¤ì¹˜ í™•ì¸
pip list | grep torch
pip install wheels/*.whl --force-reinstall
```

### Q: CUDA ê´€ë ¨ ì˜¤ë¥˜
```bash
# A: CUDA í˜¸í™˜ì„± í™•ì¸
nvidia-smi
python3 -c "import torch; print(torch.cuda.is_available())"

# CUDA ì‚¬ìš© ë¹„í™œì„±í™” (CPU ëª¨ë“œ)
export CUDA_VISIBLE_DEVICES=""
python3 api_server.py
```

### Q: ë©”ëª¨ë¦¬ ë¶€ì¡±
```bash
# A: ëª¨ë¸ ì–‘ìí™” ì„¤ì •
export WHISPER_DTYPE=float16
python3 api_server.py

# ë˜ëŠ” ë” ì‘ì€ ëª¨ë¸ ì‚¬ìš©
# download_model.pyì—ì„œ "whisper-large-v3-turbo" â†’ "whisper-base" ë³€ê²½
```

### Q: ëª¨ë¸ ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨
```bash
# A: ìˆ˜ë™ìœ¼ë¡œ ë‹¤ìš´ë¡œë“œ í›„ ì €ì¥
mkdir -p models
cd models

# Hugging Face CLI ì‚¬ìš©
huggingface-cli download openai/whisper-large-v3-turbo --repo-type model

# ë˜ëŠ” ì›¹ì—ì„œ ì§ì ‘ ë‹¤ìš´ë¡œë“œ
# https://huggingface.co/openai/whisper-large-v3-turbo
```

---

## âœ… ìµœì¢… ê²€ì¦ ì²´í¬ë¦¬ìŠ¤íŠ¸

```bash
# 1. í™˜ê²½ í™•ì¸
python3 --version              # 3.11.5
nvidia-smi                     # CUDA ë²„ì „ í™•ì¸

# 2. íŒ¨í‚¤ì§€ í™•ì¸
pip list | head -20

# 3. ëª¨ë¸ íŒŒì¼ í™•ì¸
ls -lh models/                 # 3-5GB íŒŒì¼ ì¡´ì¬

# 4. API ì„œë²„ ì‹¤í–‰
python3 api_server.py          # í¬íŠ¸ 8001ì—ì„œ ì‹¤í–‰

# 5. API í…ŒìŠ¤íŠ¸ (ìƒˆ í„°ë¯¸ë„)
curl http://localhost:8001/health

# 6. ë¡œê·¸ í™•ì¸
tail -f logs/api.log           # ì—ëŸ¬ í™•ì¸
```

---

## ğŸ“ ë°°í¬ í›„ ê¶Œì¥ ì‘ì—…

1. **ë°±ì—…**: ëª¨ë¸ ë° ì„¤ì • íŒŒì¼ ë°±ì—…
2. **ëª¨ë‹ˆí„°ë§**: API ì„œë²„ ë¡œê·¸ ë° GPU ì‚¬ìš©ë¥  ëª¨ë‹ˆí„°ë§
3. **ë¡œë“œ í…ŒìŠ¤íŠ¸**: ì—¬ëŸ¬ ë™ì‹œ ìš”ì²­ í…ŒìŠ¤íŠ¸
4. **ì„±ëŠ¥ íŠœë‹**: GPU ë©”ëª¨ë¦¬ ì„¤ì • ìµœì í™”

---

**ë°°í¬ ì™„ë£Œ! ğŸ‰**
ë¬¸ì œê°€ ìƒê¸°ë©´ logs/ ë””ë ‰í† ë¦¬ì˜ ë¡œê·¸ íŒŒì¼ì„ í™•ì¸í•˜ì„¸ìš”.
