# Docker ì˜¤í”„ë¼ì¸ í™˜ê²½ ì„¤ì • í™•ì¸ âœ…

## ğŸ“‹ ìƒí™© ì •ë¦¬

**Q: Docker ì‹¤í–‰ ì‹œ ëª¨ë¸ì´ ë³€í™˜ë˜ëŠ”ë°, ì™¸ë¶€ ë„¤íŠ¸ì›Œí¬ê°€ í•„ìš”í•œê°€?**

**A: NO! ì™¸ë¶€ ë„¤íŠ¸ì›Œí¬ í•„ìš” ì—†ìŠµë‹ˆë‹¤.** âœ…

---

## ğŸ”„ ëª¨ë¸ ë¡œë“œ í”„ë¡œì„¸ìŠ¤ (ë„¤íŠ¸ì›Œí¬ ë¶ˆí•„ìš”)

### 1ë‹¨ê³„: ë¡œì»¬ íŒŒì¼ ë§ˆìš´íŠ¸
```bash
docker run -d \
  --name stt-engine-gpu \
  -v /Users/a113211/workspace/stt_engine/models:/app/models \
  stt-engine:cuda129-v1.0
```

### 2ë‹¨ê³„: faster_whisperê°€ ë¡œì»¬ íŒŒì¼ë§Œ ì½ìŒ
```python
self.model = WhisperModel(
    "/app/models",  # â† ë¡œì»¬ ê²½ë¡œ (ë§ˆìš´íŠ¸ëœ ë””ë ‰í† ë¦¬)
    device="cuda",
    local_files_only=True  # â† ì™¸ë¶€ ë‹¤ìš´ë¡œë“œ ê¸ˆì§€!
)
```

### 3ë‹¨ê³„: ë©”ëª¨ë¦¬ì—ì„œ ë³€í™˜
- `model.safetensors` (ë¡œì»¬ íŒŒì¼) ì½ìŒ
- ctranslate2 í¬ë§·ìœ¼ë¡œ ë©”ëª¨ë¦¬ ë³€í™˜
- ë³€í™˜ëœ ëª¨ë¸ ìºì‹œ (ì»¨í…Œì´ë„ˆ ë‚´ë¶€)
- STT API ì„œë²„ êµ¬ë™

**ê²°ê³¼**: ğŸ“¡ ë„¤íŠ¸ì›Œí¬ ì ‘ê·¼ ZERO! âœ…

---

## âœ… ì˜¤í”„ë¼ì¸ ì•ˆì •ì„± ì„¤ì •

### 1. stt_engine.py ìˆ˜ì •ë¨
```python
# âœ… ì¶”ê°€ë¨: local_files_only=True
self.model = WhisperModel(
    self.model_path,
    device=self.device,
    compute_type=self.compute_type,
    num_workers=4,
    cpu_threads=4,
    download_root=None,
    local_files_only=True  # ì™¸ë¶€ ë„¤íŠ¸ì›Œí¬ ì°¨ë‹¨!
)
```

**íš¨ê³¼**:
- âœ… ì™¸ë¶€ HuggingFace ì„œë²„ ì ‘ê·¼ ë¶ˆê°€ ì„¤ì •
- âœ… ë¡œì»¬ íŒŒì¼ë§Œ ì‚¬ìš© ê°•ì œ
- âœ… ë„¤íŠ¸ì›Œí¬ ì˜¤ë¥˜ ë°©ì§€

### 2. í™˜ê²½ ë³€ìˆ˜ (ì„ íƒì‚¬í•­)

Docker ì‹¤í–‰ ì‹œ ì¶”ê°€ ì„¤ì •:
```bash
docker run -d \
  --name stt-engine-gpu \
  --gpus all \
  -p 8003:8003 \
  -v /Users/a113211/workspace/stt_engine/models:/app/models \
  -e STT_DEVICE=cuda \
  -e STT_MODEL_PATH=/app/models \
  -e HF_HUB_OFFLINE=1 \
  -e TRANSFORMERS_OFFLINE=1 \
  stt-engine:cuda129-v1.0
```

| í™˜ê²½ë³€ìˆ˜ | íš¨ê³¼ |
|---------|------|
| `HF_HUB_OFFLINE=1` | HuggingFace Hub ì™„ì „ ì˜¤í”„ë¼ì¸ |
| `TRANSFORMERS_OFFLINE=1` | Transformers ë¼ì´ë¸ŒëŸ¬ë¦¬ ì˜¤í”„ë¼ì¸ |

---

## ğŸ“¦ í˜„ì¬ ìƒíƒœ

### í•„ìˆ˜ íŒŒì¼ (ë¡œì»¬ì— ì´ë¯¸ ì¤€ë¹„ë¨)
```
/Users/a113211/workspace/stt_engine/models/
â”œâ”€â”€ model.safetensors        âœ… (1.32 GB)
â”œâ”€â”€ config.json              âœ…
â”œâ”€â”€ preprocessor_config.json âœ…
â”œâ”€â”€ tokenizer.json           âœ…
â”œâ”€â”€ tokenizer_config.json    âœ…
â”œâ”€â”€ vocab.json               âœ…
â”œâ”€â”€ generation_config.json   âœ…
â””â”€â”€ merges.txt               âœ…
```

### Docker ë§ˆìš´íŠ¸
```
í˜¸ìŠ¤íŠ¸ ê²½ë¡œ: /Users/a113211/workspace/stt_engine/models
ì»¨í…Œì´ë„ˆ ê²½ë¡œ: /app/models
```

### ê²°ê³¼
- ğŸ“¡ ë„¤íŠ¸ì›Œí¬ ì ‘ê·¼: **ZERO**
- ğŸš€ ë¡œë“œ ì†ë„: **ë§¤ìš° ë¹ ë¦„** (ë¡œì»¬ íŒŒì¼)
- ğŸ”’ ë³´ì•ˆ: **ì™„ë²½** (ì˜¤í”„ë¼ì¸ ê°•ì œ)

---

## ğŸ§ª í…ŒìŠ¤íŠ¸ ëª…ë ¹ì–´

### ì˜¤í”„ë¼ì¸ í™˜ê²½ì—ì„œ ì‹¤í–‰
```bash
# Docker ì‹¤í–‰
bash run-docker-gpu.sh

# ë˜ëŠ” ìˆ˜ë™ ì‹¤í–‰ (í™˜ê²½ë³€ìˆ˜ í¬í•¨)
docker run -d \
  --name stt-engine-gpu \
  --gpus all \
  -p 8003:8003 \
  -v /Users/a113211/workspace/stt_engine/models:/app/models \
  -e HF_HUB_OFFLINE=1 \
  -e TRANSFORMERS_OFFLINE=1 \
  stt-engine:cuda129-v1.0
```

### í—¬ìŠ¤ ì²´í¬
```bash
# ëª¨ë¸ ë¡œë“œ ëŒ€ê¸° (ì•½ 30ì´ˆ)
sleep 30

# í—¬ìŠ¤ ì²´í¬
curl http://localhost:8003/health
```

### ë¡œê·¸ í™•ì¸
```bash
docker logs stt-engine-gpu

# ê¸°ëŒ€ ì¶œë ¥
# âœ… faster-whisper ëª¨ë¸ ë¡œë“œ ì™„ë£Œ
# âœ… STT Server started on 0.0.0.0:8003
```

---

## âœ… ìµœì¢… ì²´í¬ë¦¬ìŠ¤íŠ¸

- [x] ëª¨ë¸ íŒŒì¼ ì¤€ë¹„ (ë¡œì»¬)
- [x] `local_files_only=True` ì„¤ì • ì¶”ê°€
- [x] ë§ˆìš´íŠ¸ ê²½ë¡œ êµ¬ì„±
- [x] í™˜ê²½ ë³€ìˆ˜ ì„¤ì • (ì„ íƒ)
- [x] ì˜¤í”„ë¼ì¸ ì•ˆì •ì„± í™•ë³´

---

## ğŸ¯ ê²°ë¡ 

### ì™¸ë¶€ ë„¤íŠ¸ì›Œí¬ í•„ìš” ì—¬ë¶€
| ìƒí™© | ê²°ê³¼ |
|------|------|
| **ëª¨ë¸ ë³€í™˜** | âœ… ë„¤íŠ¸ì›Œí¬ ë¶ˆí•„ìš” (ë¡œì»¬) |
| **ëª¨ë¸ ë¡œë“œ** | âœ… ë„¤íŠ¸ì›Œí¬ ë¶ˆí•„ìš” (ë¡œì»¬) |
| **STT ì¶”ë¡ ** | âœ… ë„¤íŠ¸ì›Œí¬ ë¶ˆí•„ìš” (ë¡œì»¬) |
| **API í˜¸ì¶œ** | âœ… ë„¤íŠ¸ì›Œí¬ ë¶ˆí•„ìš” (ë¡œì»¬) |

**ìµœì¢… ê²°ë¡ **: ğŸ“¡ **ì™„ë²½í•œ ì˜¤í”„ë¼ì¸ í™˜ê²½ì—ì„œ ì‘ë™ ê°€ëŠ¥!**

---
**ì—…ë°ì´íŠ¸ ì¼ì‹œ**: 2026-02-03  
**ìƒíƒœ**: âœ… ì˜¤í”„ë¼ì¸ í™˜ê²½ ì„¤ì • ì™„ë£Œ
