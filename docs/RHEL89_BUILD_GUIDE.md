# RHEL 8.9 í™˜ê²½ì— ìµœì í™”ëœ STT Engine ë¹Œë“œ & ë°°í¬ ê°€ì´ë“œ

## ğŸ“Š ëŒ€ìƒ í™˜ê²½ ì •ë³´

```
ìš´ì˜ ì„œë²„ (RHEL 8.9):
â”œâ”€ OS: RHEL 8.9 (Ootpa)
â”œâ”€ glibc: 2.28
â”œâ”€ Python: 3.11.5
â”œâ”€ CUDA: 12.9
â”œâ”€ NVIDIA Driver: 575.57.08
â””â”€ Status: âœ… ëª¨ë“  ì •ë³´ í™•ì¸ë¨
```

---

## ğŸ¯ ë¹Œë“œ ì „ëµ

### ì„ íƒ ì‚¬í•­

| ë°©ì‹ | ì¥ì  | ë‹¨ì  | í˜¸í™˜ì„± |
|------|------|------|--------|
| **RHEL 8.9 EC2** ğŸ”´ | glibc ì™„ë²½ ì¼ì¹˜ | ì•½ê°„ ë¹„ìŒˆ | âœ… 100% |
| **Ubuntu 22.04 EC2** | ì €ë ´ | glibc ë¶ˆì¼ì¹˜ | âš ï¸ 90% |
| **ìš´ì˜ ì„œë²„ ì§ì ‘ ë¹Œë“œ** | ë¹„ìš© ì ˆê° | ë‹¤ìš´íƒ€ì„ | âœ… 100% |

### ğŸ”´ **ê¶Œì¥: RHEL 8.9 EC2 ë¹Œë“œ**
```
ì´ìœ :
1. íƒ€ê²Ÿ ì„œë²„ì™€ ë™ì¼í•œ glibc 2.28
2. ë¼ì´ë¸ŒëŸ¬ë¦¬ í˜¸í™˜ì„± 100%
3. ì•ˆì „ì„± ìµœìš°ì„ 
```

---

## ğŸ“‹ Step 1: AWS EC2 ìƒì„± (RHEL 8.9)

### 1-1. AMI ì„ íƒ
```bash
# AWS Consoleì—ì„œ:
1. EC2 > Instances > Launch Instance
2. "RHEL" ê²€ìƒ‰
3. "Red Hat Enterprise Linux 8 (HVM)" ì„ íƒ
4. Version: 8.9
```

### 1-2. ì¸ìŠ¤í„´ìŠ¤ íƒ€ì…
```
t3.large (4GB RAM, 2 vCPU)
ë˜ëŠ” t3.xlarge (8GB RAM, 4 vCPU - ê¶Œì¥)
```

### 1-3. Storage
```
EBS: 50GB ì´ìƒ (gp3 ê¶Œì¥)
```

### 1-4. Security Group
```
Inbound:
- SSH (Port 22) from your-ip
- Optional: HTTP (80), HTTPS (443)
```

---

## ğŸš€ Step 2: EC2ì— ì—°ê²° ë° í™˜ê²½ ì„¤ì •

### 2-1. SSH ì—°ê²°
```bash
ssh -i your-key.pem ec2-user@<ec2-ip>
```

### 2-2. í•„ìˆ˜ íŒ¨í‚¤ì§€ ì„¤ì¹˜
```bash
# RHEL 8.9 ê¸°ë³¸ ì—…ë°ì´íŠ¸
sudo yum update -y

# Development Tools ì„¤ì¹˜
sudo yum groupinstall -y "Development Tools"

# Docker ì„¤ì¹˜
sudo yum install -y docker git

# Docker ì‹œì‘
sudo systemctl start docker
sudo systemctl enable docker

# í˜„ì¬ ì‚¬ìš©ìì—ê²Œ Docker ê¶Œí•œ
sudo usermod -aG docker ec2-user
newgrp docker

# í™•ì¸
docker --version
git --version
```

---

## ğŸ“¥ Step 3: ë ˆí¬ì§€í† ë¦¬ í´ë¡ 

```bash
# ë°©ë²• A: Git í´ë¡  (ê¶Œì¥)
cd ~
git clone https://github.com/Kuwon-KIS/stt_engine.git
cd stt_engine

# ë°©ë²• B: scpë¡œ ë¡œì»¬ íŒŒì¼ ì „ì†¡
# Macì—ì„œ:
scp -i your-key.pem -r ~/workspace/stt_engine ec2-user@<ec2-ip>:~/
```

---

## ğŸ—ï¸ Step 4: Docker ì´ë¯¸ì§€ ë¹Œë“œ

### 4-1. ë¹Œë“œ ìŠ¤í¬ë¦½íŠ¸ ì‹¤í–‰ (ê¶Œì¥)
```bash
cd ~/stt_engine

# RHEL 8.9 ìµœì í™” ë¹Œë“œ ğŸ”´
bash scripts/build-stt-engine-rhel89.sh

# ë˜ëŠ” ì¼ë°˜ ë¹Œë“œ
bash scripts/build-stt-engine-ec2.sh
```

### 4-2. ë¹Œë“œ ë¡œê·¸ ëª¨ë‹ˆí„°ë§
```bash
# ë‹¤ë¥¸ í„°ë¯¸ë„ì—ì„œ:
ssh -i your-key.pem ec2-user@<ec2-ip>
watch -n 10 'docker ps -a && echo "---" && df -h'
```

### 4-3. ë¹Œë“œ ì™„ë£Œ í™•ì¸
```bash
docker images | grep stt-engine
# ì¶œë ¥:
# stt-engine   cuda129-rhel89-v1.2   <image-id>   <time>   1.5GB
```

**ì˜ˆìƒ ì†Œìš” ì‹œê°„: 20-30ë¶„**

---

## ğŸ’¾ Step 5: ì´ë¯¸ì§€ ì €ì¥ ë° ë‹¤ìš´ë¡œë“œ

### 5-1. EC2ì—ì„œ ì´ë¯¸ì§€ ì €ì¥
```bash
cd ~/stt_engine/build/output

# RHEL 8.9 ì´ë¯¸ì§€ ì €ì¥
docker save stt-engine:cuda129-rhel89-v1.2 | gzip > stt-engine-cuda129-rhel89-v1.2.tar.gz

# ë˜ëŠ” ì¼ë°˜ ì´ë¯¸ì§€
docker save stt-engine:cuda129-v1.2 | gzip > stt-engine-cuda129-v1.2.tar.gz

# íŒŒì¼ í™•ì¸
ls -lh *.tar.gz
# ì¶œë ¥: stt-engine-cuda129-rhel89-v1.2.tar.gz  500M
```

**ì†Œìš” ì‹œê°„: 3-5ë¶„**

### 5-2. Macìœ¼ë¡œ ë‹¤ìš´ë¡œë“œ
```bash
# Mac ë¡œì»¬ í„°ë¯¸ë„:
scp -i your-key.pem ec2-user@<ec2-ip>:~/stt_engine/build/output/stt-engine-cuda129-rhel89-v1.2.tar.gz \
    ~/Downloads/

# íŒŒì¼ í™•ì¸
ls -lh ~/Downloads/stt-engine-cuda129-rhel89-v1.2.tar.gz
```

**ì†Œìš” ì‹œê°„: 2-5ë¶„ (ë„¤íŠ¸ì›Œí¬ì— ë”°ë¼)**

### 5-3. MD5 ê²€ì¦ (ì„ íƒ)
```bash
# EC2ì—ì„œ:
md5sum build/output/stt-engine-cuda129-rhel89-v1.2.tar.gz > /tmp/image.md5

# Macìœ¼ë¡œ ë‹¤ìš´ë¡œë“œ:
scp -i your-key.pem ec2-user@<ec2-ip>:/tmp/image.md5 ~/Downloads/

# ê²€ì¦:
cd ~/Downloads
md5sum -c image.md5
```

---

## ğŸš¢ Step 6: ìš´ì˜ ì„œë²„ì— ë°°í¬

### 6-1. ì´ë¯¸ì§€ ì—…ë¡œë“œ
```bash
# Macì—ì„œ:
scp -P 22 ~/Downloads/stt-engine-cuda129-rhel89-v1.2.tar.gz \
    deploy-user@production-server:/tmp/
```

### 6-2. ìš´ì˜ ì„œë²„ì—ì„œ ë¡œë“œ
```bash
# RHEL 8.9 ìš´ì˜ ì„œë²„:
cd /tmp

# 1. ì••ì¶• í•´ì œ
gunzip stt-engine-cuda129-rhel89-v1.2.tar.gz

# 2. Dockerì— ë¡œë“œ
docker load < stt-engine-cuda129-rhel89-v1.2.tar

# 3. í™•ì¸
docker images | grep stt-engine
# ì¶œë ¥: stt-engine  cuda129-rhel89-v1.2  <image-id>  1.5GB
```

---

## âœ… Step 7: ì´ë¯¸ì§€ ê²€ì¦ (ìš´ì˜ ì„œë²„)

### 7-1. PyTorch/CUDA ê²€ì¦
```bash
docker run --rm stt-engine:cuda129-rhel89-v1.2 python3.11 -c "
import torch
print(f'âœ… PyTorch: {torch.__version__}')
print(f'âœ… CUDA Available: {torch.cuda.is_available()}')
print(f'âœ… cuDNN: OK')
"

# ì˜ˆìƒ ì¶œë ¥:
# âœ… PyTorch: 2.6.0
# âœ… CUDA Available: True
# âœ… cuDNN: OK
```

### 7-2. Whisper ê²€ì¦
```bash
docker run --rm stt-engine:cuda129-rhel89-v1.2 python3.11 -c "
try:
    import faster_whisper
    print('âœ… faster-whisper: ë¡œë“œë¨')
except:
    print('âš ï¸  faster-whisper: ë¯¸ì‚¬ìš©')
    
try:
    import whisper
    print('âœ… openai-whisper: ë¡œë“œë¨')
except:
    print('âš ï¸  openai-whisper: ë¯¸ì‚¬ìš©')
"
```

### 7-3. API í—¬ìŠ¤ ì²´í¬
```bash
# ëª¨ë¸ ë‹¤ìš´ë¡œë“œ (ì²˜ìŒ 1íšŒ, 5-10ë¶„)
docker run -it --rm \
  -v /path/to/models:/app/models \
  stt-engine:cuda129-rhel89-v1.2 \
  python3.11 -c 'import whisper; whisper.load_model("large-v3")'

# API ì„œë²„ ì‹¤í–‰
docker run -d \
  --name stt-api \
  --gpus all \
  -p 8003:8003 \
  -v /path/to/models:/app/models \
  -e STT_DEVICE=cuda \
  stt-engine:cuda129-rhel89-v1.2

# í—¬ìŠ¤ ì²´í¬
sleep 10
curl http://localhost:8003/health
# ì˜ˆìƒ: {"status":"ok","backend":"faster-whisper"}
```

---

## ğŸ“Š ì˜ˆìƒ ì†Œìš” ì‹œê°„

| ë‹¨ê³„ | ì‹œê°„ |
|------|------|
| EC2 ìƒì„± | 2ë¶„ |
| Docker/Git ì„¤ì¹˜ | 5ë¶„ |
| ë ˆí¬ì§€í† ë¦¬ í´ë¡  | 2ë¶„ |
| **Docker ë¹Œë“œ** | **20-30ë¶„** |
| ì´ë¯¸ì§€ ì €ì¥ | 5ë¶„ |
| Mac ë‹¤ìš´ë¡œë“œ | 5ë¶„ |
| ìš´ì˜ ì„œë²„ ì—…ë¡œë“œ | 5ë¶„ |
| ì´ë¯¸ì§€ ë¡œë“œ | 3ë¶„ |
| ê²€ì¦ | 5ë¶„ |
| **ì´í•©** | **~60ë¶„** |

---

## ğŸ” ë¬¸ì œ í•´ê²°

### ë¹Œë“œ ì‹¤íŒ¨ - "ã‚¤ãƒ³ã‚¿ãƒ¼ãƒãƒƒãƒˆæ¥ç¶šãŒã‚ã‚Šã¾ã›ã‚“"
```bash
# EC2ì˜ ì¸í„°ë„· ì—°ê²° í™•ì¸
ping google.com

# DNS í™•ì¸
nslookup github.com

# ì¬ì‹œë„
bash scripts/build-stt-engine-rhel89.sh
```

### ì´ë¯¸ì§€ ë¡œë“œ ì‹¤íŒ¨ - "unknown file format"
```bash
# íŒŒì¼ ì†ìƒ í™•ì¸
file stt-engine-cuda129-rhel89-v1.2.tar.gz
# ì¶œë ¥: gzip compressed data

# ì••ì¶• í™•ì¸
gunzip -t stt-engine-cuda129-rhel89-v1.2.tar.gz

# MD5 ê²€ì¦
md5sum -c stt-engine-cuda129-rhel89-v1.2.tar.gz.md5
```

### CUDA ì¸ì‹ ì•ˆë¨
```bash
# ìš´ì˜ ì„œë²„ì˜ CUDA í™•ì¸
nvidia-smi
nvcc --version

# Docker ë‚´ë¶€ì˜ CUDA í™•ì¸
docker run --rm --gpus all stt-engine:cuda129-rhel89-v1.2 \
  python3.11 -c "import torch; print(torch.cuda.is_available())"
```

### ë””ìŠ¤í¬ ë¶€ì¡±
```bash
# EC2 ë””ìŠ¤í¬ í™•ì¸
df -h

# ë¶ˆí•„ìš”í•œ ì´ë¯¸ì§€ ì •ë¦¬
docker system prune -a
docker builder prune

# ê¶Œì¥: 50GB ì´ìƒ í•„ìš”
```

---

## ğŸ“ ì²´í¬ë¦¬ìŠ¤íŠ¸

```
[ ] RHEL 8.9 ì •ë³´ ìˆ˜ì§‘ ì™„ë£Œ
    - OS: 8.9
    - glibc: 2.28
    - Python: 3.11.5
    - CUDA: 12.9
    - NVIDIA Driver: 575.57.08

[ ] AWS EC2 RHEL 8.9 ìƒì„±
    - t3.large ì´ìƒ
    - 50GB ìŠ¤í† ë¦¬ì§€
    - Security Group ì„¤ì •

[ ] EC2 í™˜ê²½ ì„¤ì •
    - Docker ì„¤ì¹˜
    - Git ì„¤ì¹˜
    - ì‚¬ìš©ì ê¶Œí•œ ì„¤ì •

[ ] ë ˆí¬ì§€í† ë¦¬ í´ë¡ /ì „ì†¡

[ ] Docker ë¹Œë“œ ì‹¤í–‰
    - scripts/build-stt-engine-rhel89.sh

[ ] ì´ë¯¸ì§€ ì €ì¥ (.tar.gz)

[ ] Macìœ¼ë¡œ ë‹¤ìš´ë¡œë“œ

[ ] ìš´ì˜ ì„œë²„ì— ì—…ë¡œë“œ

[ ] ì´ë¯¸ì§€ ë¡œë“œ
    - docker load < stt-engine-cuda129-rhel89-v1.2.tar

[ ] PyTorch/CUDA ê²€ì¦

[ ] Whisper ê²€ì¦

[ ] API í—¬ìŠ¤ ì²´í¬
```

---

## ğŸ¯ ë‹¤ìŒ ë‹¨ê³„

ë¹Œë“œ ì™„ë£Œ í›„:

1. **ëª¨ë¸ ë‹¤ìš´ë¡œë“œ**
   ```bash
   docker run -it --rm \
     -v /path/to/models:/app/models \
     stt-engine:cuda129-rhel89-v1.2 \
     python3.11 -c 'import whisper; whisper.load_model("large-v3")'
   ```

2. **STT API ì„œë²„ ì‹¤í–‰**
   ```bash
   docker run -d \
     --name stt-api \
     --gpus all \
     -p 8003:8003 \
     -v /path/to/models:/app/models \
     -e STT_DEVICE=cuda \
     stt-engine:cuda129-rhel89-v1.2
   ```

3. **íŠ¸ëœìŠ¤í¬ë¦½ì…˜ í…ŒìŠ¤íŠ¸**
   ```bash
   curl -X POST http://localhost:8003/transcribe \
     -F "file=@/path/to/audio.wav"
   ```

---

## ğŸ“ íŠ¸ëŸ¬ë¸”ìŠˆíŒ…

ë¬¸ì œ ë°œìƒ ì‹œ í™•ì¸ì‚¬í•­:

1. EC2 ì¸í„°ë„· ì—°ê²°
2. Docker ì´ë¯¸ì§€ í¬ê¸° (1.5GB ì´ìƒ)
3. glibc ë²„ì „ (ìš´ì˜ ì„œë²„ 2.28ê³¼ ë™ì¼)
4. CUDA/NVIDIA Driver (12.9+)
5. ë””ìŠ¤í¬ ì—¬ìœ  ê³µê°„ (50GB ì´ìƒ)

---

**ë§ˆì§€ë§‰ ì—…ë°ì´íŠ¸**: 2026ë…„ 2ì›” 5ì¼
