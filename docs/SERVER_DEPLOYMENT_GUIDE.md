# ğŸš€ Linux ì„œë²„ ë°°í¬ ì‹¤í–‰ ê°€ì´ë“œ

**ëŒ€ìƒ**: tar íŒŒì¼ ì„œë²„ ì „ì†¡ í›„ ë‹¨ê³„  
**ì†Œìš” ì‹œê°„**: ~10ë¶„  

---

## ğŸ“‹ ì‚¬ì „ í™•ì¸ì‚¬í•­

ì„œë²„ì— ë‹¤ìŒì´ ìˆëŠ”ì§€ í™•ì¸:

```bash
# 1. Docker ì„¤ì¹˜ í™•ì¸
docker --version
# ì˜ˆìƒ ì¶œë ¥: Docker version 20.10 ì´ìƒ

# 2. Python ì„¤ì¹˜ í™•ì¸
python3.11 --version
# ì˜ˆìƒ ì¶œë ¥: Python 3.11.x

# 3. ë””ìŠ¤í¬ ê³µê°„ í™•ì¸ (ìµœì†Œ 5GB)
df -h / | tail -1
```

---

## ğŸ”§ Step 1: Docker ì´ë¯¸ì§€ ë¡œë“œ

```bash
# 1-1. ì´ë¯¸ì§€ íŒŒì¼ì´ ìˆëŠ” ë””ë ‰í† ë¦¬ë¡œ ì´ë™
cd /path/to/deployment_files

# 1-2. ì´ë¯¸ì§€ ë¡œë“œ
docker load -i stt-engine-linux-x86_64.tar

# âœ… ì˜ˆìƒ ì¶œë ¥
# Loaded image: stt-engine:linux-x86_64

# 1-3. ì´ë¯¸ì§€ í™•ì¸
docker images | grep stt-engine
# stt-engine              linux-x86_64   <id>  <date>   1.1GB
```

---

## ğŸ“¦ Step 2: Wheel íŒŒì¼ ì¤€ë¹„ (2ê°€ì§€ ë°©ë²•)

### ë°©ë²• A: ë³„ë„ wheels.tar.gz ì‚¬ìš© (ê¶Œì¥)

```bash
# 2A-1. ì••ì¶• í•´ì œ
tar -xzf wheels.tar.gz
# ìƒì„±: wheels/ ë””ë ‰í† ë¦¬

# 2A-2. í™•ì¸
ls -1 wheels/ | head -10
# 61ê°œ íŒŒì¼ì´ ë³´ì´ë©´ ì •ìƒ
```

### ë°©ë²• B: ì˜¨ë¼ì¸ì—ì„œ ì§ì ‘ ì„¤ì¹˜

```bash
# wheel íŒŒì¼ ì—†ì´ PyPIì—ì„œ ë‹¤ìš´ë¡œë“œ
# (ì¸í„°ë„· ì—°ê²° í•„ìš”)
docker run --rm stt-engine:linux-x86_64 \
  pip install torch torchaudio faster-whisper fastapi uvicorn
```

---

## ğŸ¯ Step 3: ëª¨ë¸ íŒŒì¼ ì¤€ë¹„ (3ê°€ì§€ ì„ íƒ)

### ë°©ë²• A: ì••ì¶•ëœ ëª¨ë¸ ì‚¬ìš© (ì¶”ì²œ - ê°€ì¥ ë¹ ë¦„)

```bash
# 3A-1. ë¡œì»¬ì—ì„œ ëª¨ë¸ ì „ì†¡
scp models/whisper-model.tar.gz user@server:/path/to/deployment/

# 3A-2. ì„œë²„ì—ì„œ ì••ì¶• í•´ì œ
tar -xzf whisper-model.tar.gz -C ./

# ìƒì„±: openai_whisper-large-v3-turbo/ ë””ë ‰í† ë¦¬
# ì´ ë””ë ‰í† ë¦¬ë¥¼ Dockerì— ë§ˆìš´íŠ¸
```

### ë°©ë²• B: ì²˜ìŒë¶€í„° ë‹¤ìš´ë¡œë“œ (ì˜¨ë¼ì¸ í•„ìš”)

```bash
# Docker ì‹¤í–‰ ì‹œ ìë™ìœ¼ë¡œ ì²« ì‚¬ìš© ë•Œ ë‹¤ìš´ë¡œë“œë¨
# (ì•½ 5-10ë¶„ ì†Œìš”, ëª¨ë¸ í¬ê¸°ì— ë”°ë¼)
# ì´í›„ ë””ìŠ¤í¬ì— ìºì‹œë˜ì–´ ì¬ì‚¬ìš© ê°€ëŠ¥
```

### ë°©ë²• C: NFS ê³µìœ  ìŠ¤í† ë¦¬ì§€ ì‚¬ìš©

```bash
# ì¤‘ì•™ ì €ì¥ì†Œì— ëª¨ë¸ ì €ì¥
/mnt/shared_models/openai_whisper-large-v3-turbo/

# ê° ì„œë²„ì—ì„œëŠ” ë§ˆìš´íŠ¸ë§Œ
```

---

## ğŸ³ Step 4: Docker ì»¨í…Œì´ë„ˆ ì‹¤í–‰

### ë°©ë²• 1: ë‹¨ìˆœ Docker run (ê¶Œì¥ for í…ŒìŠ¤íŠ¸)

```bash
docker run -d \
  --name stt-engine \
  -p 8003:8003 \
  -v /path/to/models:/app/models \
  -v /path/to/logs:/app/logs \
  stt-engine:linux-x86_64

# ì‹¤í–‰ ê²°ê³¼ í™•ì¸
docker ps | grep stt-engine
```

**ê²½ë¡œ ì„¤ëª…**:
- `/path/to/models` â†’ ë¡œì»¬ ëª¨ë¸ ê²½ë¡œ (ì ˆëŒ€ê²½ë¡œ ê¶Œì¥)
- `/path/to/logs` â†’ ë¡œê·¸ ì €ì¥ ê²½ë¡œ (ì„ íƒì‚¬í•­)
- `8003` â†’ API í¬íŠ¸

**êµ¬ì²´ì  ì˜ˆì‹œ**:
```bash
docker run -d \
  --name stt-engine \
  -p 8003:8003 \
  -v /home/user/deployment/openai_whisper-large-v3-turbo:/app/models/openai_whisper-large-v3-turbo \
  -v /home/user/logs:/app/logs \
  stt-engine:linux-x86_64
```

---

### ë°©ë²• 2: Docker Compose (ê¶Œì¥ for í”„ë¡œë•ì…˜)

**docker-compose.yml** ì‘ì„±:
```yaml
version: '3.8'

services:
  stt-engine:
    image: stt-engine:linux-x86_64
    container_name: stt-engine
    
    ports:
      - "8003:8003"
    
    volumes:
      - /path/to/models:/app/models
      - /path/to/logs:/app/logs
    
    environment:
      - HF_HOME=/app/models
      - PYTHONUNBUFFERED=1
    
    restart: unless-stopped
    
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8003/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 10s
```

**ì‹¤í–‰**:
```bash
docker-compose up -d

# ë¡œê·¸ í™•ì¸
docker-compose logs -f
```

**ì¤‘ì§€/ì‹œì‘**:
```bash
docker-compose stop
docker-compose start
docker-compose down  # ì™„ì „ ì œê±°
```

---

## âœ… Step 5: ì„œë¹„ìŠ¤ ê²€ì¦

### 5-1. ì»¨í…Œì´ë„ˆ ìƒíƒœ í™•ì¸

```bash
# ì‹¤í–‰ ì¤‘ì¸ì§€ í™•ì¸
docker ps | grep stt-engine

# ë¡œê·¸ í™•ì¸
docker logs stt-engine

# ì˜ˆìƒ ë¡œê·¸:
# âœ… faster-whisper ëª¨ë¸ ë¡œë“œ ì™„ë£Œ (Device: cuda, compute: float16)
# INFO:     Uvicorn running on http://0.0.0.0:8003
```

### 5-2. API í—¬ìŠ¤ ì²´í¬

```bash
# í—¬ìŠ¤ ì²´í¬ ì—”ë“œí¬ì¸íŠ¸
curl http://localhost:8003/health

# ì˜ˆìƒ ì‘ë‹µ:
# {"status":"ok","version":"1.0.0","engine":"faster-whisper"}
```

### 5-3. ì‹¤ì œ ìŒì„± ì¸ì‹ í…ŒìŠ¤íŠ¸

```bash
# í…ŒìŠ¤íŠ¸ ìŒì„± íŒŒì¼ ì¤€ë¹„
curl -X POST -F "file=@test_audio.wav" \
  http://localhost:8003/transcribe

# ì˜ˆìƒ ì‘ë‹µ:
# {
#   "success": true,
#   "text": "ì¸ì‹ëœ í…ìŠ¤íŠ¸",
#   "language": "ko",
#   "duration": 5.2
# }
```

---

## ğŸ”— Step 6: ë°©í™”ë²½ ë° ë„¤íŠ¸ì›Œí¬ ì„¤ì •

### í¬íŠ¸ ê°œë°© (Linux ë°©í™”ë²½)

```bash
# firewalld ì‚¬ìš©
sudo firewall-cmd --permanent --add-port=8003/tcp
sudo firewall-cmd --reload

# ufw ì‚¬ìš© (Ubuntu)
sudo ufw allow 8003/tcp

# í™•ì¸
sudo firewall-cmd --list-ports
```

### ì™¸ë¶€ ì ‘ê·¼ ì„¤ì •

```bash
# ë¡œì»¬ë§Œ ì ‘ê·¼ (ê¸°ë³¸)
docker run -p 127.0.0.1:8003:8003 ...

# ì™¸ë¶€ ì ‘ê·¼ í—ˆìš©
docker run -p 0.0.0.0:8003:8003 ...

# ë˜ëŠ” ë¦¬ë²„ìŠ¤ í”„ë¡ì‹œ (Nginx ê¶Œì¥)
```

---

## ğŸ“Š Step 7: ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§

### ë¦¬ì†ŒìŠ¤ ì‚¬ìš©ëŸ‰ í™•ì¸

```bash
# ì‹¤ì‹œê°„ ëª¨ë‹ˆí„°ë§
docker stats stt-engine

# ì˜ˆìƒ ì¶œë ¥:
# CONTAINER   CPU %   MEM USAGE / LIMIT   NET I/O
# stt-engine  2.5%    2.1G / 8G          125MB / 89MB
```

### ë¡œê·¸ ëª¨ë‹ˆí„°ë§

```bash
# ë§ˆì§€ë§‰ 100ì¤„ ë³´ê¸°
docker logs --tail 100 stt-engine

# ì‹¤ì‹œê°„ ë¡œê·¸
docker logs -f stt-engine

# íƒ€ì„ìŠ¤íƒ¬í”„ í¬í•¨
docker logs -f --timestamps stt-engine
```

---

## ğŸ› ï¸ Step 8: ë¬¸ì œ í•´ê²°

### ë¬¸ì œ 1: ì´ë¯¸ì§€ ë¡œë“œ ì‹¤íŒ¨

```bash
# ì›ì¸: tar íŒŒì¼ ì†ìƒ ë˜ëŠ” ê²½ë¡œ ì˜¤ë¥˜
# í•´ê²°
docker load -i /full/path/to/stt-engine-linux-x86_64.tar

# ë¡œë“œ ì§„í–‰ë¥  í™•ì¸
docker load -i stt-engine-linux-x86_64.tar 2>&1 | tail -20
```

### ë¬¸ì œ 2: ì»¨í…Œì´ë„ˆ ì‹œì‘ ì‹¤íŒ¨

```bash
# ë¡œê·¸ í™•ì¸
docker logs stt-engine

# ê³µí†µ ì›ì¸:
# - ëª¨ë¸ ê²½ë¡œ ì˜ëª»ë¨ â†’ -v ê²½ë¡œ í™•ì¸
# - í¬íŠ¸ ì´ë¯¸ ì‚¬ìš© ì¤‘ â†’ docker ps í™•ì¸
# - ë©”ëª¨ë¦¬ ë¶€ì¡± â†’ free -h í™•ì¸
```

### ë¬¸ì œ 3: ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨

```bash
# ëª¨ë¸ íŒŒì¼ì´ ì¡´ì¬í•˜ëŠ”ì§€ í™•ì¸
docker exec stt-engine ls -lh /app/models/

# ê¶Œí•œ í™•ì¸
ls -la /path/to/models/

# í•´ê²°
chmod -R 755 /path/to/models/
docker restart stt-engine
```

### ë¬¸ì œ 4: CUDA/GPU ì¸ì‹ ì‹¤íŒ¨

```bash
# GPU ë“œë¼ì´ë²„ í™•ì¸
nvidia-smi

# NVIDIA Docker ì„¤ì¹˜ í™•ì¸
docker run --rm --gpus all nvidia/cuda:12.1 nvidia-smi

# GPU ì‚¬ìš©í•˜ëŠ” Docker ì‹¤í–‰
docker run -d \
  --gpus all \
  -p 8003:8003 \
  -v /path/to/models:/app/models \
  stt-engine:linux-x86_64
```

---

## ğŸ“‹ ì™„ì „ ë°°í¬ ì²´í¬ë¦¬ìŠ¤íŠ¸

```
âœ… ì‚¬ì „ í™•ì¸
  â–¡ Docker ì„¤ì¹˜ (v20.10+)
  â–¡ Python 3.11 ì„¤ì¹˜
  â–¡ ë””ìŠ¤í¬ ê³µê°„ 5GB ì´ìƒ
  â–¡ ë„¤íŠ¸ì›Œí¬ ì—°ê²° (ì²« ëª¨ë¸ ë‹¤ìš´ë¡œë“œ ì‹œ)

âœ… Step 1: ì´ë¯¸ì§€ ë¡œë“œ
  â–¡ docker load -i stt-engine-linux-x86_64.tar
  â–¡ docker images | grep stt-engine í™•ì¸

âœ… Step 2: Wheel ì¤€ë¹„
  â–¡ tar -xzf wheels.tar.gz ë˜ëŠ” PyPI ì„¤ì¹˜
  â–¡ wheel íŒŒì¼ 61ê°œ í™•ì¸

âœ… Step 3: ëª¨ë¸ ì¤€ë¹„
  â–¡ tar -xzf whisper-model.tar.gz
  â–¡ openai_whisper-large-v3-turbo/ í™•ì¸

âœ… Step 4: ì»¨í…Œì´ë„ˆ ì‹¤í–‰
  â–¡ docker run ë˜ëŠ” docker-compose up
  â–¡ docker ps ì—ì„œ stt-engine ë³´ì„

âœ… Step 5: ê²€ì¦
  â–¡ curl http://localhost:8003/health
  â–¡ ì‘ë‹µ: {"status":"ok",...}
  â–¡ ìŒì„± íŒŒì¼ í…ŒìŠ¤íŠ¸ (ì„ íƒ)

âœ… Step 6: ë„¤íŠ¸ì›Œí¬
  â–¡ ë°©í™”ë²½ í¬íŠ¸ 8003 ê°œë°©
  â–¡ ë³´ì•ˆ ê·¸ë£¹ ì„¤ì • í™•ì¸

âœ… Step 7: ëª¨ë‹ˆí„°ë§
  â–¡ docker stats ì •ìƒ
  â–¡ docker logs ì—ëŸ¬ ì—†ìŒ

âœ… Step 8: ë°±ì—…
  â–¡ ì„¤ì • íŒŒì¼ ë°±ì—…
  â–¡ ëª¨ë¸ ê²½ë¡œ ê¸°ë¡
```

---

## ğŸ¯ Quick Start (ì™„ì „ ìë™)

ìœ„ ë‹¨ê³„ë¥¼ ìë™í™”í•œ ìŠ¤í¬ë¦½íŠ¸:

```bash
#!/bin/bash
set -e

# ì„¤ì •
IMAGE_FILE="stt-engine-linux-x86_64.tar"
WHEELS_FILE="wheels.tar.gz"
MODEL_FILE="whisper-model.tar.gz"
MODELS_PATH="/home/user/deployment/models"
LOGS_PATH="/home/user/deployment/logs"

echo "ğŸš€ STT Engine ë°°í¬ ì‹œì‘..."

# 1. ì´ë¯¸ì§€ ë¡œë“œ
echo "ğŸ“¦ Docker ì´ë¯¸ì§€ ë¡œë“œ ì¤‘..."
docker load -i "$IMAGE_FILE"

# 2. ëª¨ë¸ ì¤€ë¹„
echo "ğŸ¯ ëª¨ë¸ íŒŒì¼ ì¤€ë¹„ ì¤‘..."
mkdir -p "$MODELS_PATH"
tar -xzf "$MODEL_FILE" -C "$MODELS_PATH/.."

# 3. ì»¨í…Œì´ë„ˆ ì‹¤í–‰
echo "ğŸ³ ì»¨í…Œì´ë„ˆ ì‹¤í–‰ ì¤‘..."
docker run -d \
  --name stt-engine \
  -p 8003:8003 \
  -v "$MODELS_PATH":/app/models \
  -v "$LOGS_PATH":/app/logs \
  stt-engine:linux-x86_64

# 4. ê²€ì¦
echo "âœ… ì„œë¹„ìŠ¤ ê²€ì¦ ì¤‘..."
sleep 3
curl http://localhost:8003/health

echo "ğŸ‰ ë°°í¬ ì™„ë£Œ!"
echo "ğŸ“ API: http://localhost:8003"
echo "ğŸ“Š ë¡œê·¸: docker logs -f stt-engine"
```

---

## ğŸ“ ì§€ì› ë° ë‹¤ìŒ ë‹¨ê³„

**ë°°í¬ í›„**:
1. âœ… í—¬ìŠ¤ ì²´í¬ í™•ì¸
2. âœ… í…ŒìŠ¤íŠ¸ ìŒì„± íŒŒì¼ë¡œ ì¸ì‹ í…ŒìŠ¤íŠ¸
3. âœ… ëª¨ë‹ˆí„°ë§ ì„¤ì • (docker stats, ë¡œê·¸ ìˆ˜ì§‘)
4. âœ… ë°±ì—… ì •ì±… ìˆ˜ë¦½
5. âœ… ìë™ ì¬ì‹œì‘ ì„¤ì • (systemd ë˜ëŠ” docker restart policy)

**ë³´ì•ˆ ê¶Œì¥ì‚¬í•­**:
- ë°©í™”ë²½ìœ¼ë¡œ í¬íŠ¸ 8003 ì œí•œ
- HTTPS/SSL ì¸ì¦ì„œ ì¶”ê°€ (ë¦¬ë²„ìŠ¤ í”„ë¡ì‹œ)
- ì¸ì¦ ì¶”ê°€ (API í‚¤, JWT í† í°)
- ì •ê¸° ëª¨ë‹ˆí„°ë§ ë° ë¡œê·¸ ìˆ˜ì§‘

---

**ìƒíƒœ**: ğŸŸ¢ ì„œë²„ ë°°í¬ ì™„ë²½ ì¤€ë¹„ âœ…
