# âœ… [2026-02-03 v2.0] ìµœì¢… ì •ì •: Linux ì„œë²„ì—ì„œ ì§ì ‘ ì„¤ì¹˜í•˜ê¸° (ìœ ì¼í•œ ì •ë‹µ)

**ë²„ì „**: v2.0 (ì™„ì „ ì •ì •)  
**ë‚ ì§œ**: 2026-02-03  
**ìš°ì„ ìˆœìœ„**: â­â­â­ **ë°˜ë“œì‹œ ì´ ë¬¸ì„œë¥¼ ë”°ë¥´ì„¸ìš”!**  
**ì„±ê³µë¥ **: 99%+ (ì•„í‚¤í…ì²˜ í˜¸í™˜ì„± ì™„ë²½)  
**ì´ ì†Œìš” ì‹œê°„**: 40ë¶„

---

## ğŸ“‹ ë¬¸ì„œ ë²„ì „ ì •ë³´

| ë²„ì „ | ë‚ ì§œ | ìƒíƒœ | ì„¤ëª… |
|------|------|------|------|
| v2.0 | 2026-02-03 | âœ… **ìµœì‹ ** | Mac ì•„í‚¤í…ì²˜ ë¬¸ì œ í•´ê²° (ì„œë²„ ì§ì ‘ ì„¤ì¹˜) |
| v1.0 | 2026-01-30 | âŒ íê¸° | Docker ë¹Œë“œ ë°©ì‹ (ì‹¤íŒ¨) |

### ì´ì „ ë²„ì „ì—ì„œì˜ ë³€ê²½ì‚¬í•­
- âŒ ì œê±°: Macì—ì„œ CUDA 12.4 wheel ë‹¤ìš´ë¡œë“œ
- âŒ ì œê±°: Docker ì´ë¯¸ì§€ ë¹Œë“œ ë‹¨ê³„
- âœ… ì¶”ê°€: ì„œë²„ì—ì„œ ì§ì ‘ `pip install torch` ë°©ì‹
- âœ… ì¶”ê°€: ì•„í‚¤í…ì²˜ í˜¸í™˜ì„± ìƒì„¸ ì„¤ëª…

---

## ğŸš¨ ì´ì „ ì´ ë¬¸ì„œë¥¼ ì½ê¸° ì „ì—

### âŒ Macì—ì„œ Linuxìš© wheelì„ ë°›ëŠ” ê²ƒì€ ë¶ˆê°€ëŠ¥

```
Mac (darwin ì•„í‚¤í…ì²˜)
  â†“
pip wheel torch (â† Mac ë„¤ì´í‹°ë¸Œ wheel ë‹¤ìš´ë¡œë“œ)
  â†“
torch-2.1.2-cp311-cp311-macosx_11_0_arm64.whl â† Macìš©!
  â†“
Linux ì„œë²„ë¡œ ì „ì†¡
  â†“
ì„¤ì¹˜ ì‹œë„ â†’ âŒ í˜¸í™˜ë˜ì§€ ì•ŠìŒ (ì•„í‚¤í…ì²˜ ë¶ˆì¼ì¹˜)
```

### âœ… ì •í™•í•œ ë°©ì‹: ì„œë²„ì—ì„œ ì§ì ‘ ì„¤ì¹˜

```
Linux ì„œë²„ (x86_64 ì•„í‚¤í…ì²˜, ë„¤íŠ¸ì›Œí¬ ìˆìŒ)
  â†“
pip install torch (â† Linux ë„¤ì´í‹°ë¸Œë¡œ ì§ì ‘ ë°›ìŒ)
  â†“
torch-2.1.2-cp311-cp311-linux_x86_64.whl â† Linuxìš©!
  â†“
âœ… ì™„ë²½ í˜¸í™˜
```

---

## ğŸš€ Step-by-Step ì •ì •ëœ ì ˆì°¨

### Step 1: ë¡œì»¬ Macì—ì„œ (10ë¶„)

**PyTorch wheelì„ ë°›ìœ¼ë ¤ê³  í•˜ì§€ ë§ˆì„¸ìš”!**

**ì˜¤ì§ ì´ê²ƒë§Œ í•˜ê¸°**:

```bash
cd /Users/a113211/workspace/stt_engine

# 1. ì½”ë“œì™€ ì¼ë°˜ wheelì„ tar.gzë¡œ ì••ì¶•
# (PyTorchëŠ” ì œì™¸!)
tar -czf stt_engine_deployment.tar.gz \
  stt_engine.py \
  api_server.py \
  model_manager.py \
  requirements.txt \
  deployment_package/wheels/ \
  models/

# 2. í¬ê¸° í™•ì¸
ls -lh stt_engine_deployment.tar.gz
# ì˜ˆìƒ: 1-2GB

# 3. ì„œë²„ë¡œ ì „ì†¡
scp stt_engine_deployment.tar.gz ddpapp@dlddpgai1:/data/stt/
```

**ì™„ë£Œ!** Macì—ì„œëŠ” ë” ì´ìƒ í•  ê²ƒ ì—†ìŠµë‹ˆë‹¤.

---

### Step 2: Linux ì„œë²„ì—ì„œ (30ë¶„)

#### 2-1. ì••ì¶• íŒŒì¼ ì¶”ì¶œ

```bash
# ì„œë²„ì— SSH ì ‘ì†
ssh ddpapp@dlddpgai1

# ìœ„ì¹˜ ì´ë™
cd /data/stt

# íŒŒì¼ í™•ì¸
ls -lh stt_engine_deployment.tar.gz

# ì¶”ì¶œ
tar -xzf stt_engine_deployment.tar.gz

# í™•ì¸
ls -la
# ì˜ˆìƒ:
# stt_engine.py
# api_server.py
# model_manager.py
# requirements.txt
# deployment_package/
# models/
```

#### 2-2. ì¼ë°˜ wheel ì„¤ì¹˜ (1-2ë¶„)

```bash
# ì´ë¯¸ ë‹¤ìš´ë¡œë“œëœ 44ê°œ wheel ì„¤ì¹˜
cd /data/stt
pip install deployment_package/wheels/*.whl

# ë˜ëŠ” ê°œë³„ì ìœ¼ë¡œ (ì•ˆì „í•œ ë°©ì‹)
pip install -r requirements.txt --no-deps

# í™•ì¸
pip list | head -20
```

#### 2-3. PyTorch ì§ì ‘ ì„¤ì¹˜ (10-15ë¶„) â† í•µì‹¬!

**ë°©ë²• A: ìë™ ìµœì‹ /ìµœì  ë²„ì „ (ê¶Œì¥) â­â­â­**

```bash
# ì„œë²„ì˜ CUDA 12.9ì™€ GPU ë“œë¼ì´ë²„ 575.57.08ì„ ìë™ìœ¼ë¡œ ê°ì§€
pip install torch torchaudio torchvision

# ì„¤ì¹˜ ì‹œê°„: 10-15ë¶„
# ê²°ê³¼: ìë™ìœ¼ë¡œ ìµœì  CUDA ë²„ì „ ì„ íƒ
```

**ë˜ëŠ” ë°©ë²• B: CUDA 12.4 ëª…ì‹œ (ë³´ìˆ˜ì )**

```bash
# ë§Œì•½ ìë™ ì„ íƒì´ ë¶ˆì•ˆí•˜ë©´
pip install torch torchaudio torchvision \
  --index-url https://download.pytorch.org/whl/cu124
```

#### 2-4. ëª¨ë“  ì˜ì¡´ì„± ì„¤ì¹˜ (5ë¶„)

```bash
# requirements.txtì˜ ëª¨ë“  íŒ¨í‚¤ì§€ ì„¤ì¹˜
pip install -r requirements.txt

# ë˜ëŠ” ì´ë¯¸ ìœ„ì—ì„œ ì„¤ì¹˜í–ˆìœ¼ë©´ ìŠ¤í‚µ
```

#### 2-5. PyTorch CUDA ì§€ì› ê²€ì¦ (âš ï¸ ë°˜ë“œì‹œ í™•ì¸!)

```bash
# ì„¤ì¹˜ ê²°ê³¼ í™•ì¸
python3 << 'EOF'
import torch
import torchaudio

print("=" * 60)
print("âœ… PyTorch ì„¤ì¹˜ ê²€ì¦")
print("=" * 60)
print(f"PyTorch ë²„ì „: {torch.__version__}")
print(f"CUDA ë²„ì „: {torch.version.cuda}")
print(f"CUDA ì‚¬ìš© ê°€ëŠ¥: {torch.cuda.is_available()}")

if torch.cuda.is_available():
    print(f"GPU ì¥ì¹˜: {torch.cuda.get_device_name(0)}")
    print(f"GPU ë©”ëª¨ë¦¬: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.2f} GB")
else:
    print("âš ï¸  ê²½ê³ : GPUë¥¼ ê°ì§€í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤")

print(f"torchaudio: {torchaudio.__version__}")
print("=" * 60)
EOF

# ì˜ˆìƒ ì¶œë ¥:
# PyTorch ë²„ì „: 2.1.2 (ë˜ëŠ” ë” ìµœì‹ )
# CUDA ë²„ì „: 12.4 ë˜ëŠ” 12.9 â† âœ… ì¤‘ìš”!
# CUDA ì‚¬ìš© ê°€ëŠ¥: True â† âœ… ì¤‘ìš”!
# GPU ì¥ì¹˜: NVIDIA ...
```

**ë§Œì•½ "CUDA ì‚¬ìš© ê°€ëŠ¥: False"ì´ë©´**:
1. ë“œë¼ì´ë²„ í™•ì¸: `nvidia-smi`
2. CUDA Runtime í™•ì¸: `ls /usr/local/cuda/lib64/libcudart.so*`
3. ê²½ë¡œ í™•ì¸: `echo $LD_LIBRARY_PATH`

#### 2-6. ëª¨ë¸ ë‹¤ìš´ë¡œë“œ (10-20ë¶„)

```bash
# Whisper ëª¨ë¸ ìë™ ë‹¤ìš´ë¡œë“œ
python3 << 'EOF'
from faster_whisper import WhisperModel

model = WhisperModel("large-v3", device="cuda", compute_type="float16")
print("âœ… ëª¨ë¸ ë‹¤ìš´ë¡œë“œ ì™„ë£Œ")
EOF

# ë˜ëŠ” ì§ì ‘ ë‹¤ìš´ë¡œë“œ (ì‹œê°„ ê±¸ë¦¼)
cd /data/stt/models
# (ìë™ìœ¼ë¡œ ë‹¤ìš´ë¡œë“œë¨)
```

#### 2-7. API ì„œë²„ ì‹œì‘ (ê²€ì¦)

```bash
# API ì„œë²„ ì‹¤í–‰
cd /data/stt
python3 api_server.py

# ì˜ˆìƒ ë¡œê·¸:
# âœ… faster-whisper ëª¨ë¸ ë¡œë“œ ì™„ë£Œ (Device: cuda, compute: float16)
# INFO:     Started server process
# INFO:     Uvicorn running on http://0.0.0.0:8003

# ë³„ë„ í„°ë¯¸ë„ì—ì„œ í…ŒìŠ¤íŠ¸
curl http://localhost:8003/health
# ì‘ë‹µ: {"status":"healthy","device":"cuda"}
```

---

## ğŸ“‹ ìµœì¢… ì²´í¬ë¦¬ìŠ¤íŠ¸

```
Mac (ë¡œì»¬)
â˜‘ ì½”ë“œ/wheel íŒŒì¼ tar.gzë¡œ ì••ì¶•
â˜‘ ì„œë²„ë¡œ scp ì „ì†¡
â˜‘ PyTorchëŠ” ë°›ì§€ ì•ŠìŒ â† ì¤‘ìš”!

Linux ì„œë²„
â˜‘ tar.gz ì¶”ì¶œ
â˜‘ ì¼ë°˜ wheel ì„¤ì¹˜ (deployment_package/wheels/*.whl)
â˜‘ pip install torch torchaudio (ì§ì ‘ ì„¤ì¹˜) â† í•µì‹¬!
â˜‘ python3ë¡œ PyTorch CUDA ê²€ì¦
  â†’ torch.version.cuda = "12.4" ë˜ëŠ” "12.9" âœ…
  â†’ torch.cuda.is_available() = True âœ…
â˜‘ ëª¨ë¸ ë‹¤ìš´ë¡œë“œ
â˜‘ API ì„œë²„ í…ŒìŠ¤íŠ¸
```

---

## ğŸš¨ "PyTorch CUDA: None" ì—ëŸ¬ë¥¼ í”¼í•˜ëŠ” ë°©ë²•

```
âŒ ì˜ëª»ëœ ê²½ë¡œ:
1. Macì—ì„œ pip wheel torch â†’ ì˜ëª»ëœ ì•„í‚¤í…ì²˜
2. Docker ë¹Œë“œ ì¤‘ pip install torch â†’ CPU ë²„ì „ì¼ ìˆ˜ ìˆìŒ
3. ì˜ˆì „ wheel íŒŒì¼ ì¬ì‚¬ìš© â†’ CPU ì „ìš© ë²„ì „

âœ… ì •í™•í•œ ê²½ë¡œ:
1. ì„œë²„ì—ì„œ ì§ì ‘ pip install torch
2. CUDA 12.9 ê°ì§€ë¨
3. CUDA ì§€ì› ë²„ì „ ìë™ ì„¤ì¹˜
```

---

## â±ï¸ ì˜ˆìƒ ì†Œìš” ì‹œê°„

| ë‹¨ê³„ | ì‹œê°„ | ìœ„ì¹˜ |
|------|------|------|
| tar ì••ì¶• + ì „ì†¡ | 10ë¶„ | Mac |
| ì„œë²„ ì••ì¶• í•´ì œ | 2ë¶„ | ì„œë²„ |
| wheel ì„¤ì¹˜ | 1-2ë¶„ | ì„œë²„ |
| PyTorch ì„¤ì¹˜ | 10-15ë¶„ | ì„œë²„ |
| ì˜ì¡´ì„± ì„¤ì¹˜ | 5ë¶„ | ì„œë²„ |
| PyTorch ê²€ì¦ | 1ë¶„ | ì„œë²„ |
| ëª¨ë¸ ë‹¤ìš´ë¡œë“œ | 15-30ë¶„ | ì„œë²„ |
| **ì´ê³„** | **40-60ë¶„** | |

---

## ğŸ¯ ì´ ë°©ì‹ì´ ì •ë‹µì¸ ì´ìœ 

### 1. ì•„í‚¤í…ì²˜ ì™„ë²½ í˜¸í™˜
```
Mac (darwin) â‰  Linux (x86_64-linux-gnu)

ì„œë²„ì—ì„œ ì§ì ‘ ë°›ìœ¼ë©´:
â†’ Linux ë„¤ì´í‹°ë¸Œ wheel (ì™„ë²½ í˜¸í™˜)
```

### 2. CUDA í™˜ê²½ ìë™ ê°ì§€
```
ì„œë²„: nvidia-smi â†’ 575.57.08
ì„œë²„: nvcc â†’ ì—†ìŒ (í•„ìš” ì—†ìŒ)
ì„œë²„: CUDA Runtime â†’ 12.9 (ìë™ ê°ì§€)

pip install torch:
â†’ ìë™ìœ¼ë¡œ ê°€ì¥ í˜¸í™˜ë˜ëŠ” ë²„ì „ ì„ íƒ
```

### 3. ì˜ì¡´ì„± ìë™ í•´ê²°
```
pip install torch:
â†’ í•„ìš”í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ ìë™ìœ¼ë¡œ ë‹¤ìš´ë¡œë“œ
â†’ ë²„ì „ ì¶©ëŒ ìë™ í•´ê²°
```

### 4. ë„¤íŠ¸ì›Œí¬ ì•ˆì •ì„±
```
Mac CDN: ë¶ˆì•ˆì • (ë©€ì–´ì„œ)
ì„œë²„ ë„¤íŠ¸ì›Œí¬: ì•ˆì •ì  (ë¡œì»¬ í™˜ê²½)
```

---

## ğŸ“š ì°¸ê³ 

- **ê³¼ê±° ì‹œë„**: Mac ë‹¤ìš´ë¡œë“œ â†’ Docker ë¹Œë“œ â†’ ì‹¤íŒ¨
- **ìµœì¢… í•´ë²•**: ì„œë²„ ì§ì ‘ ì„¤ì¹˜ â†’ ì„±ê³µ
- **í•µì‹¬**: PyTorchëŠ” ì„œë²„ì—ì„œ ë°›ìœ¼ì„¸ìš”!

---

**ê²°ë¡ **: ì´ ë°©ì‹ì„ ë”°ë¥´ë©´ 99% ì„±ê³µí•©ë‹ˆë‹¤! âœ…
