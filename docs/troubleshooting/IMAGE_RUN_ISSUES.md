# ğŸš¨ Docker ì´ë¯¸ì§€ ì‹¤í–‰ ì˜¤ë¥˜ ì§„ë‹¨ ë° í•´ê²°

**ëª©ì **: `docker run` ì‹¤íŒ¨ ë˜ëŠ” ì»¨í…Œì´ë„ˆ ì¦‰ì‹œ ì¢…ë£Œ ë¬¸ì œ í•´ê²°  
**ë‚œì´ë„**: ì¤‘ê¸‰

---

## ğŸ“Š ì˜¤ë¥˜ ì§„ë‹¨ ì ˆì°¨

### Step 1: ì˜¤ë¥˜ ë©”ì‹œì§€ ìˆ˜ì§‘

```bash
# 1-1. ì»¨í…Œì´ë„ˆ ID í™•ì¸
docker ps -a | grep stt-engine

# 1-2. ìƒì„¸ ì˜¤ë¥˜ ë©”ì‹œì§€ í™•ì¸
docker logs <CONTAINER_ID>

# 1-3. ì˜¤ë¥˜ê°€ ë§ìœ¼ë©´ ì „ì²´ ì¶œë ¥
docker logs <CONTAINER_ID> > error.log
cat error.log
```

### Step 2: ì˜¤ë¥˜ ìœ í˜• ì‹ë³„

ì•„ë˜ì—ì„œ í•´ë‹¹í•˜ëŠ” ì˜¤ë¥˜ë¥¼ ì°¾ì•„ í•´ê²°ì±…ì„ ë”°ë¥´ì„¸ìš”.

---

## ğŸ” ì¼ë°˜ì ì¸ ì˜¤ë¥˜ì™€ í•´ê²°ì±…

### âŒ ì˜¤ë¥˜ 1: "No such file or directory"

**ì¦ìƒ:**
```
FileNotFoundError: No such file or directory: '/app/models/...'
```

**ì›ì¸:**
- ëª¨ë¸ íŒŒì¼ì´ ë§ˆìš´íŠ¸ë˜ì§€ ì•ŠìŒ
- ê²½ë¡œê°€ ì˜ëª»ë¨

**í•´ê²°ì±…:**

```bash
# 1. ëª¨ë¸ íŒŒì¼ ì¡´ì¬ í™•ì¸
ls -lh /path/to/local/models/

# 2. ë§ˆìš´íŠ¸ ê²½ë¡œ í™•ì¸
docker inspect <CONTAINER_ID> | grep -A 5 "Mounts"

# 3. ì˜¬ë°”ë¥¸ ê²½ë¡œë¡œ ì¬ì‹¤í–‰
docker run -d \
  --name stt-engine \
  -p 8003:8003 \
  -v /home/user/models/openai_whisper-large-v3-turbo:/app/models/openai_whisper-large-v3-turbo \
  stt-engine:linux-x86_64
```

---

### âŒ ì˜¤ë¥˜ 2: "Address already in use"

**ì¦ìƒ:**
```
Error response from daemon: Ports are not available: exposing port TCP 0.0.0.0:8003 -> 0.0.0.0:0: listen tcp 0.0.0.0:8003: bind: address already in use
```

**ì›ì¸:**
- í¬íŠ¸ 8003ì´ ì´ë¯¸ ì‚¬ìš© ì¤‘

**í•´ê²°ì±…:**

```bash
# 1. í¬íŠ¸ ì ìœ  í™•ë¡œ í™•ì¸
lsof -i :8003
# ë˜ëŠ”
netstat -tulpn | grep 8003

# 2. ê¸°ì¡´ ì»¨í…Œì´ë„ˆ í™•ì¸ ë° ì¤‘ì§€
docker ps | grep stt-engine
docker stop <OLD_CONTAINER_ID>
docker rm <OLD_CONTAINER_ID>

# 3. ë‹¤ë¥¸ í¬íŠ¸ ì‚¬ìš© (ì„ì‹œ)
docker run -d \
  --name stt-engine \
  -p 8004:8003 \
  stt-engine:linux-x86_64

# 4. í”„ë¡œì„¸ìŠ¤ ê°•ì œ ì¢…ë£Œ (ìµœí›„ì˜ ìˆ˜ë‹¨)
kill -9 $(lsof -t -i :8003)
```

---

### âŒ ì˜¤ë¥˜ 3: "Out of memory"

**ì¦ìƒ:**
```
Killed
# ë˜ëŠ”
MemoryError
```

**ì›ì¸:**
- ì»¨í…Œì´ë„ˆ ë©”ëª¨ë¦¬ ì œí•œì´ ë„ˆë¬´ ì‘ìŒ
- ëª¨ë¸ì´ ë„ˆë¬´ í¼

**í•´ê²°ì±…:**

```bash
# 1. ì‹œìŠ¤í…œ ë©”ëª¨ë¦¬ í™•ì¸
free -h

# 2. ë©”ëª¨ë¦¬ í•œê³„ ì¦ì„¤
docker run -d \
  --name stt-engine \
  -p 8003:8003 \
  -m 8gb \
  --memory-swap 8gb \
  -v /path/to/models:/app/models \
  stt-engine:linux-x86_64

# 3. ë˜ëŠ” docker-compose.ymlì—ì„œ
services:
  stt-engine:
    mem_limit: 8g
    memswap_limit: 8g
```

**ë©”ëª¨ë¦¬ ìš”êµ¬ì‚¬í•­:**
| ëª¨ë¸ | ìµœì†Œ ë©”ëª¨ë¦¬ | ê¶Œì¥ ë©”ëª¨ë¦¬ |
|------|-----------|-----------|
| large-v3 | 4GB | 8GB |
| medium | 2GB | 4GB |
| base | 1GB | 2GB |

---

### âŒ ì˜¤ë¥˜ 4: "ModuleNotFoundError"

**ì¦ìƒ:**
```
ModuleNotFoundError: No module named 'faster_whisper'
```

**ì›ì¸:**
- Python íŒ¨í‚¤ì§€ ì„¤ì¹˜ ì‹¤íŒ¨
- Wheel íŒŒì¼ ì„¤ì¹˜ ì•ˆ ë¨

**í•´ê²°ì±…:**

```bash
# 1. ì»¨í…Œì´ë„ˆ ì§„ì…
docker exec -it <CONTAINER_ID> /bin/bash

# 2. íŒ¨í‚¤ì§€ ì„¤ì¹˜ ìƒíƒœ í™•ì¸
pip list | grep faster-whisper

# 3. ëˆ„ë½ëœ íŒ¨í‚¤ì§€ ì„¤ì¹˜
pip install faster-whisper

# ë˜ëŠ” wheel íŒŒì¼ì—ì„œ ì„¤ì¹˜
pip install --no-index --find-links=/wheels/ faster-whisper

# 4. ì»¨í…Œì´ë„ˆ ì¬ì‹œì‘
docker restart <CONTAINER_ID>
```

---

### âŒ ì˜¤ë¥˜ 5: "Model not found"

**ì¦ìƒ:**
```
RuntimeError: Model not found at /app/models/...
```

**ì›ì¸:**
- ëª¨ë¸ í´ë” ì´ë¦„ ë¶ˆì¼ì¹˜
- ê²½ë¡œ ì˜¤ë¥˜

**í•´ê²°ì±…:**

```bash
# 1. ì»¨í…Œì´ë„ˆ ë‚´ ëª¨ë¸ êµ¬ì¡° í™•ì¸
docker exec <CONTAINER_ID> ls -lh /app/models/

# 2. ì˜ˆìƒë˜ëŠ” êµ¬ì¡°:
# /app/models/
# â””â”€â”€ openai_whisper-large-v3-turbo/
#     â”œâ”€â”€ config.json
#     â”œâ”€â”€ model.bin
#     â””â”€â”€ ...

# 3. êµ¬ì¡°ê°€ ë‹¤ë¥´ë©´ ì••ì¶• í•´ì œ
docker exec <CONTAINER_ID> tar -xzf /app/models/whisper-model.tar.gz -C /app/models/

# 4. í™•ì¸
docker exec <CONTAINER_ID> ls -lh /app/models/openai_whisper-large-v3-turbo/
```

---

### âŒ ì˜¤ë¥˜ 6: "CUDA/GPU not found"

**ì¦ìƒ:**
```
WARNING: CUDA not found, falling back to CPU
# ë˜ëŠ”
torch.cuda.is_available() = False
```

**ì›ì¸:**
- NVIDIA Docker ë¯¸ì„¤ì¹˜
- GPU ë“œë¼ì´ë²„ ë¬¸ì œ
- Dockerì— GPU ì ‘ê·¼ ê¶Œí•œ ì—†ìŒ

**í•´ê²°ì±…:**

```bash
# 1. NVIDIA Docker ì„¤ì¹˜ í™•ì¸
nvidia-docker --version

# ì„¤ì¹˜ ì•ˆ ë˜ì–´ ìˆìœ¼ë©´
apt-get install nvidia-docker2

# 2. Docker ë°ëª¬ ì¬ì‹œì‘
sudo systemctl restart docker

# 3. GPU ì‚¬ìš©í•˜ì—¬ ì‹¤í–‰
docker run -d \
  --gpus all \
  --name stt-engine \
  -p 8003:8003 \
  -v /path/to/models:/app/models \
  stt-engine:linux-x86_64

# 4. GPU ì¸ì‹ í™•ì¸
docker exec <CONTAINER_ID> nvidia-smi
```

---

### âŒ ì˜¤ë¥˜ 7: "Uvicorn bind failed"

**ì¦ìƒ:**
```
ERROR: [Errno 99] Cannot assign requested address
```

**ì›ì¸:**
- í¬íŠ¸ ë°”ì¸ë”© ì„¤ì • ì˜¤ë¥˜
- ë„¤íŠ¸ì›Œí¬ ì¸í„°í˜ì´ìŠ¤ ë¬¸ì œ

**í•´ê²°ì±…:**

```bash
# 1. í˜¸ìŠ¤íŠ¸ ëª¨ë“œ í™•ì¸
docker inspect <CONTAINER_ID> | grep "NetworkMode"

# 2. ëª…ì‹œì ìœ¼ë¡œ ë°”ì¸ë“œ ì„¤ì •
docker run -d \
  --name stt-engine \
  -p 0.0.0.0:8003:8003 \
  stt-engine:linux-x86_64

# 3. localhostë§Œ ë°”ì¸ë“œ (ë¡œì»¬ ì ‘ê·¼ë§Œ)
docker run -d \
  --name stt-engine \
  -p 127.0.0.1:8003:8003 \
  stt-engine:linux-x86_64
```

---

## ğŸ”§ ì»¨í…Œì´ë„ˆ ìƒíƒœ í™•ì¸

### ê¸°ë³¸ ì§„ë‹¨

```bash
# 1. ì»¨í…Œì´ë„ˆ ìƒíƒœ
docker ps -a | grep stt-engine

# 2. ìƒì„¸ ì •ë³´
docker inspect <CONTAINER_ID> | jq '.State'

# ì˜ˆìƒ ì¶œë ¥:
# {
#   "Status": "running",
#   "Running": true,
#   "Paused": false,
#   "Restarting": false,
#   "OOMKilled": false,
#   "Dead": false,
#   "Pid": 12345,
#   "ExitCode": 0,
#   "Error": ""
# }
```

### ìƒì„¸ ì§„ë‹¨

```bash
# 1. ë§ˆìš´íŠ¸ í™•ì¸
docker inspect <CONTAINER_ID> | jq '.Mounts'

# 2. í¬íŠ¸ í™•ì¸
docker inspect <CONTAINER_ID> | jq '.HostConfig.PortBindings'

# 3. í™˜ê²½ ë³€ìˆ˜ í™•ì¸
docker inspect <CONTAINER_ID> | jq '.Config.Env'

# 4. ë©”ëª¨ë¦¬ ì„¤ì • í™•ì¸
docker inspect <CONTAINER_ID> | jq '.HostConfig | {Memory, MemorySwap, MemoryReservation}'
```

---

## ğŸ“ ë¡œê·¸ ë¶„ì„ íŒ

### ë¡œê·¸ í•„í„°ë§

```bash
# íŠ¹ì • ë‹¨ì–´ í¬í•¨ ë¡œê·¸ë§Œ ë³´ê¸°
docker logs <CONTAINER_ID> 2>&1 | grep -i "error"

# ë§ˆì§€ë§‰ Nì¤„ë§Œ ë³´ê¸°
docker logs --tail 50 <CONTAINER_ID>

# íƒ€ì„ìŠ¤íƒ¬í”„ í¬í•¨
docker logs --timestamps <CONTAINER_ID>

# ì‹¤ì‹œê°„ ë¡œê·¸
docker logs -f <CONTAINER_ID>

# íŠ¹ì • ì‹œê°„ ì´í›„
docker logs --since 30m <CONTAINER_ID>
```

### ë¡œê·¸ ì €ì¥

```bash
# ì „ì²´ ë¡œê·¸ ì €ì¥
docker logs <CONTAINER_ID> > container.log 2>&1

# ë¶„ì„ìš© ì •ë ¬
docker logs <CONTAINER_ID> 2>&1 | grep -E "ERROR|WARNING|FAIL" | tee errors.log
```

---

## ğŸš€ ë³µêµ¬ ì ˆì°¨

### ì™„ì „ ì´ˆê¸°í™”

```bash
# 1. ì»¨í…Œì´ë„ˆ ì¤‘ì§€ ë° ì œê±°
docker stop <CONTAINER_ID>
docker rm <CONTAINER_ID>

# 2. ì´ë¯¸ì§€ ë‹¤ì‹œ ë¡œë“œ (í•„ìš”ì‹œ)
docker load -i stt-engine-linux-x86_64.tar

# 3. ìƒˆë¡œ ì‹¤í–‰
docker run -d \
  --name stt-engine \
  -p 8003:8003 \
  -v /path/to/models:/app/models \
  stt-engine:linux-x86_64

# 4. ë¡œê·¸ í™•ì¸
docker logs stt-engine
```

### ë¶€ë¶„ ë³µêµ¬

```bash
# 1. ì»¨í…Œì´ë„ˆë§Œ ì¬ì‹œì‘
docker restart <CONTAINER_ID>

# 2. íŠ¹ì • íŒŒì¼ë§Œ ì—…ë°ì´íŠ¸
docker cp stt_engine.py <CONTAINER_ID>:/app/
docker restart <CONTAINER_ID>
```

---

## ğŸ“Š ì§„ë‹¨ ì²´í¬ë¦¬ìŠ¤íŠ¸

ì˜¤ë¥˜ ë°œìƒ ì‹œ ë‹¤ìŒì„ í™•ì¸í•˜ì„¸ìš”:

```
â–¡ docker ps -a ì—ì„œ ì»¨í…Œì´ë„ˆ ìƒíƒœ í™•ì¸
â–¡ docker logs ë¡œ ì˜¤ë¥˜ ë©”ì‹œì§€ ìˆ˜ì§‘
â–¡ ì˜¤ë¥˜ ìœ í˜• ì‹ë³„
â–¡ í•´ë‹¹ ì„¹ì…˜ì˜ í•´ê²°ì±… ì ìš©
â–¡ docker restart ì‹¤í–‰
â–¡ curl http://localhost:8003/health ë¡œ í™•ì¸
â–¡ ë¬¸ì œ í•´ê²°ë˜ì§€ ì•Šìœ¼ë©´ ë‹¤ìŒ ì„¹ì…˜ ì‹œë„
```

---

## ğŸ“ ì¶”ê°€ ë„ì›€ë§

- [CONTAINER_FILE_UPDATES.md](./CONTAINER_FILE_UPDATES.md) - íŒŒì¼ ì—…ë°ì´íŠ¸ ë°©ë²•
- [SERVER_DEPLOYMENT_GUIDE.md](../SERVER_DEPLOYMENT_GUIDE.md) - ë°°í¬ ê°€ì´ë“œ
- Docker ê³µì‹ ë¬¸ì„œ: https://docs.docker.com/

---

**ìƒíƒœ**: ğŸŸ¢ ëŒ€ë¶€ë¶„ì˜ ì˜¤ë¥˜ í•´ê²° ê°€ëŠ¥ âœ…
