# ğŸ”§ Docker ëª¨ë¸ ë¡œë“œ ì˜¤ë¥˜ í•´ê²° ê°€ì´ë“œ

**ë¬¸ì œ**: Docker ì»¨í…Œì´ë„ˆì—ì„œ `Unable to open file 'model.bin'` ì˜¤ë¥˜ ë°œìƒ  
**ì›ì¸**: CTranslate2 ë³€í™˜ì´ ì™„ì „í•˜ì§€ ì•Šê±°ë‚˜ `config.json`ì´ ì†ìƒë¨  
**í•´ê²°ì±…**: EC2ì—ì„œ ëª¨ë¸ ì¬ë‹¤ìš´ë¡œë“œ ë° ë³€í™˜

---

## ğŸ“‹ ë¬¸ì œ ë¶„ì„

### ì¦ìƒ 1: config.jsonì´ ë„ˆë¬´ ì‘ìŒ (2.2KB)
```
âš ï¸  config.jsonì´ ë„ˆë¬´ ì‘ìŒ: 2.2KB (ì†ìƒ ê°€ëŠ¥ì„±)
```
- **ì›ì¸**: CTranslate2 ë³€í™˜ ì¤‘ config.jsonì´ ì œëŒ€ë¡œ ìƒì„±ë˜ì§€ ì•ŠìŒ
- **ê²°ê³¼**: model.binì„ ë¡œë“œí•  ìˆ˜ ì—†ìŒ

### ì¦ìƒ 2: model.bin íŒŒì¼ì„ ì—´ ìˆ˜ ì—†ìŒ
```
âŒ faster-whisper ë¡œë“œ ì‹¤íŒ¨: RuntimeError
   ë©”ì‹œì§€: Unable to open file 'model.bin' in model '/app/models/openai_whisper-large-v3-turbo'
```
- **ì›ì¸**: config.json ì†ìƒìœ¼ë¡œ ì¸í•´ model.binì„ ì¸ì‹í•˜ì§€ ëª»í•¨
- **ë˜ëŠ”**: model.binì´ ì†ìƒë˜ì—ˆê±°ë‚˜ ë¶ˆì™„ì „í•œ ìƒíƒœ

---

## ğŸš€ EC2ì—ì„œ í•´ê²°í•˜ê¸°

### Step 1: SSHë¡œ EC2 ì ‘ì†
```bash
ssh -i your-key.pem ec2-user@your-ec2-ip

# ë˜ëŠ” EC2 ì¸ìŠ¤í„´ìŠ¤ì—ì„œ ì§ì ‘
cd /home/ec2-user/stt_engine
```

### Step 2: ê¸°ì¡´ ëª¨ë¸ ë°±ì—… ë° ì‚­ì œ
```bash
# ë°±ì—… (ì„ íƒì‚¬í•­)
tar czf models_backup_$(date +%Y%m%d).tar.gz models/ 2>/dev/null || true

# ëª¨ë¸ ì™„ì „ ì‚­ì œ
rm -rf models/openai_whisper-large-v3-turbo
rm -rf build/output/*

# í™•ì¸
ls -la models/
```

### Step 3: ëª¨ë¸ ì¬ë‹¤ìš´ë¡œë“œ (ìƒˆë¡œ ì‹œì‘)
```bash
# Python 3 ì‚¬ìš© í™•ì¸
python3 --version

# ëª¨ë¸ ë‹¤ìš´ë¡œë“œ + CTranslate2 ë³€í™˜ + ê²€ì¦
python3 download_model_hf.py 2>&1 | tee model_rebuild.log
```

**ì˜ˆìƒ ì†Œìš” ì‹œê°„**: 30~45ë¶„

### Step 4: ëª¨ë¸ íŒŒì¼ ê²€ì¦
```bash
echo "=== ëª¨ë¸ íŒŒì¼ ê²€ì¦ ==="

# 1. ctranslate2_model í´ë” í™•ì¸
ls -lh models/openai_whisper-large-v3-turbo/ctranslate2_model/

# 2. íŒŒì¼ í¬ê¸° í™•ì¸ (ì •ìƒ ë²”ìœ„)
du -sh models/openai_whisper-large-v3-turbo/ctranslate2_model/model.bin
# ì˜ˆìƒ: 1.5GB ì •ë„

# 3. config.json í¬ê¸° í™•ì¸ (ì •ìƒ: 2KB ì´ìƒ)
ls -lh models/openai_whisper-large-v3-turbo/ctranslate2_model/config.json
# ì˜ˆìƒ: 2.2KB ì´ìƒ

# 4. MD5 ê²€ì¦ (ìƒì„±ëœ tar.gzì˜ ë¬´ê²°ì„±)
cat build/output/*.md5
# ì••ì¶• íŒŒì¼ê³¼ md5 ë¹„êµ
```

**ì •ìƒ ìƒíƒœ**:
```
ctranslate2_model/:
  -rw-r--r--  1 ec2-user  ec2-user 1.5G  model.bin        âœ…
  -rw-r--r--  1 ec2-user  ec2-user 2.2K  config.json      âœ…
  -rw-r--r--  1 ec2-user  ec2-user 1.0M  vocabulary.json  âœ…
```

### Step 5: Docker ì´ë¯¸ì§€ ì¬ë¹Œë“œ
```bash
# ì´ì „ ì´ë¯¸ì§€ ì œê±° (ì„ íƒì‚¬í•­)
docker rmi stt-engine:cuda129-rhel89-v1.4

# ìƒˆ ì´ë¯¸ì§€ ë¹Œë“œ (ìµœì‹  ëª¨ë¸ í¬í•¨)
bash scripts/build-server-image.sh

# ì´ë¯¸ì§€ í™•ì¸
docker images | grep stt-engine
```

**ì†Œìš” ì‹œê°„**: 30ë¶„

### Step 6: ì»¨í…Œì´ë„ˆ ì¬ì‹¤í–‰
```bash
# ì´ì „ ì»¨í…Œì´ë„ˆ ì œê±°
docker stop stt-engine 2>/dev/null || true
docker rm stt-engine 2>/dev/null || true

# ìƒˆ ì»¨í…Œì´ë„ˆ ì‹¤í–‰
docker run -d \
  --name stt-engine \
  -p 8003:8003 \
  -v $(pwd)/models:/app/models \
  -v $(pwd)/logs:/app/logs \
  -e CUDA_VISIBLE_DEVICES=0 \
  stt-engine:cuda129-rhel89-v1.4

# ì‹¤í–‰ í™•ì¸
docker ps | grep stt-engine
```

### Step 7: ë¡œê·¸ í™•ì¸
```bash
# ì‹¤ì‹œê°„ ë¡œê·¸ ë³´ê¸°
docker logs -f stt-engine

# íŠ¹ì • ë¼ì¸ ìˆ˜ë§Œ ë³´ê¸°
docker logs --tail 50 stt-engine

# ëª¨ë“  ë¡œê·¸ ì €ì¥
docker logs stt-engine > stt_engine.log 2>&1
cat stt_engine.log | grep -E "âœ…|âŒ|âš ï¸|ë¡œë“œ" | head -20
```

**ì •ìƒ ë¡œê·¸**:
```
âœ… STT ëª¨ë¸ ë¡œë“œ ì™„ë£Œ (Device: cpu, Backend: faster-whisper)
```

**ì˜¤ë¥˜ ë¡œê·¸**:
```
âŒ ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: RuntimeError
âŒ ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: ë‘ ë°±ì—”ë“œ ëª¨ë‘ ì‹¤íŒ¨
```

### Step 8: í—¬ìŠ¤ ì²´í¬
```bash
# API í—¬ìŠ¤ ì²´í¬
curl -s http://localhost:8003/health | python3 -m json.tool

# ì˜ˆìƒ ì‘ë‹µ
{
  "status": "ok",
  "version": "1.0.0",
  "backend": "faster-whisper"
}
```

---

## ğŸ” ê³ ê¸‰ ì§„ë‹¨

### ì»¨í…Œì´ë„ˆ ë‚´ë¶€ì—ì„œ ëª¨ë¸ í™•ì¸
```bash
# ì»¨í…Œì´ë„ˆ ë‚´ë¶€ ì ‘ì†
docker exec -it stt-engine bash

# ë‚´ë¶€ì—ì„œ ì‹¤í–‰
ls -lh /app/models/openai_whisper-large-v3-turbo/ctranslate2_model/
file /app/models/openai_whisper-large-v3-turbo/ctranslate2_model/config.json

# Pythonì—ì„œ ì§ì ‘ í…ŒìŠ¤íŠ¸
python3 << 'EOF'
from faster_whisper import WhisperModel

model = WhisperModel(
    "/app/models/openai_whisper-large-v3-turbo/ctranslate2_model",
    device="cpu",
    compute_type="float32"
)
print("âœ… ëª¨ë¸ ë¡œë“œ ì„±ê³µ!")
EOF

# ì»¨í…Œì´ë„ˆ ì¢…ë£Œ
exit
```

### ë§ˆìš´íŠ¸ ê²½ë¡œ í™•ì¸
```bash
# ì»¨í…Œì´ë„ˆì˜ ë§ˆìš´íŠ¸ í™•ì¸
docker inspect stt-engine | grep -A 10 "Mounts"

# ë˜ëŠ”
docker exec stt-engine df -h | grep models
```

### ê¶Œí•œ ë¬¸ì œ í™•ì¸
```bash
# EC2ì˜ ëª¨ë¸ ê¶Œí•œ
ls -la models/openai_whisper-large-v3-turbo/ctranslate2_model/

# ì»¨í…Œì´ë„ˆ ë‚´ë¶€ì˜ ê¶Œí•œ
docker exec stt-engine ls -la /app/models/openai_whisper-large-v3-turbo/ctranslate2_model/

# ì‚¬ìš©ì í™•ì¸
docker exec stt-engine id
# ì˜ˆìƒ: uid=2000(stt-user) gid=2000(stt-user)
```

---

## âš ï¸ ì¼ë°˜ì ì¸ ë¬¸ì œë“¤

### ë¬¸ì œ 1: ëª¨ë¸ ë‹¤ìš´ë¡œë“œ ì‹œ OOM (Out of Memory)
```bash
# ì›ì¸: EC2 ì¸ìŠ¤í„´ìŠ¤ ë©”ëª¨ë¦¬ ë¶€ì¡±
# í•´ê²°ì±…: ì´ë¯¸ì§€ì—ì„œ ìë™ìœ¼ë¡œ ë¡œë“œ í…ŒìŠ¤íŠ¸ ìŠ¤í‚µ

# í™•ì¸
tail -100 model_rebuild.log | grep -E "âš ï¸|OOM|ë©”ëª¨ë¦¬"
```

### ë¬¸ì œ 2: ëª¨ë¸ ë³€í™˜ ì‹¤íŒ¨
```bash
# ì›ì¸: CTranslate2 ë³€í™˜ ì¤‘ ì˜¤ë¥˜
# ë¡œê·¸ í™•ì¸
tail -100 model_rebuild.log | grep -E "âŒ|ë³€í™˜|CTranslate2"

# ìˆ˜ë™ ë³€í™˜ ì‹œë„
python3 << 'EOF'
from ctranslate2.converters import TransformersConverter

converter = TransformersConverter("openai/whisper-large-v3-turbo")
converter.convert("models/openai_whisper-large-v3-turbo/ctranslate2_model", force=True)
EOF
```

### ë¬¸ì œ 3: ë””ìŠ¤í¬ ë¶€ì¡±
```bash
# ì—¬ìœ  ê³µê°„ í™•ì¸
df -h

# ì„ì‹œ íŒŒì¼ ì •ë¦¬
rm -rf ~/.cache/huggingface/hub/*
rm -rf /tmp/*
```

---

## ğŸ’¾ ë°°í¬ ì „ ì²´í¬ë¦¬ìŠ¤íŠ¸

- [ ] ëª¨ë¸ íŒŒì¼ ì¡´ì¬: `models/openai_whisper-large-v3-turbo/ctranslate2_model/`
- [ ] config.json í¬ê¸°: 2.2KB ì´ìƒ
- [ ] model.bin í¬ê¸°: 1.5GB ì •ë„
- [ ] vocabulary.json ì¡´ì¬
- [ ] Docker ì´ë¯¸ì§€ ë¹Œë“œ ì„±ê³µ
- [ ] ì»¨í…Œì´ë„ˆ ì‹¤í–‰ ì„±ê³µ
- [ ] í—¬ìŠ¤ ì²´í¬ í†µê³¼
- [ ] ë¡œê·¸ì—ì„œ "âœ… STT ëª¨ë¸ ë¡œë“œ ì™„ë£Œ" í™•ì¸

---

## ğŸ“ ê²°ê³¼ ì €ì¥

ì¬ë¹Œë“œ ì™„ë£Œ í›„:

```bash
# ê²°ê³¼ ê¸°ë¡
echo "=== ëª¨ë¸ ì¬ë¹Œë“œ ì™„ë£Œ ===" >> rebuild_summary.txt
date >> rebuild_summary.txt
ls -lh models/openai_whisper-large-v3-turbo/ctranslate2_model/ >> rebuild_summary.txt
docker images | grep stt-engine >> rebuild_summary.txt

# ë¡œê·¸ ì €ì¥
docker logs stt-engine > stt_engine_final.log
```

---

**ì‘ì„±ì¼**: 2026ë…„ 2ì›” 7ì¼  
**ìƒíƒœ**: ìµœì‹  ë²„ì „ ê¸°ì¤€  
**ë‹¤ìŒ**: ëª¨ë¸ ì¬ë¹Œë“œ í›„ í—¬ìŠ¤ ì²´í¬ ë° API í…ŒìŠ¤íŠ¸
