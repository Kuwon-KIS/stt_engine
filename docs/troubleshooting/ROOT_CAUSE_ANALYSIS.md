# ğŸ” ê·¼ë³¸ ì›ì¸ ë¶„ì„ ë° í•´ê²°ì±…

**ì‘ì„±ì¼**: 2026-02-03  
**í˜„í™©**: ì„¸ ê°€ì§€ ì‹¤ì œ ë¬¸ì œ ì‹ë³„ ë° í•´ê²° ë°©ì•ˆ ì œì‹œ

---

## âš ï¸ ë°œê²¬ëœ ë¬¸ì œë“¤

### ë¬¸ì œ 1: python-multipart Wheel íŒŒì¼ ëˆ„ë½ âŒ

**í™•ì¸ ê²°ê³¼**:
```bash
$ ls deployment_package/wheels/ | grep -i multipart
# ê²°ê³¼: ì—†ìŒ âŒ
```

**ì˜í–¥**:
- FastAPIì˜ File Upload ê¸°ëŠ¥ ì‚¬ìš© ë¶ˆê°€
- `/transcribe` ì—”ë“œí¬ì¸íŠ¸ ë¡œë“œ ì‹¤íŒ¨
- ì˜¤í”„ë¼ì¸ í™˜ê²½ì—ì„œ pip ì„¤ì¹˜ ë¶ˆê°€ëŠ¥

**í•´ê²°ì±…**: ë‘ ê°€ì§€ ì˜µì…˜

---

## ğŸ”§ í•´ê²° ë°©ë²• 1: python-multipart Wheel ì¶”ê°€

### ì˜µì…˜ A: ìƒˆ Wheel ë‹¤ìš´ë¡œë“œ í›„ ì¶”ê°€

ë¡œì»¬ ë¨¸ì‹ ì—ì„œ:
```bash
# 1. pip-wheel ì„¤ì¹˜ (ì•„ì§ ì—†ìœ¼ë©´)
pip install pip-wheel

# 2. python-multipart wheel ë‹¤ìš´ë¡œë“œ
pip wheel python-multipart -w deployment_package/wheels/

# 3. ë‹¤ìš´ë¡œë“œ í™•ì¸
ls -lh deployment_package/wheels/ | grep multipart

# 4. wheels.tar.gz ë‹¤ì‹œ ìƒì„±
tar -czf build/output/wheels.tar.gz -C deployment_package wheels/
```

### ì˜µì…˜ B: ê¸°ì¡´ Wheel íŒŒì¼ ì°¾ê¸°

```bash
# ì‹œìŠ¤í…œì— ì´ë¯¸ ì„¤ì¹˜ëœ wheel ìœ„ì¹˜ ì°¾ê¸°
find /path/to/pip/cache -name "*multipart*.whl" 2>/dev/null

# ë˜ëŠ” PyPIì—ì„œ ì§ì ‘ ë‹¤ìš´ë¡œë“œ
wget https://files.pythonhosted.org/packages/.../python_multipart-0.0.6-py3-none-any.whl \
  -O deployment_package/wheels/

# í™•ì¸
ls -lh deployment_package/wheels/python_multipart*
```

### ì˜µì…˜ C: Dockerfileì—ì„œ ì§ì ‘ ì„¤ì¹˜

Dockerfile.engine ìˆ˜ì •:
```dockerfile
# ... (ê¸°ì¡´ ë‚´ìš©)

# Install packages from wheels (offline)
RUN python3.11 -m pip install --no-index --find-links=/wheels/ \
    torch torchaudio faster-whisper \
    librosa scipy numpy \
    fastapi uvicorn requests pydantic \
    huggingface-hub python-dotenv pyyaml \
    python-multipart  # â† ì¶”ê°€
```

---

## ğŸ”§ ë¬¸ì œ 2: CUDA ë“œë¼ì´ë²„ í˜¸í™˜ì„±

**í˜„ì¬ ìƒí™©**:
- ì´ë¯¸ì§€: CUDA 12.1 ê¸°ë°˜ PyTorch 2.1.2
- ì„œë²„: CUDA ë“œë¼ì´ë²„ ë²„ì „ ë‚®ìŒ (ì¶©ëŒ)
- ì˜¤ë¥˜: `CUDA driver version is insufficient for CUDA runtime version`

**ì™œ ë°˜ì˜ì´ ì•ˆ ëëŠ”ê°€**:

api_server.py ë¼ì¸ 25:
```python
device="cuda",  # â† í•˜ë“œì½”ë”©ë˜ì–´ ìˆìŒ
```

stt_engine.py ë¼ì¸ 237:
```python
device = "cuda"  # â† ê¸°ë³¸ê°’ì´ cuda
```

**ë¬¸ì œ**: CPU ì˜µì…˜ì´ ì—†ì´ í•­ìƒ CUDA ì‚¬ìš© ì‹œë„

### í•´ê²°ì±… 1: CPU ëª¨ë“œë¡œ ë¹Œë“œ (ê¶Œì¥ - ì„œë²„ í™˜ê²½)

api_server.py ìˆ˜ì •:
```python
# ë¼ì¸ 25 ë³€ê²½
device="cpu",  # CUDA ë“œë¼ì´ë²„ ë¶ˆì¼ì¹˜ ë¬¸ì œ í•´ê²°
```

ë˜ëŠ” í™˜ê²½ë³€ìˆ˜ ì‚¬ìš©:
```python
# ë¼ì¸ 25 ë³€ê²½
device=os.getenv("STT_DEVICE", "cpu"),  # ê¸°ë³¸ê°’: cpu
```

Dockerfile.engine ìˆ˜ì •:
```dockerfile
ENV STT_DEVICE=cpu  # CUDA ë“œë¼ì´ë²„ í˜¸í™˜ì„± ë¬¸ì œ ìˆëŠ” ì„œë²„ìš©
```

### í•´ê²°ì±… 2: ì—¬ëŸ¬ ë²„ì „ ì´ë¯¸ì§€ ë¹Œë“œ

**Dockerfile.engine-cpu** (ìƒˆë¡œ ìƒì„±):
```dockerfile
FROM python:3.11-slim

# ... (ë™ì¼í•œ ë‚´ìš©)

# CPU ìµœì í™”
ENV STT_DEVICE=cpu
CMD ["python3.11", "api_server.py"]
```

ë¹Œë“œ ëª…ë ¹:
```bash
docker build -t stt-engine:linux-x86_64-cpu -f docker/Dockerfile.engine-cpu .
```

---

## ğŸ”§ ë¬¸ì œ 3: Exited ì»¨í…Œì´ë„ˆì—ì„œ docker exec ë¶ˆê°€

**í˜„ì¬ ìƒí™©**:
```
[ddpapp@dlddpgai1 sw]$ docker ps
# stt-engine: Exited (1)
```

**ì´ìœ **: ì»¨í…Œì´ë„ˆê°€ ì‹œì‘ ì‹¤íŒ¨ë¡œ ì¢…ë£Œë¨ (exec ë¶ˆê°€ëŠ¥)

### í•´ê²°ì±…: ìƒˆ ì´ë¯¸ì§€ë¡œ ì»¨í…Œì´ë„ˆ ì¬ì‹¤í–‰

```bash
# 1. ê¸°ì¡´ ì»¨í…Œì´ë„ˆ ì œê±°
docker stop 29534921b493
docker rm 29534921b493

# 2. ìƒˆ ì´ë¯¸ì§€ ë¡œë“œ (ìˆ˜ì • í›„)
docker load -i stt-engine-linux-x86_64.tar

# 3. ìƒˆë¡œ ì‹¤í–‰
docker run -d \
  --name stt-engine \
  -p 8003:8003 \
  -v /path/to/models:/app/models \
  stt-engine:linux-x86_64

# 4. í™•ì¸
docker ps | grep stt-engine
```

---

## ğŸ“‹ ì™„ì „í•œ í•´ê²° ìˆœì„œ

### Step 1: ë¡œì»¬ì—ì„œ ì¤€ë¹„ (10ë¶„)

```bash
cd /Users/a113211/workspace/stt_engine

# 1-1. python-multipart wheel ì¶”ê°€
pip wheel python-multipart -w deployment_package/wheels/

# 1-2. wheels.tar.gz ê°±ì‹ 
tar -czf build/output/wheels.tar.gz -C deployment_package wheels/

# 1-3. api_server.py CPU ëª¨ë“œë¡œ ë³€ê²½
sed -i '' 's/device="cuda"/device="cpu"/' api_server.py

# ë˜ëŠ” í™˜ê²½ë³€ìˆ˜ ë°©ì‹ ì‚¬ìš© (ë” ë‚˜ìŒ)
```

### Step 2: Dockerfile ìˆ˜ì •

**docker/Dockerfile.engine** ìˆ˜ì •:
```dockerfile
# ë¼ì¸ 19-22 ë³€ê²½:
RUN python3.11 -m pip install --no-index --find-links=/wheels/ \
    torch torchaudio faster-whisper \
    librosa scipy numpy \
    fastapi uvicorn requests pydantic \
    huggingface-hub python-dotenv pyyaml \
    python-multipart

# ë¼ì¸ 31 ì¶”ê°€:
ENV STT_DEVICE=cpu  # ë˜ëŠ” cuda (CUDA ë“œë¼ì´ë²„ê°€ ì¶©ë¶„í•˜ë©´)
```

### Step 3: ìƒˆ ì´ë¯¸ì§€ ë¹Œë“œ

```bash
bash scripts/build-engine-image.sh
# ë˜ëŠ”
docker build -t stt-engine:linux-x86_64 -f docker/Dockerfile.engine .
```

### Step 4: ì„œë²„ë¡œ ì „ì†¡ ë° ë°°í¬

```bash
# ë¡œì»¬ì—ì„œ
scp build/output/stt-engine-linux-x86_64.tar user@server:/path/to/

# ì„œë²„ì—ì„œ
docker load -i stt-engine-linux-x86_64.tar
docker stop stt-engine
docker rm stt-engine
docker run -d \
  --name stt-engine \
  -p 8003:8003 \
  -v /path/to/models:/app/models \
  stt-engine:linux-x86_64

# í™•ì¸
docker logs stt-engine
curl http://localhost:8003/health
```

---

## ğŸ“Š ì‹¤ì œ ì½”ë“œ ë³€ê²½ ì‚¬í•­

### api_server.py - ë¼ì¸ 20-28

**ë³€ê²½ ì „**:
```python
# ëª¨ë¸ ì´ˆê¸°í™”
# faster-whisperëŠ” ìë™ìœ¼ë¡œ CUDA ê°ì§€
try:
    model_path = Path(__file__).parent / "models" / "openai_whisper-large-v3-turbo"
    stt = WhisperSTT(
        str(model_path),
        device="cuda",
        compute_type="float16"  # VRAM íš¨ìœ¨ì , ë¹ ë¥¸ ì¶”ë¡ 
    )
```

**ë³€ê²½ í›„ (ì˜µì…˜ 1 - ê³ ì •)**:
```python
# ëª¨ë¸ ì´ˆê¸°í™”
# CPU/CUDA ìë™ ì„ íƒ ë˜ëŠ” ê³ ì •
try:
    model_path = Path(__file__).parent / "models" / "openai_whisper-large-v3-turbo"
    stt = WhisperSTT(
        str(model_path),
        device=os.getenv("STT_DEVICE", "cpu"),  # í™˜ê²½ë³€ìˆ˜ë¡œ ì œì–´
        compute_type="float16"  # VRAM íš¨ìœ¨ì , ë¹ ë¥¸ ì¶”ë¡ 
    )
```

**import ì¶”ê°€**:
```python
import os  # ë¼ì¸ 8ì— ì¶”ê°€
```

### Dockerfile.engine - ë¼ì¸ 19-23

**ë³€ê²½ ì „**:
```dockerfile
RUN python3.11 -m pip install --no-index --find-links=/wheels/ \
    torch torchaudio faster-whisper \
    librosa scipy numpy \
    fastapi uvicorn requests pydantic \
    huggingface-hub python-dotenv pyyaml && \
```

**ë³€ê²½ í›„**:
```dockerfile
RUN python3.11 -m pip install --no-index --find-links=/wheels/ \
    torch torchaudio faster-whisper \
    librosa scipy numpy \
    fastapi uvicorn requests pydantic \
    huggingface-hub python-dotenv pyyaml \
    python-multipart && \
```

**ë¼ì¸ 31ì— ì¶”ê°€**:
```dockerfile
ENV STT_DEVICE=cpu
```

---

## ğŸ¯ ìµœì¢… ì²´í¬ë¦¬ìŠ¤íŠ¸

```
ì‚¬ì „ ì‘ì—…
â–¡ python-multipart wheel ì¶”ê°€ (deployment_package/wheels/)
â–¡ wheels.tar.gz ê°±ì‹ 
â–¡ api_server.py ìˆ˜ì • (device ì„¤ì •)
â–¡ Dockerfile.engine ìˆ˜ì • (python-multipart ì¶”ê°€, STT_DEVICE ì„¤ì •)
â–¡ ìƒˆ ì´ë¯¸ì§€ ë¹Œë“œ (scripts/build-engine-image.sh)

ë°°í¬
â–¡ ì„œë²„ë¡œ ì´ë¯¸ì§€ ì „ì†¡
â–¡ ê¸°ì¡´ ì»¨í…Œì´ë„ˆ ì¤‘ì§€/ì œê±°
â–¡ ìƒˆ ì´ë¯¸ì§€ ë¡œë“œ (docker load)
â–¡ ìƒˆ ì»¨í…Œì´ë„ˆ ì‹¤í–‰ (docker run)
â–¡ ë¡œê·¸ í™•ì¸ (docker logs)
â–¡ í—¬ìŠ¤ ì²´í¬ ì„±ê³µ (curl /health)
â–¡ ìŒì„± íŒŒì¼ í…ŒìŠ¤íŠ¸
```

---

## ğŸ“ ì •ë¦¬

### ê·¼ë³¸ ì›ì¸ 3ê°€ì§€:

1. **python-multipart ëˆ„ë½** 
   - âœ… Wheel ì¶”ê°€ë¡œ í•´ê²°

2. **CUDA ë“œë¼ì´ë²„ í˜¸í™˜ì„±**
   - âœ… í™˜ê²½ë³€ìˆ˜ ë°©ì‹ìœ¼ë¡œ CPU/CUDA ì„ íƒ ê°€ëŠ¥í•˜ê²Œ ë³€ê²½

3. **Exited ì»¨í…Œì´ë„ˆì—ì„œ exec ë¶ˆê°€**
   - âœ… ìƒˆ ì´ë¯¸ì§€ë¡œ ì¬ì‹œì‘í•˜ë©´ í•´ê²°

**ìƒíƒœ**: ğŸŸ¢ ëª…í™•í•œ í•´ê²° ë°©ì•ˆ ì œì‹œ âœ…
