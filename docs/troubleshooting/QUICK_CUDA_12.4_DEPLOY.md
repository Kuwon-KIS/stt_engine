# âš ï¸ âŒ [2026-02-03 v1.0-DEPRECATED] CUDA 12.4 ë°°í¬ (íê¸°ë¨)

**ë²„ì „**: v1.0-DEPRECATED (íê¸°ë¨)  
**ë‚ ì§œ**: 2026-02-03  
**ìƒíƒœ**: âŒ **ì‚¬ìš© ê¸ˆì§€** (Docker ì´ë¯¸ì§€ ë¹Œë“œ ë°©ì‹)

---

## ğŸ“‹ ë¬¸ì„œ ìƒíƒœ

| ë²„ì „ | ë‚ ì§œ | ìƒíƒœ | ì„¤ëª… |
|------|------|------|------|
| v1.0-DEPRECATED | 2026-02-03 | âŒ **íê¸°** | Macì—ì„œ wheel ë°›ì•„ Docker ë¹Œë“œ (CPU ë²„ì „ ìœ„í—˜) |

### âš ï¸ ì´ ë¬¸ì„œë¥¼ ì‚¬ìš©í•˜ë©´ ì•ˆ ë˜ëŠ” ì´ìœ 
- âŒ Macì—ì„œ Linuxìš© wheel ìˆ˜ì§‘ ì‹œë„ (ì•„í‚¤í…ì²˜ ë¶ˆì¼ì¹˜)
- âŒ Docker ë¹Œë“œ ì¤‘ ë„¤íŠ¸ì›Œí¬ ë¶ˆì•ˆì •
- âŒ CPU ë²„ì „ ë‹¤ìš´ë¡œë“œ ê°€ëŠ¥ì„±

### âœ… ëŒ€ì‹  ì´ ë¬¸ì„œë¥¼ ì½ìœ¼ì„¸ìš”
ğŸ‘‰ **[CORRECT_FINAL_DEPLOYMENT.md](CORRECT_FINAL_DEPLOYMENT.md)**

---

# âŒ ì´ì „ ë‚´ìš© (ì‘ë™í•˜ì§€ ì•ŠìŒ)

## ğŸ  ë¡œì»¬ ë¨¸ì‹ ì—ì„œ (40ë¶„)

### 1ï¸âƒ£ í´ë” ë° íŒŒì¼ ì¤€ë¹„

```bash
cd /Users/a113211/workspace/stt_engine

# CUDA 12.4ìš© wheels í´ë” ìƒì„±
mkdir -p deployment_package/wheels-cu124
```

### 2ï¸âƒ£ CUDA 12.4 PyTorch wheels ë‹¤ìš´ë¡œë“œ (10-15ë¶„)

```bash
python3 -m pip wheel torch==2.1.2 torchaudio==2.1.2 \
  --index-url https://download.pytorch.org/whl/cu124 \
  -w deployment_package/wheels-cu124/ \
  --no-deps

# ë‹¤ë¥¸ ì˜ì¡´ì„± ë‹¤ìš´ë¡œë“œ
python3 -m pip wheel \
  faster-whisper==1.0.3 \
  librosa==0.10.0 \
  numpy==1.24.3 \
  scipy==1.12.0 \
  huggingface-hub==0.21.4 \
  python-dotenv==1.0.0 \
  pydantic==2.5.3 \
  fastapi==0.109.0 \
  uvicorn==0.27.0 \
  requests==2.31.0 \
  pyyaml==6.0.1 \
  python-multipart==0.0.22 \
  -w deployment_package/wheels-cu124/ \
  --no-deps

# ë‹¤ìš´ë¡œë“œ í™•ì¸
ls -1 deployment_package/wheels-cu124/ | wc -l
# ì˜ˆìƒ: 60ê°œ ì´ìƒ
```

### 3ï¸âƒ£ Dockerfile.engine-cu124 ìƒì„±

ë‹¤ìŒ ë‚´ìš©ì„ `docker/Dockerfile.engine-cu124` íŒŒì¼ë¡œ ì €ì¥:

```dockerfile
FROM python:3.11-slim

# Install system dependencies
RUN apt-get update && apt-get install -y \
    libsndfile1 \
    ffmpeg \
    curl \
    ca-certificates \
    && rm -rf /var/lib/apt/lists/*

# Set working directory
WORKDIR /app

# Copy CUDA 12.4 wheels
COPY deployment_package/wheels-cu124/ /wheels/

# Install packages from wheels (offline)
RUN python3.11 -m pip install --no-index --find-links=/wheels/ \
    torch torchaudio faster-whisper \
    librosa scipy numpy \
    fastapi uvicorn requests pydantic \
    huggingface-hub python-dotenv pyyaml \
    python-multipart && \
    rm -rf /wheels/

# Copy application files
COPY stt_engine.py /app/
COPY api_server.py /app/
COPY requirements.txt /app/

# Create directories for models and logs
RUN mkdir -p /app/models /app/logs /app/audio

# Set environment variables
ENV PYTHONUNBUFFERED=1
ENV HF_HOME=/app/models
ENV STT_DEVICE=auto

# Expose port
EXPOSE 8003

# Health check
HEALTHCHECK --interval=30s --timeout=10s --start-period=5s --retries=3 \
    CMD curl -f http://localhost:8003/health || exit 1

# Run API server
CMD ["python3.11", "api_server.py"]
```

### 4ï¸âƒ£ Docker ì´ë¯¸ì§€ ë¹Œë“œ (20-25ë¶„)

```bash
cd /Users/a113211/workspace/stt_engine

docker build \
  -t stt-engine:cu124 \
  -f docker/Dockerfile.engine-cu124 \
  .

# ë¹Œë“œ ì™„ë£Œ í™•ì¸
docker images | grep cu124
```

### 5ï¸âƒ£ ì´ë¯¸ì§€ë¥¼ tar.gzë¡œ ì €ì¥ (2-3ë¶„)

```bash
mkdir -p build/output

docker save stt-engine:cu124 | gzip > build/output/stt-engine-cu124.tar.gz

# í¬ê¸° í™•ì¸
ls -lh build/output/stt-engine-cu124.tar.gz
# ì˜ˆìƒ: ~1.0-1.1GB
```

---

## ğŸ–¥ï¸ ì„œë²„ì—ì„œ (10-15ë¶„)

### 1ï¸âƒ£ ë¡œì»¬ì—ì„œ ì„œë²„ë¡œ ì´ë¯¸ì§€ ì „ì†¡ (5-10ë¶„)

```bash
# ë¡œì»¬ ë¨¸ì‹ ì—ì„œ ì‹¤í–‰

scp build/output/stt-engine-cu124.tar.gz ddpapp@dlddpgai1:/data/stt/

# ë˜ëŠ” ë‹¤ë¥¸ ì„œë²„ ì£¼ì†Œë©´:
# scp build/output/stt-engine-cu124.tar.gz user@server-ip:/path/to/
```

### 2ï¸âƒ£ ì„œë²„ì— SSH ì ‘ì† í›„ ì´ë¯¸ì§€ ë¡œë“œ (2-3ë¶„)

```bash
# ì„œë²„ì— ì ‘ì†
ssh ddpapp@dlddpgai1

# ì´ë¯¸ì§€ ë¡œë“œ
docker load -i /data/stt/stt-engine-cu124.tar.gz

# ë¡œë“œ í™•ì¸
docker images | grep cu124
# ì¶œë ¥: stt-engine  cu124  ... 1.1GB
```

### 3ï¸âƒ£ ê¸°ì¡´ ì»¨í…Œì´ë„ˆ ì •ë¦¬ (1ë¶„)

```bash
# ì‹¤í–‰ ì¤‘ì¸ ì»¨í…Œì´ë„ˆ ì¤‘ì§€
docker stop stt-engine 2>/dev/null || true

# ì»¨í…Œì´ë„ˆ ì œê±°
docker rm stt-engine 2>/dev/null || true

# í™•ì¸
docker ps -a | grep stt-engine
# (ì•„ë¬´ê²ƒë„ ë‚˜ì˜¤ì§€ ì•Šì•„ì•¼ í•¨)
```

### 4ï¸âƒ£ ìƒˆ ì»¨í…Œì´ë„ˆ ì‹¤í–‰ (1-2ë¶„)

```bash
docker run -d \
  --name stt-engine \
  -p 8003:8003 \
  -v /data/models:/app/models \
  -v /data/logs:/app/logs \
  --gpus all \
  stt-engine:cu124

# ì»¨í…Œì´ë„ˆ ìƒíƒœ í™•ì¸
docker ps | grep stt-engine
# ì¶œë ¥: stt-engine ... Up ... 0.0.0.0:8003->8003/tcp
```

### 5ï¸âƒ£ ë¡œê·¸ í™•ì¸ (CUDA ì´ˆê¸°í™” í™•ì¸)

```bash
docker logs -f stt-engine

# ì˜ˆìƒ ì¶œë ¥:
# âœ… faster-whisper ëª¨ë¸ ë¡œë“œ ì™„ë£Œ (Device: cuda, compute: float16)
# INFO:     Started server process
# INFO:     Uvicorn running on http://0.0.0.0:8003

# Ctrl+Cë¡œ ë¹ ì ¸ë‚˜ì˜¤ê¸°
```

### 6ï¸âƒ£ í—¬ìŠ¤ ì²´í¬ (API ì‘ë‹µ í™•ì¸)

```bash
curl -X GET http://localhost:8003/health

# ì˜ˆìƒ ì‘ë‹µ:
# {"status":"healthy","device":"cuda"}
```

---

## ğŸ¬ ìŒì„± íŒŒì¼ í…ŒìŠ¤íŠ¸

### 1ï¸âƒ£ í…ŒìŠ¤íŠ¸ ìŒì„± íŒŒì¼ ì¤€ë¹„

```bash
# ì„œë²„ì— í…ŒìŠ¤íŠ¸ íŒŒì¼ì´ ìˆìœ¼ë©´
ls /data/test_audio.wav

# ì—†ìœ¼ë©´ ë¡œì»¬ì—ì„œ ë‹¤ìš´ë¡œë“œí•˜ì—¬ ì„œë²„ë¡œ ì „ì†¡
scp /path/to/test_audio.wav ddpapp@dlddpgai1:/data/
```

### 2ï¸âƒ£ API í˜¸ì¶œë¡œ STT í…ŒìŠ¤íŠ¸

```bash
# ì„œë²„ì—ì„œ

curl -X POST http://localhost:8003/transcribe \
  -F "file=@/data/test_audio.wav"

# ì˜ˆìƒ ì‘ë‹µ (JSON):
# {
#   "text": "recognized text here...",
#   "duration_seconds": 5.2,
#   "processing_time_seconds": 1.2,
#   "model": "whisper-large-v3-turbo",
#   "device": "cuda"
# }
```

---

## ğŸ“Š ì§„í–‰ ìƒí™© ëª¨ë‹ˆí„°ë§

### ë¹Œë“œ ì§„í–‰ ì¤‘ (ë¡œì»¬)

```bash
# ë³„ë„ í„°ë¯¸ë„ì—ì„œ Docker ë¹Œë“œ ìƒí™© ë³´ê¸°
docker stats
```

### ë°°í¬ í›„ (ì„œë²„)

```bash
# ì‹¤ì‹œê°„ ë¡œê·¸ ëª¨ë‹ˆí„°ë§
docker logs -f stt-engine

# ë˜ëŠ” ë§ˆì§€ë§‰ 100ì¤„ë§Œ ë³´ê¸°
docker logs --tail 100 stt-engine

# GPU ì‚¬ìš©ë¥  í™•ì¸
nvidia-smi

# ë˜ëŠ” ì‹¤ì‹œê°„ ëª¨ë‹ˆí„°ë§
watch -n 1 nvidia-smi
```

---

## ğŸ†˜ ë¬¸ì œ ë°œìƒ ì‹œ

### ì»¨í…Œì´ë„ˆê°€ Exited ìƒíƒœë©´

```bash
# ë¡œê·¸ í™•ì¸
docker logs stt-engine

# ì—ëŸ¬ ë©”ì‹œì§€ ì°¾ê¸°
docker logs stt-engine 2>&1 | tail -50

# ì»¨í…Œì´ë„ˆ ìƒì„¸ ì •ë³´
docker inspect stt-engine
```

### CUDA ì—ëŸ¬ë©´

```bash
# nvidia-smi í™•ì¸
nvidia-smi

# GPU ë“œë¼ì´ë²„ì™€ CUDA Runtime í˜¸í™˜ì„± í™•ì¸
nvidia-smi | grep -E "Driver|CUDA"
# ì˜ˆìƒ: Driver 575.57, CUDA 12.9
```

### í¬íŠ¸ 8003ì´ ì´ë¯¸ ì‚¬ìš© ì¤‘ì´ë©´

```bash
# í¬íŠ¸ í™•ì¸
lsof -i :8003

# ê¸°ì¡´ í”„ë¡œì„¸ìŠ¤ ì¢…ë£Œ
kill -9 <PID>

# ë˜ëŠ” ë‹¤ë¥¸ í¬íŠ¸ ì‚¬ìš©
docker run -d --name stt-engine -p 8004:8003 --gpus all stt-engine:cu124
```

---

## âœ… ìµœì¢… ì²´í¬ë¦¬ìŠ¤íŠ¸

```
ë¡œì»¬ ë¹Œë“œ (50ë¶„ ì´ì†Œìš” ì‹œê°„ ì¤‘ 40ë¶„)
â˜‘ deployment_package/wheels-cu124/ í´ë” ìƒì„±
â˜‘ PyTorch CUDA 12.4 wheels ë‹¤ìš´ë¡œë“œ (10-15ë¶„)
â˜‘ ë‹¤ë¥¸ ì˜ì¡´ì„± wheels ë‹¤ìš´ë¡œë“œ
â˜‘ Dockerfile.engine-cu124 ìƒì„±
â˜‘ docker build ì‹œì‘ (20-25ë¶„)
â˜‘ docker saveë¡œ tar.gz ìƒì„± (~1.1GB)

ì„œë²„ ë°°í¬ (10-15ë¶„)
â˜‘ scpë¡œ ì´ë¯¸ì§€ ì „ì†¡ (5-10ë¶„)
â˜‘ docker load ì‹¤í–‰ (2-3ë¶„)
â˜‘ ê¸°ì¡´ ì»¨í…Œì´ë„ˆ ì œê±°
â˜‘ docker runìœ¼ë¡œ ìƒˆ ì»¨í…Œì´ë„ˆ ì‹¤í–‰
â˜‘ docker logsì—ì„œ cuda í™•ì¸
â˜‘ curl /healthë¡œ API ì‘ë‹µ í™•ì¸

ê²€ì¦
â˜‘ nvidia-smiì—ì„œ GPU ë©”ëª¨ë¦¬ ì‚¬ìš© í™•ì¸
â˜‘ ìŒì„± íŒŒì¼ë¡œ STT í…ŒìŠ¤íŠ¸
â˜‘ ì²˜ë¦¬ ì‹œê°„ í™•ì¸ (GPU: 1-2ì´ˆ, CPU: 5-10ì´ˆ)
```

---

**ìƒíƒœ**: ğŸŸ¢ ì¤€ë¹„ ì™„ë£Œ! ì§€ê¸ˆ ë°”ë¡œ ì‹œì‘ ê°€ëŠ¥ âœ…
