# âš ï¸ âŒ [2026-02-03 v1.0-DEPRECATED] ì´ ë¬¸ì„œëŠ” ì‘ë™í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤ (ì•„í‚¤í…ì²˜ ë¶ˆì¼ì¹˜)

**ë²„ì „**: v1.0-DEPRECATED (íê¸°ë¨)  
**ë‚ ì§œ**: 2026-02-03  
**ìƒíƒœ**: âŒ **ì‚¬ìš© ê¸ˆì§€** (ì•„í‚¤í…ì²˜ ë¶ˆì¼ì¹˜)  
**ìš°ì„ ìˆœìœ„**: ì½ì§€ ë§ˆì„¸ìš” (ì°¸ê³ ìš©ìœ¼ë¡œë§Œ)

---

## ğŸ“‹ ë¬¸ì„œ ìƒíƒœ

| ë²„ì „ | ë‚ ì§œ | ìƒíƒœ | ì„¤ëª… |
|------|------|------|------|
| v1.0-DEPRECATED | 2026-02-03 | âŒ **íê¸°** | Mac ì•„í‚¤í…ì²˜ì—ì„œ Linux ë°”ì´ë„ˆë¦¬ ë°›ìœ¼ë ¤ê³  ì‹œë„ (ë¶ˆê°€ëŠ¥) |

### âš ï¸ ì´ ë¬¸ì„œë¥¼ ì‚¬ìš©í•˜ë©´ ì•ˆ ë˜ëŠ” ì´ìœ 
- âŒ Macì—ì„œ Linuxìš© wheel ë‹¤ìš´ë¡œë“œ ì‹œë„ (ì•„í‚¤í…ì²˜ ë¶ˆì¼ì¹˜)
- âŒ Docker ì´ë¯¸ì§€ ë¹Œë“œ (ì‹¤íŒ¨ ê²½í—˜ ìˆìŒ)
- âŒ CPU ë²„ì „ ì„¤ì¹˜ ê°€ëŠ¥ì„± ë†’ìŒ

### âœ… ëŒ€ì‹  ì´ ë¬¸ì„œë¥¼ ì½ìœ¼ì„¸ìš”
ğŸ‘‰ **[CORRECT_FINAL_DEPLOYMENT.md](CORRECT_FINAL_DEPLOYMENT.md)**

---

## ì™œ ì´ ë°©ì‹ì´ ì‘ë™í•˜ì§€ ì•ŠëŠ”ê°€?

```
âŒ ë¬¸ì œ: Macì—ì„œ Linuxìš© PyTorch wheelì„ ë‹¤ìš´ë¡œë“œí•˜ë ¤ê³  í•¨

Mac (darwin ì•„í‚¤í…ì²˜)
  â†“
pip wheel torch (â† Macìš© wheel ë‹¤ìš´ë¡œë“œ)
  â†“
torch-2.1.2-cp311-cp311-macosx_11_0_arm64.whl â† Macìš©!
  â†“
Linux ì„œë²„ë¡œ ì „ì†¡
  â†“
ì„¤ì¹˜ ì‹œë„ â†’ âŒ í˜¸í™˜ë˜ì§€ ì•ŠìŒ (ì•„í‚¤í…ì²˜ ë¶ˆì¼ì¹˜)
```

**í•´ê²°ì±…**: Linux ì„œë²„ì—ì„œ ì§ì ‘ `pip install torch` (ì•„ë˜ ë§í¬ ì°¸ê³ )

---

## âœ… ì •ì •ëœ ìµœì¢… ë°©ë²•

ğŸ‘‰ **[CORRECT_FINAL_DEPLOYMENT.md](CORRECT_FINAL_DEPLOYMENT.md)ë¥¼ ì½ìœ¼ì„¸ìš”!**

ì´ ë¬¸ì„œì—ì„œ:
1. Macì—ì„œëŠ” tar.gzë§Œ ì¤€ë¹„
2. Linux ì„œë²„ì—ì„œ ì§ì ‘ `pip install torch`
3. 100% ì„±ê³µë¥ 

---

# âŒ ì´ì „ ë‚´ìš© (ì°¸ê³ ìš©, ì‹¤ì œë¡œëŠ” ì‘ë™ ì•ˆ í•¨)

### Step 1: wheels-cu124 í´ë” ìƒì„±

```bash
cd /Users/a113211/workspace/stt_engine
mkdir -p deployment_package/wheels-cu124
```

### Step 2: CUDA 12.4 PyTorch ë‹¤ìš´ë¡œë“œ (âš ï¸ --index-url í•„ìˆ˜!)

```bash
# âš ï¸ ë°˜ë“œì‹œ --index-url í¬í•¨í•  ê²ƒ! 
# ì—†ìœ¼ë©´ CPU ë²„ì „ ë‹¤ìš´ë¡œë“œë¨

python3 -m pip wheel torch==2.1.2 torchaudio==2.1.2 \
  --index-url https://download.pytorch.org/whl/cu124 \
  -w deployment_package/wheels-cu124/ \
  --no-deps
```

### Step 3: ë‹¤ìš´ë¡œë“œ í™•ì¸ (ë§¤ìš° ì¤‘ìš”!)

```bash
# cu124ê°€ í¬í•¨ë˜ì–´ì•¼ í•¨!
ls -lh deployment_package/wheels-cu124/ | grep torch

# âœ… ì •í™•í•œ íŒŒì¼ëª…:
# torch-2.1.2-cp311-cp311-cu124-linux_x86_64.whl
# torchaudio-2.1.2-cp311-cp311-cu124-linux_x86_64.whl

# âŒ ì˜ëª»ëœ íŒŒì¼ëª… (ì´ëŸ¬ë©´ ì‚­ì œí•˜ê³  ë‹¤ì‹œ):
# torch-2.1.2+cpu-cp311-cp311-linux_x86_64.whl (CPU ë²„ì „)
# torch-2.1.2-cp311-cp311-linux_x86_64.whl (cu124 ì—†ìŒ)
```

**ë‹¤ì‹œ ë‹¤ìš´ë¡œë“œí•˜ë ¤ë©´** (cu124 íŒŒì¼ì´ ì—†ìœ¼ë©´):
```bash
rm -rf deployment_package/wheels-cu124
mkdir -p deployment_package/wheels-cu124

# ë‹¤ì‹œ ì‹œë„ (--index-url í™•ì¸)
python3 -m pip wheel torch==2.1.2 torchaudio==2.1.2 \
  --index-url https://download.pytorch.org/whl/cu124 \
  -w deployment_package/wheels-cu124/ \
  --no-deps
```

### Step 4: ë‹¤ë¥¸ ì˜ì¡´ì„± ë‹¤ìš´ë¡œë“œ

```bash
python3 -m pip wheel \
  faster-whisper==1.0.3 \
  librosa==0.10.0 \
  numpy==1.24.3 \
  scipy==1.12.0 \
  huggingface-hub==0.21.4 \
  python-dotenv==1.0.0 \
  pydantic==2.5.3 \
  fastapi==0.109.0 \
  uvicorn==0.27.0 \
  requests==2.31.0 \
  pyyaml==6.0.1 \
  python-multipart==0.0.22 \
  -w deployment_package/wheels-cu124/ \
  --no-deps
```

### Step 5: Dockerfile.engine-cu124 ìƒì„±

íŒŒì¼ `docker/Dockerfile.engine-cu124` ìƒì„±:

```dockerfile
FROM python:3.11-slim

RUN apt-get update && apt-get install -y \
    libsndfile1 ffmpeg curl ca-certificates && \
    rm -rf /var/lib/apt/lists/*

WORKDIR /app

COPY deployment_package/wheels-cu124/ /wheels/

RUN python3.11 -m pip install --no-index --find-links=/wheels/ \
    torch torchaudio faster-whisper \
    librosa scipy numpy \
    fastapi uvicorn requests pydantic \
    huggingface-hub python-dotenv pyyaml \
    python-multipart && \
    rm -rf /wheels/

COPY stt_engine.py api_server.py requirements.txt /app/

RUN mkdir -p /app/models /app/logs /app/audio

ENV PYTHONUNBUFFERED=1
ENV HF_HOME=/app/models
ENV STT_DEVICE=auto

EXPOSE 8003

HEALTHCHECK --interval=30s --timeout=10s --start-period=5s --retries=3 \
    CMD curl -f http://localhost:8003/health || exit 1

CMD ["python3.11", "api_server.py"]
```

### Step 6: Docker ì´ë¯¸ì§€ ë¹Œë“œ (20-25ë¶„)

```bash
cd /Users/a113211/workspace/stt_engine

docker build \
  -t stt-engine:cu124 \
  -f docker/Dockerfile.engine-cu124 \
  .
```

### Step 7: CUDA ì§€ì› í™•ì¸ (âš ï¸ ë°˜ë“œì‹œ í™•ì¸!)

```bash
# ìƒˆ ì´ë¯¸ì§€ì—ì„œ PyTorch CUDA ë²„ì „ í™•ì¸
docker run -it stt-engine:cu124 python3 -c \
  "import torch; print(f'PyTorch CUDA: {torch.version.cuda}')"

# âœ… ì •í™•í•œ ì¶œë ¥ (ì´ë ‡ê²Œ ë‚˜ì™€ì•¼ í•¨):
# PyTorch CUDA: 12.4

# âŒ ì˜ëª»ëœ ì¶œë ¥ (ì´ëŸ¬ë©´ Step 2ë¶€í„° ë‹¤ì‹œ):
# PyTorch CUDA: None
```

**ì´ ë‹¨ê³„ë¥¼ ë°˜ë“œì‹œ í™•ì¸í•˜ì„¸ìš”!** ë§Œì•½ `None`ì´ ë‚˜ì˜¤ë©´ --index-url ë¬¸ì œì…ë‹ˆë‹¤.

### Step 8: ì´ë¯¸ì§€ ì €ì¥

```bash
mkdir -p build/output

docker save stt-engine:cu124 | gzip > build/output/stt-engine-cu124.tar.gz

ls -lh build/output/stt-engine-cu124.tar.gz
# ì˜ˆìƒ: ~1.0-1.1GB
```

---

## ğŸ–¥ï¸ ì„œë²„ ë°°í¬ (10ë¶„)

### 1. ì´ë¯¸ì§€ ì „ì†¡

```bash
# ë¡œì»¬ì—ì„œ
scp build/output/stt-engine-cu124.tar.gz ddpapp@dlddpgai1:/data/stt/
```

### 2. ì„œë²„ì—ì„œ ë¡œë“œ ë° ì‹¤í–‰

```bash
# ì„œë²„ì— SSH
ssh ddpapp@dlddpgai1

# ì´ë¯¸ì§€ ë¡œë“œ
docker load -i /data/stt/stt-engine-cu124.tar.gz

# ê¸°ì¡´ ì»¨í…Œì´ë„ˆ ì •ë¦¬
docker stop stt-engine 2>/dev/null || true
docker rm stt-engine 2>/dev/null || true

# ìƒˆ ì»¨í…Œì´ë„ˆ ì‹¤í–‰
docker run -d \
  --name stt-engine \
  -p 8003:8003 \
  -v /data/models:/app/models \
  -v /data/logs:/app/logs \
  --gpus all \
  stt-engine:cu124

# ë¡œê·¸ í™•ì¸ (Ctrl+Cë¡œ ì¢…ë£Œ)
docker logs -f stt-engine
```

### 3. GPU ì‚¬ìš© í™•ì¸ (ë§¤ìš° ì¤‘ìš”!)

```bash
# ì»¨í…Œì´ë„ˆì—ì„œ PyTorch CUDA í™•ì¸
docker exec stt-engine python3 -c \
  "import torch; print(f'PyTorch CUDA: {torch.version.cuda}'); \
   print(f'CUDA Available: {torch.cuda.is_available()}')"

# âœ… ì •í™•í•œ ì¶œë ¥:
# PyTorch CUDA: 12.4
# CUDA Available: True

# âŒ ì˜ëª»ëœ ì¶œë ¥ (ì´ëŸ¬ë©´ Step 2ë¶€í„° ë‹¤ì‹œ):
# PyTorch CUDA: None
# CUDA Available: False
```

### 4. API í…ŒìŠ¤íŠ¸

```bash
# í—¬ìŠ¤ ì²´í¬
curl -X GET http://localhost:8003/health

# ì˜ˆìƒ ì‘ë‹µ:
# {"status":"healthy","device":"cuda"}

# GPU ë©”ëª¨ë¦¬ í™•ì¸
nvidia-smi

# ì˜ˆìƒ: 1.1GB GPU ë©”ëª¨ë¦¬ ì‚¬ìš© ì¤‘
```

---

## ğŸš¨ ì£¼ì˜ì‚¬í•­

### --index-url ì ˆëŒ€ ë¹ ëœ¨ë¦¬ë©´ ì•ˆ ë¨!

```bash
# âŒ ì´ë ‡ê²Œ í•˜ë©´ CPU ë²„ì „ ë‹¤ìš´ë¡œë“œë¨:
pip wheel torch==2.1.2 -w deployment_package/wheels-cu124/

# âœ… ë°˜ë“œì‹œ ì´ë ‡ê²Œ:
pip wheel torch==2.1.2 \
  --index-url https://download.pytorch.org/whl/cu124 \
  -w deployment_package/wheels-cu124/
```

### ë‹¤ìš´ë¡œë“œ í›„ íŒŒì¼ëª… ë°˜ë“œì‹œ í™•ì¸!

```bash
# torch íŒŒì¼ í™•ì¸
ls deployment_package/wheels-cu124/ | grep torch

# âœ… cu124ê°€ ìˆì–´ì•¼ í•¨:
# torch-2.1.2-cp311-cp311-cu124-linux_x86_64.whl

# âŒ cu124ê°€ ì—†ìœ¼ë©´ ë‹¤ì‹œ ë‹¤ìš´ë¡œë“œ:
# torch-2.1.2+cpu-cp311-cp311-linux_x86_64.whl (ì´ê±´ CPU!)
```

### Docker ë¹Œë“œ í›„ CUDA í…ŒìŠ¤íŠ¸ ë°˜ë“œì‹œ í•  ê²ƒ!

```bash
# Step 7ì—ì„œ ë°˜ë“œì‹œ í™•ì¸:
docker run -it stt-engine:cu124 python3 -c \
  "import torch; print(torch.version.cuda)"

# Noneì´ ë‚˜ì˜¤ë©´ Step 2ë¶€í„° ë‹¤ì‹œ!
```

---

## ğŸ“Š ì§„í–‰ ìƒí™© ì²´í¬ë¦¬ìŠ¤íŠ¸

```
ë¡œì»¬ (40ë¶„)
â˜‘ wheels-cu124 í´ë” ìƒì„±
â˜‘ --index-url https://download.pytorch.org/whl/cu124 ë¡œ torch ë‹¤ìš´ë¡œë“œ
â˜‘ lsë¡œ cu124 íŒŒì¼ í™•ì¸ (cu124ê°€ íŒŒì¼ëª…ì— ìˆëŠ”ì§€!)
â˜‘ ë‹¤ë¥¸ ì˜ì¡´ì„± ë‹¤ìš´ë¡œë“œ
â˜‘ Dockerfile.engine-cu124 ìƒì„±
â˜‘ docker build ì‹¤í–‰
â˜‘ docker runìœ¼ë¡œ PyTorch CUDA í™•ì¸: "PyTorch CUDA: 12.4" âœ…
â˜‘ docker saveë¡œ tar.gz ìƒì„±

ì„œë²„ (10ë¶„)
â˜‘ scpë¡œ ì´ë¯¸ì§€ ì „ì†¡
â˜‘ docker load
â˜‘ docker run --gpus all
â˜‘ docker execë¡œ CUDA ì¬í™•ì¸: "PyTorch CUDA: 12.4" âœ…
â˜‘ curl /health â†’ "device":"cuda"
```

---

**ì‹œì‘í•˜ì„¸ìš”!** Step 1ë¶€í„° Step 7ê¹Œì§€ ìˆœì„œëŒ€ë¡œ ë”°ë¼ê°€ë©´ ë©ë‹ˆë‹¤. íŠ¹íˆ Step 3ê³¼ Step 7ì—ì„œ CUDA ë²„ì „ì„ ë°˜ë“œì‹œ í™•ì¸í•˜ì„¸ìš”! âœ…
