# ğŸ¯ Docker ëª¨ë¸ ë§ˆìš´íŠ¸ ê°€ì´ë“œ

**í˜„ì¬ ìƒíƒœ**: âœ… ë§ˆìš´íŠ¸ ì™„ë²½ ì§€ì›

---

## ğŸ“Š í˜„ì¬ ëª¨ë¸ ìƒíƒœ

### ë¡œì»¬ ëª¨ë¸ (1.4GB)
```
models/
â”œâ”€â”€ models--openai--whisper-large-v3-turbo/    # HuggingFace ìºì‹œ í˜•ì‹
â”œâ”€â”€ openai_whisper-large-v3-turbo/             # Faster-Whisper ì‚¬ìš© ê²½ë¡œ â­
â””â”€â”€ whisper-model.tar.gz                       # ì••ì¶•ë³¸ (1.4GB)
```

**ìƒíƒœ**:
- âœ… ë¡œì»¬ì—ì„œ ì´ë¯¸ ë‹¤ìš´ë¡œë“œë¨
- âœ… Docker ì´ë¯¸ì§€ì— **í¬í•¨ë˜ì§€ ì•ŠìŒ** (ì´ë¯¸ì§€ í¬ê¸° ìµœì†Œí™”)
- âœ… ë§ˆìš´íŠ¸ë¥¼ í†µí•´ ì£¼ì… ê°€ëŠ¥

---

## ğŸ³ Docker ë§ˆìš´íŠ¸ ë°©ë²•

### ë°©ë²• 1: ë¡œì»¬ ëª¨ë¸ ë§ˆìš´íŠ¸ (ê¶Œì¥)

```bash
docker run -p 8003:8003 \
  -v /path/to/local/models:/app/models \
  stt-engine:linux-x86_64
```

**ì˜ˆì‹œ** (ì‹¤ì œ ê²½ë¡œ):
```bash
docker run -p 8003:8003 \
  -v ~/workspace/stt_engine/models:/app/models \
  stt-engine:linux-x86_64
```

---

### ë°©ë²• 2: Docker Compose ì‚¬ìš©

**docker-compose.yml**:
```yaml
version: '3.8'

services:
  stt-engine:
    image: stt-engine:linux-x86_64
    ports:
      - "8003:8003"
    volumes:
      - ./models:/app/models          # ë¡œì»¬ models â†’ ì»¨í…Œì´ë„ˆ /app/models
      - ./logs:/app/logs              # ë¡œê·¸ ì €ì¥
    environment:
      - HF_HOME=/app/models           # Hugging Face ìºì‹œ ê²½ë¡œ
    restart: unless-stopped
```

**ì‹¤í–‰**:
```bash
docker-compose up -d
```

---

### ë°©ë²• 3: ì••ì¶•ë³¸ ì‚¬ìš© (ì˜¨ë¼ì¸ í™˜ê²½)

ì„œë²„ì— `models/whisper-model.tar.gz` ë¥¼ ì „ì†¡ í›„:

```bash
# 1. ì••ì¶• í•´ì œ
cd /path/to/deployment_package
tar -xzf models/whisper-model.tar.gz

# 2. Docker ì‹¤í–‰
docker run -p 8003:8003 \
  -v ./openai_whisper-large-v3-turbo:/app/models/openai_whisper-large-v3-turbo \
  stt-engine:linux-x86_64
```

---

## âš™ï¸ ëª¨ë¸ ê²½ë¡œ ì„¤ì •

### Docker ì´ë¯¸ì§€ ë‚´ë¶€ êµ¬ì¡°

```dockerfile
ENV HF_HOME=/app/models

# ì• í”Œë¦¬ì¼€ì´ì…˜ì´ ì°¾ëŠ” ê²½ë¡œ
models/
â””â”€â”€ openai_whisper-large-v3-turbo/
    â”œâ”€â”€ config.json
    â”œâ”€â”€ model.bin (ë˜ëŠ” safetensors)
    â”œâ”€â”€ preprocessor_config.json
    â”œâ”€â”€ tokenizer.json
    â””â”€â”€ ...
```

### ì†ŒìŠ¤ ì½”ë“œì—ì„œì˜ ì„¤ì •

**api_server.py** (í˜„ì¬):
```python
model_path = Path(__file__).parent / "models" / "openai_whisper-large-v3-turbo"
stt = WhisperSTT(str(model_path), device="cuda")
```

**í™˜ê²½ë³€ìˆ˜ë¡œ ë³€ê²½ ê°€ëŠ¥** (ê¶Œì¥):
```python
import os

model_path = os.getenv(
    "MODEL_PATH",
    Path(__file__).parent / "models" / "openai_whisper-large-v3-turbo"
)
stt = WhisperSTT(str(model_path), device="cuda")
```

**ì‹¤í–‰í•  ë•Œ**:
```bash
# ì»¤ìŠ¤í…€ ê²½ë¡œ ì‚¬ìš©
MODEL_PATH=/custom/path/to/model python3.11 api_server.py

# ë˜ëŠ” Dockerì—ì„œ
docker run -e MODEL_PATH=/app/models/custom_model \
  -v /path/to/model:/app/models/custom_model \
  stt-engine:linux-x86_64
```

---

## ğŸ“¦ ë°°í¬ ì‹œë‚˜ë¦¬ì˜¤ë³„ ê°€ì´ë“œ

### ì‹œë‚˜ë¦¬ì˜¤ 1: ë¡œì»¬ì—ì„œ ê°œë°œ ì¤‘

```bash
# ëª¨ë¸ì´ ì´ë¯¸ ë¡œì»¬ì— ìˆìœ¼ë¯€ë¡œ ì§ì ‘ ì‚¬ìš©
python3.11 api_server.py

# ë˜ëŠ” Dockerë¡œ í…ŒìŠ¤íŠ¸
docker run -p 8003:8003 \
  -v $(pwd)/models:/app/models \
  stt-engine:linux-x86_64
```

---

### ì‹œë‚˜ë¦¬ì˜¤ 2: Linux ì„œë²„ ë°°í¬ (ì²˜ìŒ)

```bash
# 1. ëª¨ë¸ íŒŒì¼ ì „ì†¡ (ë¡œì»¬ â†’ ì„œë²„)
scp models/whisper-model.tar.gz user@server:/home/user/deployment/

# 2. ì„œë²„ì—ì„œ ì••ì¶• í•´ì œ
ssh user@server
cd /home/user/deployment
tar -xzf whisper-model.tar.gz

# 3. Docker ì‹¤í–‰
docker run -p 8003:8003 \
  -v /home/user/deployment/openai_whisper-large-v3-turbo:/app/models/openai_whisper-large-v3-turbo \
  stt-engine:linux-x86_64
```

---

### ì‹œë‚˜ë¦¬ì˜¤ 3: ë‹¤ì¤‘ ì„œë²„ ë°°í¬ (ëª¨ë¸ ê³µìœ )

```bash
# ì¤‘ì•™ NFS/ê³µìœ  ìŠ¤í† ë¦¬ì§€ì— ëª¨ë¸ ì €ì¥
/mnt/shared_models/openai_whisper-large-v3-turbo/

# ê° ì„œë²„ì—ì„œ ë§ˆìš´íŠ¸
docker run -p 8003:8003 \
  -v /mnt/shared_models/openai_whisper-large-v3-turbo:/app/models/openai_whisper-large-v3-turbo \
  stt-engine:linux-x86_64
```

---

## ğŸ” ëª¨ë¸ ê²½ë¡œ ê²€ì¦

Docker ì‹¤í–‰ í›„ ëª¨ë¸ì´ ì œëŒ€ë¡œ ë¡œë“œë˜ì—ˆëŠ”ì§€ í™•ì¸:

```bash
# 1. í—¬ìŠ¤ ì²´í¬
curl http://localhost:8003/health

# ì˜ˆìƒ ê²°ê³¼:
# {"status": "ok", "version": "1.0.0", "engine": "faster-whisper"}

# 2. ë¡œê·¸ í™•ì¸
docker logs <container_id> | grep "faster-whisper ëª¨ë¸"

# 3. ëª¨ë¸ ê²½ë¡œ ê²€ì¦
docker exec <container_id> ls -lh /app/models/openai_whisper-large-v3-turbo/
```

---

## ğŸ’¾ ëª¨ë¸ ë‹¤ìš´ë¡œë“œê°€ í•„ìš”í•œ ê²½ìš°

ë§ˆìš´íŠ¸í•  ëª¨ë¸ì´ ì—†ë‹¤ë©´, Docker ì»¨í…Œì´ë„ˆ ì‹¤í–‰ ì‹œ ìë™ìœ¼ë¡œ ë‹¤ìš´ë¡œë“œ:

```bash
docker run -p 8003:8003 \
  -v /path/to/local/models:/app/models \
  stt-engine:linux-x86_64

# ì²« ì‹¤í–‰ ì‹œ:
# 1. /app/modelsì´ ë¹„ì–´ìˆìŒ
# 2. Hugging Faceì—ì„œ ìë™ ë‹¤ìš´ë¡œë“œ
# 3. /app/modelsì— ìºì‹œë¨
# 4. ì´í›„ ì¬ì‚¬ìš© ê°€ëŠ¥
```

**ì£¼ì˜**: ì˜¨ë¼ì¸ ì—°ê²° í•„ìš”í•˜ë©°, ëª¨ë¸ ë‹¤ìš´ë¡œë“œì— ì‹œê°„ ì†Œìš” (ëª¨ë¸ í¬ê¸°ì— ë”°ë¼)

---

## ğŸ¯ ê¶Œì¥ ë°°í¬ êµ¬ì„±

### ì™„ì „ ì˜¤í”„ë¼ì¸ ë°°í¬ (ì¶”ì²œ)

```bash
# ì „ì†¡ íŒŒì¼
build/output/stt-engine-linux-x86_64.tar     # 1.1GB
deployment_package/wheels.tar.gz              # 400MB
models/whisper-model.tar.gz                   # 1.4GB

# ì„œë²„ì—ì„œ ì„¤ì¹˜
docker load -i stt-engine-linux-x86_64.tar
tar -xzf wheels.tar.gz
tar -xzf whisper-model.tar.gz -C ./models

# ì‹¤í–‰
docker run -p 8003:8003 \
  -v $(pwd)/openai_whisper-large-v3-turbo:/app/models/openai_whisper-large-v3-turbo \
  stt-engine:linux-x86_64
```

---

## ğŸ“‹ ì²´í¬ë¦¬ìŠ¤íŠ¸

ë§ˆìš´íŠ¸ ì„¤ì • ì „ í™•ì¸ì‚¬í•­:

- [ ] ë¡œì»¬ ëª¨ë¸ ê²½ë¡œ í™•ì¸: `models/openai_whisper-large-v3-turbo/` ì¡´ì¬?
- [ ] Docker ì´ë¯¸ì§€ ë¡œë“œë¨: `docker images | grep stt-engine`
- [ ] ë§ˆìš´íŠ¸ ê²½ë¡œ ê¶Œí•œ: `-v` í”Œë˜ê·¸ ê²½ë¡œì— ì½ê¸° ê¶Œí•œ?
- [ ] ë””ìŠ¤í¬ ê³µê°„: ëª¨ë¸ í¬ê¸°(~2GB) + ì„ì‹œ íŒŒì¼ ê³µê°„ í™•ì¸?

---

**ê²°ë¡ **: í˜„ì¬ ìƒíƒœëŠ” ë§ˆìš´íŠ¸ë¥¼ ìœ„í•´ ì™„ë²½í•˜ê²Œ ì¤€ë¹„ë˜ì–´ ìˆìŠµë‹ˆë‹¤! ğŸ‰
