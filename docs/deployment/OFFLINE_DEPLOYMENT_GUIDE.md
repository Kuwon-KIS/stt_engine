# ğŸš€ STT Engine ì˜¤í”„ë¼ì¸ ë°°í¬ ìµœì¢… ê°€ì´ë“œ

**ìƒí™©:** RHEL 8.9 Linux ì„œë²„ëŠ” ì™¸ë¶€ ì¸í„°ë„· ì—†ìŒ â†’ macOSì—ì„œ íŒ¨í‚¤ì§€ ì¤€ë¹„ â†’ ì„œë²„ë¡œ transfer â†’ ì„¤ì¹˜

---

## ğŸ“¦ ì¤€ë¹„ëœ ë°°í¬ íŒŒì¼

### ì˜µì…˜ 1: ê¶Œì¥ (2.8GB - ì™„ì „ íŒ¨í‚¤ì§€)
```bash
stt_engine_deployment_final.tar.gz
```
- âœ… 44ê°œ ì¼ë°˜ íŒ¨í‚¤ì§€ wheels í¬í•¨
- âœ… ëª¨ë“  ì„¤ì • ìŠ¤í¬ë¦½íŠ¸
- âœ… ìë™ PyTorch ì˜¨ë¼ì¸ ì„¤ì¹˜ ìŠ¤í¬ë¦½íŠ¸
- âœ… ëª¨ë“  ë¬¸ì„œ í¬í•¨

### ì˜µì…˜ 2: ê²½ëŸ‰ (137MB - wheelsë§Œ)
```bash
stt_engine_deployment_slim_v2.tar.gz
```
- 44ê°œ wheelsë§Œ í¬í•¨ (venv ì œì™¸)
- PyTorchëŠ” Linux ì„œë²„ì—ì„œ ì˜¨ë¼ì¸ ì„¤ì¹˜

---

## ğŸ¯ Linux ì„œë²„ ë°°í¬ ì ˆì°¨

### Step 1: íŒŒì¼ ì „ì†¡ (macOS â†’ Linux ì„œë²„)

```bash
# macOS í„°ë¯¸ë„ì—ì„œ:
scp stt_engine_deployment_final.tar.gz user@your-server:/tmp/

# ë˜ëŠ” ê²½ëŸ‰ ë²„ì „:
scp stt_engine_deployment_slim_v2.tar.gz user@your-server:/tmp/
```

### Step 2: ì„œë²„ì—ì„œ ì¶”ì¶œ ë° ì„¤ì •

```bash
# Linux ì„œë²„ì—ì„œ ë¡œê·¸ì¸:
ssh user@your-server

# ì¶”ì¶œ
cd /tmp
tar -xzf stt_engine_deployment_final.tar.gz
cd stt_engine

# ë˜ëŠ”
tar -xzf stt_engine_deployment_slim_v2.tar.gz
cd stt_engine
```

### Step 3: PyTorch ìë™ ì„¤ì¹˜

#### ì˜µì…˜ A: ìë™ ìŠ¤í¬ë¦½íŠ¸ (ê¶Œì¥)
```bash
bash LINUX_PYTORCH_INSTALL.sh
```

**ìŠ¤í¬ë¦½íŠ¸ê°€ í•˜ëŠ” ì¼:**
- ì‹œìŠ¤í…œ ì •ë³´ í™•ì¸ (Python, CUDA, GPU)
- ê°€ìƒí™˜ê²½ í™œì„±í™”
- pip ì—…ê·¸ë ˆì´ë“œ
- 44ê°œ wheels ì„¤ì¹˜
- **PyTorch ì˜¨ë¼ì¸ ë‹¤ìš´ë¡œë“œ ë° ì„¤ì¹˜** (ì•½ 10-20ë¶„)
- ì„¤ì¹˜ ê²€ì¦ (GPU í™•ì¸)
- ë‹¤ìŒ ë‹¨ê³„ ì•ˆë‚´

**ì˜ˆìƒ ì†Œìš” ì‹œê°„:** 15-30ë¶„

#### ì˜µì…˜ B: í•œ ì¤„ ëª…ë ¹
```bash
source venv/bin/activate && \
pip install --upgrade pip && \
pip install deployment_package/wheels/*.whl && \
pip install torch torchaudio torchvision
```

#### ì˜µì…˜ C: ë‹¨ê³„ë³„ ìˆ˜ë™ ì„¤ì¹˜
```bash
# 1. ê°€ìƒí™˜ê²½ í™œì„±í™”
source venv/bin/activate

# 2. pip ì—…ê·¸ë ˆì´ë“œ
pip install --upgrade pip setuptools wheel

# 3. ê¸°ì¡´ wheels ì„¤ì¹˜
find deployment_package/wheels -name "*.whl" ! -name "torch*" ! -name "torchaudio*" -type f \
  | xargs pip install -q

# 4. PyTorch ì„¤ì¹˜ (ìë™ ì„ íƒ)
pip install torch torchaudio torchvision

# ë˜ëŠ” CUDA 12.4 ëª…ì‹œ:
pip install torch torchaudio torchvision \
    --index-url https://download.pytorch.org/whl/cu124
```

### Step 4: ì„¤ì¹˜ ê²€ì¦

```bash
python3 << 'EOF'
import torch
import torchaudio

print(f"âœ… PyTorch: {torch.__version__}")
print(f"âœ… torchaudio: {torchaudio.__version__}")
print(f"âœ… CUDA Available: {torch.cuda.is_available()}")

if torch.cuda.is_available():
    print(f"âœ… GPU: {torch.cuda.get_device_name(0)}")
    print(f"âœ… GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB")
EOF
```

**ì˜ˆìƒ ì¶œë ¥:**
```
âœ… PyTorch: 2.4.0+cu124 (ë˜ëŠ” ìµœì‹  ë²„ì „)
âœ… torchaudio: 2.4.0+cu124
âœ… CUDA Available: True
âœ… GPU: NVIDIA A100 (ë˜ëŠ” ë‹¹ì‹ ì˜ GPU)
âœ… GPU Memory: 40.0 GB
```

### Step 5: ëª¨ë¸ ë‹¤ìš´ë¡œë“œ

```bash
# venv í™œì„±í™” ìƒíƒœì—ì„œ:
python3 download_model.py
```

**ì˜ˆìƒ ì†Œìš” ì‹œê°„:** 15-30ë¶„ (ë„¤íŠ¸ì›Œí¬ ì†ë„ì— ë”°ë¼)

**ë‹¤ìš´ë¡œë“œë  ëª¨ë¸:**
- OpenAI Whisper Large v3 (~5GB)
- HuggingFaceì—ì„œ ìë™ ë‹¤ìš´ë¡œë“œ

### Step 6: API ì„œë²„ ì‹¤í–‰

```bash
python3 api_server.py
```

**ì¶œë ¥:**
```
INFO:     Uvicorn running on http://0.0.0.0:8001
```

### Step 7: í—¬ìŠ¤ ì²´í¬

```bash
# ë‹¤ë¥¸ í„°ë¯¸ë„ì—ì„œ:
curl http://localhost:8001/health

# ì‘ë‹µ:
# {"status":"ok","version":"1.0.0"}
```

---

## ğŸ”§ íŠ¸ëŸ¬ë¸”ìŠˆíŒ…

### ë¬¸ì œ 1: "torch not found"
**ì›ì¸:** ê°€ìƒí™˜ê²½ ë¯¸í™œì„±í™”

**í•´ê²°:**
```bash
source venv/bin/activate
python3 -c "import torch; print(torch.__version__)"
```

### ë¬¸ì œ 2: "CUDA not available" (ê²½ê³ )
**ì›ì¸:** NVIDIA ë“œë¼ì´ë²„/CUDA ë¶ˆì¼ì¹˜

**í•´ê²°:** CPU ëª¨ë“œë¡œë„ ì‘ë™ (ëŠë¦¼), ë˜ëŠ”:
```bash
# NVIDIA driver í™•ì¸
nvidia-smi

# CUDA ë²„ì „ í™•ì¸
nvcc --version
```

### ë¬¸ì œ 3: "Connection refused" (ëª¨ë¸ ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨)
**ì›ì¸:** ì¸í„°ë„· ì—°ê²° í•„ìš”

**í•´ê²°:**
- Linux ì„œë²„ì— ì¸í„°ë„· ì—°ê²° í•„ìš” (ëª¨ë¸ ë‹¤ìš´ë¡œë“œ)
- ë˜ëŠ” ë¯¸ë¦¬ ë‹¤ìš´ë¡œë“œí•œ ëª¨ë¸ íŒŒì¼ transfer

### ë¬¸ì œ 4: ë””ìŠ¤í¬ ë¶€ì¡±
**í™•ì¸:**
```bash
df -h /
du -sh ~/.cache/pip/  # pip ìºì‹œ
du -sh ~/.cache/huggingface/  # HF ìºì‹œ
```

**í•´ê²°:**
```bash
# pip ìºì‹œ ì •ë¦¬
rm -rf ~/.cache/pip/*

# í•„ìš”ì‹œ ëª¨ë¸ë§Œ ë‹¤ìš´ë¡œë“œ (ì „ì²´ ì„¤ì¹˜ ìŠ¤í‚µ)
python3 download_model.py
```

---

## ğŸ“Š ì„¤ì¹˜ ì˜ˆìƒ ì‹œê°„ ë¶„ì„

| ë‹¨ê³„ | ì‹œê°„ | ë¹„ê³  |
|------|------|------|
| tar ì¶”ì¶œ | 1-2ë¶„ | ë””ìŠ¤í¬ ì†ë„ ì˜ì¡´ |
| pip ì—…ê·¸ë ˆì´ë“œ | 1-2ë¶„ | ë¹ ë¦„ |
| 44ê°œ wheels ì„¤ì¹˜ | 2-3ë¶„ | ì˜¤í”„ë¼ì¸ |
| PyTorch ë‹¤ìš´ë¡œë“œ | 5-10ë¶„ | ë„¤íŠ¸ì›Œí¬ ì˜ì¡´ |
| PyTorch ì„¤ì¹˜ | 3-5ë¶„ | ë””ìŠ¤í¬ ì†ë„ ì˜ì¡´ |
| ëª¨ë¸ ë‹¤ìš´ë¡œë“œ | 15-30ë¶„ | ë„¤íŠ¸ì›Œí¬ ì˜ì¡´ |
| **ì´í•©** | **30-60ë¶„** | |

---

## ğŸ¯ ì²´í¬ë¦¬ìŠ¤íŠ¸

ë°°í¬ ì „:
- [ ] macOSì—ì„œ `stt_engine_deployment_final.tar.gz` ìƒì„± í™•ì¸
- [ ] íŒŒì¼ í¬ê¸° í™•ì¸ (~2.8GB)
- [ ] tar êµ¬ì¡° ê²€ì¦: `tar -tzf file.tar.gz | head -20`

ì„œë²„ì—ì„œ:
- [ ] tar íŒŒì¼ ì „ì†¡ ì™„ë£Œ
- [ ] ì¶”ì¶œ ì™„ë£Œ
- [ ] `LINUX_PYTORCH_INSTALL.sh` ì¡´ì¬ í™•ì¸
- [ ] `deployment_package/wheels/` ë””ë ‰í† ë¦¬ í™•ì¸

ì„¤ì¹˜ í›„:
- [ ] Python import torch ì„±ê³µ
- [ ] nvidia-smi ì‹¤í–‰ ì„±ê³µ
- [ ] ëª¨ë¸ ë‹¤ìš´ë¡œë“œ ì™„ë£Œ
- [ ] API ì„œë²„ ì‹¤í–‰ ì„±ê³µ
- [ ] í—¬ìŠ¤ ì²´í¬ 200 ì‘ë‹µ

---

## ğŸ’¡ ì¶”ê°€ íŒ

### 1. ë°±ê·¸ë¼ìš´ë“œ ì„¤ì¹˜ (SSH ì—°ê²° ëŠê²¨ë„ ê³„ì†)
```bash
nohup bash LINUX_PYTORCH_INSTALL.sh > install.log 2>&1 &

# ì§„í–‰ ìƒí™© í™•ì¸
tail -f install.log
```

### 2. ì„¤ì¹˜ ë¡œê·¸ ì €ì¥
```bash
bash LINUX_PYTORCH_INSTALL.sh 2>&1 | tee install_$(date +%Y%m%d_%H%M%S).log
```

### 3. ì—¬ëŸ¬ ë²„ì „ ë™ì‹œ í…ŒìŠ¤íŠ¸
```bash
# PyTorch ë²„ì „ í™•ì¸
pip show torch | grep Version

# ë‹¤ë¥¸ CUDA ë²„ì „ìœ¼ë¡œ ì¬ì„¤ì¹˜
pip install torch==2.2.0 --index-url https://download.pytorch.org/whl/cu121
```

### 4. ëª¨ë¸ ìºì‹œ ìœ„ì¹˜ ë³€ê²½
```bash
# HuggingFace ìºì‹œ ìœ„ì¹˜ ë³€ê²½ (í° ë””ìŠ¤í¬ë¡œ)
export HF_HOME=/large/disk/path
python3 download_model.py
```

---

## ğŸ“ ë¬¸ì œ ë°œìƒ ì‹œ ìˆ˜ì§‘ ì •ë³´

ì„¤ì¹˜ ì‹¤íŒ¨ ì‹œ ì´ ì •ë³´ë“¤ì„ ìˆ˜ì§‘í•´ì£¼ì„¸ìš”:

```bash
# ì‹œìŠ¤í…œ ì •ë³´
uname -a
python3 --version
nvidia-smi
nvcc --version

# PyTorch ì„¤ì¹˜ ìƒíƒœ
pip show torch
python3 -c "import torch; print(torch.version.cuda, torch.cuda.is_available())"

# ì—ëŸ¬ ë¡œê·¸
cat install.log | tail -50
```

---

## âœ… ìµœì¢… í™•ì¸

ë°°í¬ ì™„ë£Œ ê¸°ì¤€:

```bash
# 1. íŒ¨í‚¤ì§€ í™•ì¸
python3 -c "import torch, torchaudio, transformers, librosa; print('âœ… All packages OK')"

# 2. GPU í™•ì¸
python3 -c "import torch; print(f'GPU: {torch.cuda.get_device_name(0)}' if torch.cuda.is_available() else 'CPU mode')"

# 3. ëª¨ë¸ í™•ì¸
ls -lah ~/.cache/huggingface/hub/ | grep whisper

# 4. API í™•ì¸
curl -s http://localhost:8001/health | python3 -m json.tool
```

ëª¨ë‘ ì„±ê³µí•˜ë©´ **ë°°í¬ ì™„ë£Œ! ğŸ‰**

---

**Last Updated:** 2026-02-02
**Deployment Method:** Offline (44 wheels) + Online PyTorch
**Target Server:** RHEL 8.9, Python 3.11.5, CUDA 12.9
