# EC2 STT ì—”ì§„ ëª¨ë¸ ë¬¸ì œ ì§„ë‹¨ ë° í•´ê²°

## ğŸš¨ í˜„ì¬ ë¬¸ì œ

Docker ì»¨í…Œì´ë„ˆì—ì„œ ëª¨ë¸ì„ ë¡œë“œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤:
```
âŒ RuntimeError: Unable to open file 'model.bin' in model '/app/models/openai_whisper-large-v3-turbo'
```

**ì›ì¸**: CTranslate2 ëª¨ë¸ ë³€í™˜ì´ ì˜¬ë°”ë¥´ê²Œ ì™„ë£Œë˜ì§€ ì•Šì•˜ê±°ë‚˜, íŒŒì¼ì´ ì†ìƒë¨

---

## âœ… í•´ê²° ë°©ë²• (3ë‹¨ê³„)

### Step 1ï¸âƒ£: EC2ì—ì„œ ëª¨ë¸ ìƒíƒœ ì§„ë‹¨

```bash
# EC2ì— ì ‘ì†
ssh -i your-key.pem ec2-user@your-ec2-ip

# ëª¨ë¸ ë””ë ‰í† ë¦¬ ì´ë™
cd /home/ec2-user/stt_engine

# ì§„ë‹¨ ìŠ¤í¬ë¦½íŠ¸ ì‹¤í–‰
python ec2_diagnose_and_fix.py
```

**ì¶œë ¥ ì˜ˆì‹œ:**
```
=======================================================================
ğŸ” EC2 STT ì—”ì§„ ëª¨ë¸ ì§„ë‹¨ (RHEL 8.9)
=======================================================================

ğŸ“Œ Step 1: ë””ë ‰í† ë¦¬ ê²½ë¡œ í™•ì¸
--------

  âœ… STT ë””ë ‰í† ë¦¬ ì¡´ì¬
  âœ… ëª¨ë¸ ë””ë ‰í† ë¦¬ ì¡´ì¬
  âœ… ëª¨ë¸ í´ë” ì¡´ì¬

ğŸ“Œ Step 2: ëª¨ë¸ íŒŒì¼ êµ¬ì¡° ì§„ë‹¨
--------

  âœ… ctranslate2_model í´ë” ì¡´ì¬
  âŒ model.bin ë„ˆë¬´ ì‘ìŒ: 45.25MB (ìµœì†Œ 1000MB í•„ìš”)
  âŒ model.bin íŒŒì¼ì´ ì†ìƒë˜ì—ˆì„ ê°€ëŠ¥ì„± ë†’ìŒ
```

---

### Step 2ï¸âƒ£: ëª¨ë¸ íŒŒì¼ ë¹ ë¥¸ í™•ì¸

ì§„ë‹¨ ìŠ¤í¬ë¦½íŠ¸ ì—†ì´ ë¹ ë¥´ê²Œ í™•ì¸:

```bash
# ëª¨ë¸ ë””ë ‰í† ë¦¬ í™•ì¸
ls -lh /home/ec2-user/stt_engine/models/openai_whisper-large-v3-turbo/

# CTranslate2 ëª¨ë¸ íŒŒì¼ í™•ì¸
ls -lh /home/ec2-user/stt_engine/models/openai_whisper-large-v3-turbo/ctranslate2_model/

# config.json í¬ê¸° í™•ì¸ (2.2KB ë¯¸ë§Œì´ë©´ ì†ìƒ)
stat /home/ec2-user/stt_engine/models/openai_whisper-large-v3-turbo/ctranslate2_model/config.json

# model.bin í¬ê¸° í™•ì¸ (1.5GB ì´ìƒ í•„ìš”)
du -h /home/ec2-user/stt_engine/models/openai_whisper-large-v3-turbo/ctranslate2_model/model.bin
```

**ì •ìƒ ìƒíƒœ:**
```
-rw-r--r-- model.bin         (1.5GB ì´ìƒ)
-rw-r--r-- config.json       (5KB ì´ìƒ)
-rw-r--r-- vocabulary.json   (1MB ì´ìƒ)
```

---

### Step 3ï¸âƒ£: ëª¨ë¸ ì¬êµ¬ì¶• (ìë™ ë˜ëŠ” ìˆ˜ë™)

#### ì˜µì…˜ A: ìë™ ìˆ˜ì • (ê¶Œì¥)

```bash
# ì§„ë‹¨ + ìë™ ìˆ˜ì •
python ec2_diagnose_and_fix.py --fix

# ë˜ëŠ” ê°•ì œ ì¬êµ¬ì¶•
python ec2_diagnose_and_fix.py --rebuild
```

ì´ ëª…ë ¹ì€:
1. ê¸°ì¡´ ëª¨ë¸ ë°±ì—…
2. ìƒˆ ëª¨ë¸ ë‹¤ìš´ë¡œë“œ ë° ë³€í™˜
3. ì¬ì§„ë‹¨ìœ¼ë¡œ ì„±ê³µ í™•ì¸

---

#### ì˜µì…˜ B: ìˆ˜ë™ ì¬êµ¬ì¶•

```bash
# 1. ê¸°ì¡´ ëª¨ë¸ ì‚­ì œ
rm -rf /home/ec2-user/stt_engine/models/openai_whisper-large-v3-turbo

# 2. ëª¨ë¸ ì¬ë‹¤ìš´ë¡œë“œ ë° ë³€í™˜ (10-20ë¶„ ì†Œìš”)
cd /home/ec2-user/stt_engine
python download_model_hf.py

# 3. ì™„ë£Œ í™•ì¸
ls -lh models/openai_whisper-large-v3-turbo/ctranslate2_model/

# 4. ëª¨ë¸ ë¡œë“œ í…ŒìŠ¤íŠ¸
python -c "from faster_whisper import WhisperModel; m = WhisperModel('/home/ec2-user/stt_engine/models/openai_whisper-large-v3-turbo/ctranslate2_model', device='cpu'); print('âœ… ëª¨ë¸ ë¡œë“œ ì„±ê³µ')"
```

---

## ğŸ“Š ìƒì„¸ íŒŒì¼ êµ¬ì¡°

**ì •ìƒì ì¸ ëª¨ë¸ êµ¬ì¡°:**
```
models/openai_whisper-large-v3-turbo/
â”œâ”€â”€ config.json
â”œâ”€â”€ generation_config.json
â”œâ”€â”€ model.safetensors (3GB+)
â”œâ”€â”€ preprocessor_config.json
â”œâ”€â”€ tokenizer.json
â””â”€â”€ ctranslate2_model/              â­ ì¤‘ìš”
    â”œâ”€â”€ model.bin (1.5GB+)          â† ì´ íŒŒì¼ì´ ê°€ì¥ ì¤‘ìš”
    â”œâ”€â”€ config.json (5KB+)
    â””â”€â”€ vocabulary.json (1MB+)
```

**ë¬¸ì œ ìƒí™© 1**: model.bin ì†ìƒ ë˜ëŠ” ë„ˆë¬´ ì‘ìŒ
```
âŒ model.bin: 45.25MB  (âŒ ë„ˆë¬´ ì‘ìŒ, ìµœì†Œ 1.5GB í•„ìš”)
```
â†’ **í•´ê²°**: ëª¨ë¸ ì¬ë‹¤ìš´ë¡œë“œ í•„ìˆ˜

**ë¬¸ì œ ìƒí™© 2**: ctranslate2_model í´ë” ì—†ìŒ
```
âŒ ctranslate2_model/ í´ë” ì—†ìŒ
```
â†’ **í•´ê²°**: ëª¨ë¸ ë³€í™˜ ìŠ¤í¬ë¦½íŠ¸ ì¬ì‹¤í–‰

---

## ğŸ§ª ëª¨ë¸ ë¡œë“œ í…ŒìŠ¤íŠ¸ (ìˆ˜ë™)

```bash
cd /home/ec2-user/stt_engine

# Python ëŒ€í™”í˜• ëª¨ë“œì—ì„œ í…ŒìŠ¤íŠ¸
python3 << 'EOF'
from pathlib import Path
from faster_whisper import WhisperModel

model_path = Path("/home/ec2-user/stt_engine/models/openai_whisper-large-v3-turbo/ctranslate2_model")

print(f"ğŸ“‚ ëª¨ë¸ ê²½ë¡œ: {model_path}")
print(f"âœ… ê²½ë¡œ ì¡´ì¬: {model_path.exists()}")

# íŒŒì¼ í™•ì¸
print("\nğŸ“‹ íŒŒì¼ í™•ì¸:")
for f in sorted(model_path.glob("*")):
    if f.is_file():
        size = f.stat().st_size / (1024**2)
        print(f"  - {f.name}: {size:.2f}MB")

# ëª¨ë¸ ë¡œë“œ
print("\nğŸ”„ ëª¨ë¸ ë¡œë“œ ì¤‘...")
try:
    model = WhisperModel(str(model_path), device="cpu", compute_type="int8")
    print("âœ… ëª¨ë¸ ë¡œë“œ ì„±ê³µ!")
except Exception as e:
    print(f"âŒ ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {e}")
EOF
```

---

## ğŸ³ Docker ì—ì„œ ë‹¤ì‹œ í…ŒìŠ¤íŠ¸

ëª¨ë¸ì„ ì¬êµ¬ì¶•í•œ í›„:

```bash
# Docker ì´ë¯¸ì§€ ì¬ë¹Œë“œ (ê¶Œì¥)
cd /home/ec2-user/stt_engine
docker build --platform linux/amd64 -t stt-engine:cuda129-rhel89-v1.5 -f docker/Dockerfile.engine.rhel89 .

# ë˜ëŠ” ê¸°ì¡´ ì´ë¯¸ì§€ë¡œ í…ŒìŠ¤íŠ¸ (ëª¨ë¸ë§Œ ë§ˆìš´íŠ¸)
docker run -it \
  --name stt-api-test \
  -p 8003:8003 \
  -v /home/ec2-user/stt_engine/models:/app/models \
  -e CUDA_VISIBLE_DEVICES=0 \
  stt-engine:cuda129-rhel89-v1.5

# ë˜ëŠ” python api_server.py ì§ì ‘ ì‹¤í–‰
docker run -it \
  --name stt-api-test \
  -p 8003:8003 \
  -v /home/ec2-user/stt_engine/models:/app/models \
  stt-engine:cuda129-rhel89-v1.5 \
  python3.11 api_server.py
```

---

## ğŸ” ì¶”ê°€ ë¬¸ì œ í•´ê²°

### ë¬¸ì œ: download_model_hf.py ì‹¤í–‰ ì‹¤íŒ¨

```bash
# íŒ¨í‚¤ì§€ ë²„ì „ í™•ì¸
python -c "import ctranslate2, faster_whisper, transformers; print(f'ctranslate2: {ctranslate2.__version__}, faster-whisper ì„¤ì¹˜ë¨, transformers: {transformers.__version__}')"

# ë¬¸ì œ íŒ¨í‚¤ì§€ ì¬ì„¤ì¹˜
pip install --upgrade ctranslate2==4.7.1
pip install --upgrade faster-whisper==1.2.1
```

### ë¬¸ì œ: ë””ìŠ¤í¬ ê³µê°„ ë¶€ì¡±

```bash
# ë””ìŠ¤í¬ ì‚¬ìš©ëŸ‰ í™•ì¸
df -h /home/ec2-user

# ë¶ˆí•„ìš”í•œ íŒŒì¼ ì •ë¦¬
rm -rf ~/.cache/huggingface/hub/*
docker system prune -a
```

### ë¬¸ì œ: ë©”ëª¨ë¦¬ ë¶€ì¡± (16GB ì´ìƒ ê¶Œì¥)

```bash
# ë©”ëª¨ë¦¬ í™•ì¸
free -h

# swap ìƒì„± (í•„ìš”ì‹œ)
sudo fallocate -l 8G /swapfile
sudo chmod 600 /swapfile
sudo mkswap /swapfile
sudo swapon /swapfile
```

---

## ğŸ’¡ ì˜ˆìƒ ì†Œìš” ì‹œê°„

| ë‹¨ê³„ | ì‹œê°„ | ì„¤ëª… |
|------|------|------|
| ëª¨ë¸ ë‹¤ìš´ë¡œë“œ | 5-10ë¶„ | Hugging Faceì—ì„œ 1.5GB ë‹¤ìš´ë¡œë“œ |
| CTranslate2 ë³€í™˜ | 5-15ë¶„ | PyTorch â†’ CTranslate2 í¬ë§· ë³€í™˜ |
| ì••ì¶• | 2-5ë¶„ | tar.gz ì••ì¶• (ì„ íƒì‚¬í•­) |
| **ì´ì†Œìš”ì‹œê°„** | **15-30ë¶„** | ë„¤íŠ¸ì›Œí¬ ì†ë„ì— ë”°ë¼ ë³€í•¨ |

---

## âœ… ì„±ê³µ í™•ì¸

ëª¨ë“  ë‹¨ê³„ ì™„ë£Œ í›„:

```bash
# 1. ëª¨ë¸ íŒŒì¼ í™•ì¸
ls -lh models/openai_whisper-large-v3-turbo/ctranslate2_model/

# 2. Docker ì»¨í…Œì´ë„ˆ ì‹œì‘
docker run -it -p 8003:8003 -v $(pwd)/models:/app/models stt-engine:cuda129-rhel89-v1.5

# 3. API ê±´ê°• í™•ì¸ (ë‹¤ë¥¸ í„°ë¯¸ë„)
curl http://localhost:8003/health

# 4. ê¸°ëŒ€ë˜ëŠ” ì‘ë‹µ:
# {"status":"ok","version":"1.0.0","backend":"faster-whisper"}
```

---

## ğŸ”„ ìµœì‹  ê°œì„ ì‚¬í•­ (2025ë…„ 2ì›”)

### ìƒëŒ€ ê²½ë¡œ ì‹¬ë§í¬ ì ìš©

**ë¬¸ì œ**: ì´ì „ì—ëŠ” model.bin ì‹¬ë§í¬ê°€ ì ˆëŒ€ ê²½ë¡œë¡œ ìƒì„±ë˜ì–´ì„œ, Docker (`/app/models`)ì™€ ìš´ì˜ ì„œë²„ (`/data/models`)ì—ì„œ ê²½ë¡œê°€ ë‹¤ë¥´ë©´ ì‘ë™í•˜ì§€ ì•ŠìŒ

**í•´ê²°**: ìƒëŒ€ ê²½ë¡œ ì‹¬ë§í¬ë¡œ ë³€ê²½
```
# ì´ì „ (ì ˆëŒ€ ê²½ë¡œ)
model.bin â†’ /home/ec2-user/stt_engine/models/openai_whisper-large-v3-turbo/ctranslate2_model/model-0001.bin
âŒ Dockerì—ì„œ ì‘ë™ ì•ˆí•¨

# í˜„ì¬ (ìƒëŒ€ ê²½ë¡œ) âœ…
model.bin â†’ ./ctranslate2_model/model-0001.bin
âœ… Docker (/app/models) & ìš´ì˜ ì„œë²„ (/data/models) ëª¨ë‘ ì‘ë™
```

### ìë™ ì§„ë‹¨ ë° ë³µêµ¬ ë„êµ¬

ëª¨ë¸ ë¬¸ì œ ì‹œ ìë™ìœ¼ë¡œ ì§„ë‹¨í•˜ê³  ìˆ˜ì •í•˜ëŠ” ìŠ¤í¬ë¦½íŠ¸ ì¶”ê°€:

```bash
# EC2ì—ì„œ ëª¨ë¸ ì§„ë‹¨
python diagnose_model.py

# ë˜ëŠ” íŠ¹ì • ê²½ë¡œ ì§„ë‹¨
python diagnose_model.py /data/models/openai_whisper-large-v3-turbo
```

**ê¸°ëŠ¥:**
1. ëª¨ë¸ ë””ë ‰í† ë¦¬ êµ¬ì¡° ìƒì„¸ ì§„ë‹¨
2. model.bin íŒŒì¼ ìœ„ì¹˜ ìë™ íŒŒì•…
3. ìƒëŒ€ ê²½ë¡œ ì‹¬ë§í¬ ìë™ ìƒì„± (ë˜ëŠ” íŒŒì¼ ë³µì‚¬)
4. faster-whisper ë¡œë“œ í…ŒìŠ¤íŠ¸

**ì¶œë ¥ ì˜ˆì‹œ:**
```
======================================================================
ğŸ” ëª¨ë¸ ë””ë ‰í† ë¦¬ ì§„ë‹¨
======================================================================

ğŸ“ ëª¨ë¸ ë””ë ‰í† ë¦¬: /data/models/openai_whisper-large-v3-turbo

ğŸ“‚ ìµœìƒìœ„ íŒŒì¼:
   ğŸ”— model.bin (1.50GB)
      â†’ ctranslate2_model/model-0001.bin
   ğŸ“ ctranslate2_model/ (3 items)

ğŸ” model.bin íŒŒì¼ ê²€ìƒ‰:
   âœ… 1ê°œ ë°œê²¬:
      - ctranslate2_model/model-0001.bin (1.50GB)

======================================================================
âœ… faster-whisper ëª¨ë¸ ë¡œë“œ í…ŒìŠ¤íŠ¸
======================================================================

âœ… ëª¨ë¸ ë¡œë“œ ì„±ê³µ!

ğŸ“‹ ëª¨ë¸ ì •ë³´:
   íƒ€ì…: Whisper Large-v3-Turbo (CTranslate2)
   ë””ë°”ì´ìŠ¤: CPU
   Compute Type: FP32
```

### ëª¨ë¸ ì¤€ë¹„ ìŠ¤í¬ë¦½íŠ¸ (EC2ìš©)

EC2ì—ì„œ ëª¨ë¸ì„ ì²˜ìŒë¶€í„° ì¤€ë¹„í•˜ëŠ” ì‰˜ ìŠ¤í¬ë¦½íŠ¸:

```bash
# ìŠ¤í¬ë¦½íŠ¸ ì‹¤í–‰
bash ec2_prepare_model.sh

# ë˜ëŠ” ì˜µì…˜ê³¼ í•¨ê»˜
bash ec2_prepare_model.sh --skip-test        # í…ŒìŠ¤íŠ¸ ìŠ¤í‚µ
bash ec2_prepare_model.sh --skip-compress    # ì••ì¶• ìŠ¤í‚µ
bash ec2_prepare_model.sh --no-convert       # ë³€í™˜ ìŠ¤í‚µ (PyTorchë§Œ)
```

**í¬í•¨ ê¸°ëŠ¥:**
- Python 3.11 í™˜ê²½ í™•ì¸
- í•„ìˆ˜ íŒ¨í‚¤ì§€ ê²€ì¦ (huggingface-hub, faster-whisper, ctranslate2)
- ëª¨ë¸ ë‹¤ìš´ë¡œë“œ & CTranslate2 ë³€í™˜
- ìë™ ì§„í–‰ ìƒí™© ë³´ê³ 

### ì‹¬ë§í¬ í˜¸í™˜ì„± í™•ì¸

Dockerì™€ ìš´ì˜ ì„œë²„ ëª¨ë‘ì—ì„œ ì‘ë™í•˜ëŠ”ì§€ ê²€ì¦:

```bash
# ì‹¬ë§í¬ í™•ì¸
ls -l models/openai_whisper-large-v3-turbo/model.bin

# ì •ìƒ ì¶œë ¥ (ìƒëŒ€ ê²½ë¡œ)
lrwxr-xr-x  user  group  ctranslate2_model/model-0001.bin â†’ model.bin
```

**í˜¸í™˜ ê²½ë¡œ:**

| í™˜ê²½ | ê²½ë¡œ | ì‘ë™ |
|------|------|------|
| Docker | `/app/models/openai_whisper-large-v3-turbo` | âœ… |
| EC2 (/data) | `/data/models/openai_whisper-large-v3-turbo` | âœ… |
| EC2 (/home) | `/home/ec2-user/stt_engine/models/...` | âœ… |

ëª¨ë“  ê²½ë¡œì—ì„œ ìƒëŒ€ ê²½ë¡œë¥¼ ì‚¬ìš©í•˜ë¯€ë¡œ ë¬¸ì œì—†ì´ ì‘ë™í•©ë‹ˆë‹¤! âœ¨

**ì§ˆë¬¸ì´ë‚˜ ì¶”ê°€ ë„ì›€ì´ í•„ìš”í•˜ë©´ ì•Œë ¤ì£¼ì„¸ìš”!**
