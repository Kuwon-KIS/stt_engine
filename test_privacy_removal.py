#!/usr/bin/env python3
"""
Privacy Removal Feature Integration Test Script
ê°œì¸ì •ë³´ ì œê±° ê¸°ëŠ¥ í…ŒìŠ¤íŠ¸
"""

import asyncio
import json
import sys
from pathlib import Path

# Add project root to path
sys.path.insert(0, str(Path(__file__).parent))

from api_server.services.privacy_removal import PrivacyRemovalService


async def test_privacy_removal():
    """Privacy Removal ê¸°ëŠ¥ í…ŒìŠ¤íŠ¸"""
    
    print("=" * 70)
    print("Privacy Removal Feature Test")
    print("=" * 70)
    
    # ì„œë¹„ìŠ¤ ì´ˆê¸°í™”
    print("\n1ï¸âƒ£ PrivacyRemovalService ì´ˆê¸°í™”...")
    try:
        service = PrivacyRemovalService(
            vllm_base_url="http://localhost:8000",
            vllm_model="meta-llama/Llama-2-7b-hf"
        )
        print("âœ… ì„œë¹„ìŠ¤ ì´ˆê¸°í™” ì™„ë£Œ")
    except Exception as e:
        print(f"âŒ ì„œë¹„ìŠ¤ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
        return
    
    # ì‚¬ìš© ê°€ëŠ¥í•œ í”„ë¡¬í”„íŠ¸ í™•ì¸
    print("\n2ï¸âƒ£ ì‚¬ìš© ê°€ëŠ¥í•œ í”„ë¡¬í”„íŠ¸ íƒ€ì… ì¡°íšŒ...")
    try:
        available_prompts = service.get_available_prompts()
        print(f"âœ… ì‚¬ìš© ê°€ëŠ¥í•œ í”„ë¡¬í”„íŠ¸: {available_prompts}")
        
        if not available_prompts:
            print("âš ï¸ í”„ë¡¬í”„íŠ¸ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤")
            return
    except Exception as e:
        print(f"âŒ í”„ë¡¬í”„íŠ¸ ì¡°íšŒ ì‹¤íŒ¨: {e}")
        return
    
    # í…ŒìŠ¤íŠ¸ í…ìŠ¤íŠ¸ ì¤€ë¹„
    test_texts = [
        "ë‚˜ëŠ” John Smithì´ê³  010-1234-5678ì—ì„œ ì „í™”í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤",
        "ì œ ì´ë¦„ì€ ê¹€ì² ìˆ˜ì´ê³ , ì´ë©”ì¼ì€ kim.chulsu@example.comì…ë‹ˆë‹¤. ì£¼ì†ŒëŠ” ì„œìš¸ì‹œ ê°•ë‚¨êµ¬ì…ë‹ˆë‹¤",
        "ì¼ë°˜ì ì¸ STT ê²°ê³¼ í…ìŠ¤íŠ¸ì…ë‹ˆë‹¤. íŠ¹ë³„í•œ ê°œì¸ì •ë³´ê°€ ì—†ìŠµë‹ˆë‹¤"
    ]
    
    # ê° í…ìŠ¤íŠ¸ì— ëŒ€í•´ privacy removal ì‹¤í–‰
    print("\n3ï¸âƒ£ Privacy Removal ì²˜ë¦¬...")
    for i, text in enumerate(test_texts, 1):
        print(f"\ní…ŒìŠ¤íŠ¸ {i}: {text[:50]}...")
        
        try:
            result = await service.remove_privacy_from_stt(
                stt_text=text,
                prompt_type="privacy_remover_default_v6",
                max_tokens=8192,
                temperature=0.3
            )
            
            print(f"âœ… ì²˜ë¦¬ ì„±ê³µ")
            print(f"   - Privacy Exist: {result['privacy_exist']}")
            print(f"   - Reason: {result['exist_reason'][:50]}")
            print(f"   - Processed Text: {result['privacy_rm_text'][:50]}...")
            print(f"   - Success: {result['success']}")
            
        except Exception as e:
            print(f"âŒ ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
    
    print("\n" + "=" * 70)
    print("í…ŒìŠ¤íŠ¸ ì™„ë£Œ")
    print("=" * 70)


async def test_direct_processor():
    """LLMProcessor ì§ì ‘ í…ŒìŠ¤íŠ¸ (vLLM ì—†ì´)"""
    
    from api_server.services.privacy_removal.privacy_remover import LLMProcessorForPrivacy
    from api_server.services.privacy_removal.vllm_client import VLLMClient
    
    print("\n" + "=" * 70)
    print("Direct LLMProcessor Test")
    print("=" * 70)
    
    # vLLM í´ë¼ì´ì–¸íŠ¸ ìƒì„±
    print("\n1ï¸âƒ£ vLLM í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”...")
    vllm_client = VLLMClient(
        base_url="http://localhost:8000",
        model_name="meta-llama/Llama-2-7b-hf"
    )
    print("âœ… vLLM í´ë¼ì´ì–¸íŠ¸ ì¤€ë¹„ë¨")
    
    # LLMProcessor ìƒì„±
    print("\n2ï¸âƒ£ LLMProcessor ì´ˆê¸°í™”...")
    processor = LLMProcessorForPrivacy(vllm_client=vllm_client)
    print("âœ… LLMProcessor ì´ˆê¸°í™” ì™„ë£Œ")
    
    # í”„ë¡¬í”„íŠ¸ í™•ì¸
    print("\n3ï¸âƒ£ í”„ë¡¬í”„íŠ¸ íŒŒì¼ ë¡œë“œ...")
    try:
        template = processor._load_prompt_template("privacy_remover_default_v6")
        print(f"âœ… í”„ë¡¬í”„íŠ¸ ë¡œë“œ ì™„ë£Œ (í¬ê¸°: {len(template)} bytes)")
        print(f"   ì²« 100ê¸€ì: {template[:100]}...")
    except FileNotFoundError as e:
        print(f"âŒ í”„ë¡¬í”„íŠ¸ íŒŒì¼ ì—†ìŒ: {e}")
        return
    
    print("\ní…ŒìŠ¤íŠ¸ ì™„ë£Œ")


if __name__ == "__main__":
    import sys
    import os
    
    print("\nğŸš€ Privacy Removal Integration Test Suite\n")
    
    # vLLM ì—°ê²° í™•ì¸
    print("ğŸ“¡ vLLM ì—°ê²° í™•ì¸...")
    import subprocess
    try:
        # vLLM ì„œë²„ í™•ì¸ (curlìœ¼ë¡œ í—¬ìŠ¤ ì²´í¬)
        result = subprocess.run(
            ["curl", "-s", "-o", "/dev/null", "-w", "%{http_code}", "http://localhost:8000/health"],
            timeout=5,
            capture_output=True
        )
        
        if result.returncode == 0 and result.stdout.decode().strip() in ["200", "404"]:
            print("âœ… vLLM ì„œë²„ ì—°ê²°ë¨ (http://localhost:8000)")
        else:
            print("âš ï¸ vLLM ì„œë²„ ë¯¸ì‘ë‹µ (í…ŒìŠ¤íŠ¸ëŠ” ê³„ì† ì§„í–‰í•˜ë˜, ì‹¤ì œ ê°œì¸ì •ë³´ ì œê±°ëŠ” ë™ì‘í•˜ì§€ ì•ŠìŒ)")
    except Exception as e:
        print(f"âš ï¸ vLLM ì—°ê²° í™•ì¸ ì‹¤íŒ¨: {e}")
        print("   â†’ vLLM ì„œë²„ë¥¼ ì‹œì‘í•˜ì„¸ìš”: docker run --gpus all -p 8000:8000 vllm/vllm-openai")
    
    # í…ŒìŠ¤íŠ¸ ì„ íƒ
    print("\ní…ŒìŠ¤íŠ¸ ì˜µì…˜:")
    print("1. Privacy Removal Service í…ŒìŠ¤íŠ¸ (vLLM í•„ìš”)")
    print("2. LLMProcessor ì§ì ‘ í…ŒìŠ¤íŠ¸")
    print("3. í”„ë¡¬í”„íŠ¸ íŒŒì¼ë§Œ í™•ì¸")
    
    choice = input("\nì„ íƒ (ê¸°ë³¸ê°’ 3): ").strip() or "3"
    
    if choice == "1":
        print("\nâ†’ Privacy Removal Service í…ŒìŠ¤íŠ¸ ì‹œì‘...")
        print("âš ï¸ vLLM ì„œë²„ê°€ ì‹¤í–‰ ì¤‘ì´ì–´ì•¼ í•©ë‹ˆë‹¤!")
        asyncio.run(test_privacy_removal())
    elif choice == "2":
        print("\nâ†’ LLMProcessor ì§ì ‘ í…ŒìŠ¤íŠ¸ ì‹œì‘...")
        asyncio.run(test_direct_processor())
    elif choice == "3":
        print("\nâ†’ í”„ë¡¬í”„íŠ¸ íŒŒì¼ í™•ì¸...")
        prompts_dir = Path(__file__).parent / "api_server" / "services" / "privacy_removal" / "prompts"
        print(f"í”„ë¡¬í”„íŠ¸ ë””ë ‰í† ë¦¬: {prompts_dir}")
        
        if prompts_dir.exists():
            prompt_files = list(prompts_dir.glob("*.prompt"))
            if prompt_files:
                print(f"âœ… ì°¾ì€ í”„ë¡¬í”„íŠ¸ íŒŒì¼:")
                for f in prompt_files:
                    size = f.stat().st_size
                    print(f"   - {f.name} ({size:,} bytes)")
            else:
                print("âŒ í”„ë¡¬í”„íŠ¸ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤")
        else:
            print(f"âŒ ë””ë ‰í† ë¦¬ê°€ ì—†ìŠµë‹ˆë‹¤: {prompts_dir}")
    else:
        print("âŒ ì˜ëª»ëœ ì„ íƒ")
