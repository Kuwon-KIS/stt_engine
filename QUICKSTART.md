# ğŸš€ STT Engine - ë¹ ë¥¸ ì‹œì‘ ê°€ì´ë“œ

## ğŸ¯ í”„ë¡œì íŠ¸ ê°œìš”

**STT Engine**ì€ OpenAIì˜ Whisper ëª¨ë¸ì„ ì‚¬ìš©í•˜ì—¬ ìŒì„±ì„ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜í•˜ê³ , vLLMì„ í†µí•´ ì¶”ê°€ ì²˜ë¦¬ë¥¼ ìˆ˜í–‰í•˜ëŠ” ì™„ì „í•œ STT ì†”ë£¨ì…˜ì…ë‹ˆë‹¤.

### ì£¼ìš” íŠ¹ì§•
- âœ… Whisper Large v3 Turbo ëª¨ë¸ ê¸°ë°˜ ê³ ì •ë°€ STT
- âœ… ë‹¤êµ­ì–´ ì§€ì› (í•œêµ­ì–´, ì˜ì–´ ë“±)
- âœ… vLLM í†µí•©ìœ¼ë¡œ ìë™ ìš”ì•½/ë¶„ì„ ê°€ëŠ¥
- âœ… Docker/Docker Compose ì§€ì›
- âœ… GPU ìµœì í™” (CUDA 11.0+)
- âœ… FastAPI REST API ì œê³µ
- âœ… Linux ì„œë²„ ë°°í¬ ì™„ë²½ ê°€ì´ë“œ

---

## ğŸ“¦ ì„¤ì¹˜ ë° ì‹¤í–‰

### Option 1ï¸âƒ£ : ë¡œì»¬ ê°œë°œ í™˜ê²½ (macOS/Linux)

#### Step 1: ìë™ ì„¤ì • ìŠ¤í¬ë¦½íŠ¸ ì‹¤í–‰
```bash
chmod +x setup.sh
./setup.sh
```

#### Step 2: Whisper ëª¨ë¸ ë‹¤ìš´ë¡œë“œ
```bash
source venv/bin/activate
python download_model.py
```

> **â±ï¸ ì˜ˆìƒ ì‹œê°„**: 10-20ë¶„ (ì¸í„°ë„· ì†ë„ì— ë”°ë¼ ë³€í•¨)
> **ğŸ’¾ í•„ìš” ìš©ëŸ‰**: ì•½ 3GB

#### Step 3: ìŒì„± íŒŒì¼ ì¤€ë¹„
```bash
# audio/ ë””ë ‰í† ë¦¬ì— WAV, MP3, FLAC ë˜ëŠ” OGG íŒŒì¼ ì¶”ê°€
cp /path/to/your/audio.wav audio/
```

#### Step 4: STT í…ŒìŠ¤íŠ¸
```bash
python stt_engine.py
```

#### Step 5: API ì„œë²„ ì‹¤í–‰ (ë³„ë„ í„°ë¯¸ë„)
```bash
python api_server.py
```

APIê°€ `http://localhost:8001`ì—ì„œ ì‹¤í–‰ë©ë‹ˆë‹¤.

---

### Option 2ï¸âƒ£ : Docker í™˜ê²½ (ê¶Œì¥)

#### Step 1: Docker ì´ë¯¸ì§€ ë¹Œë“œ
```bash
# ê¸°ë³¸ CPU ë²„ì „
docker build -t stt-engine:latest .

# GPU ì§€ì› ë²„ì „ (CUDA í¬í•¨)
docker build -t stt-engine:gpu -f Dockerfile.gpu .
```

#### Step 2: Docker Composeë¡œ ì‹¤í–‰
```bash
# í™˜ê²½ íŒŒì¼ ìƒì„±
cp .env.example .env

# ì„œë¹„ìŠ¤ ì‹œì‘ (STT ì—”ì§„ + vLLM ì„œë²„)
docker-compose up -d

# ìƒíƒœ í™•ì¸
docker-compose ps
docker-compose logs -f
```

#### Step 3: ì„œë²„ ìƒíƒœ í™•ì¸
```bash
curl http://localhost:8001/health
```

---

## ğŸ¤ ì‚¬ìš© ë°©ë²•

### Python API í´ë¼ì´ì–¸íŠ¸ ì‚¬ìš©

#### 1. STTë§Œ ìˆ˜í–‰
```python
from stt_engine import WhisperSTT

stt = WhisperSTT("models/openai_whisper-large-v3-turbo")
result = stt.transcribe("audio/sample.wav", language="ko")
print(result["text"])
```

#### 2. vLLMê³¼ í•¨ê»˜ ì‚¬ìš©
```python
from stt_engine import WhisperSTT
from vllm_client import VLLMClient, VLLMConfig

stt = WhisperSTT("models/openai_whisper-large-v3-turbo")
vllm = VLLMClient(VLLMConfig())

# STT ì²˜ë¦¬
stt_result = stt.transcribe("audio/sample.wav", language="ko")

# vLLMìœ¼ë¡œ ì¶”ê°€ ì²˜ë¦¬
llm_result = vllm.generate(
    f"ë‹¤ìŒ í…ìŠ¤íŠ¸ë¥¼ ìš”ì•½í•´ì£¼ì„¸ìš”:\n{stt_result['text']}"
)
print(llm_result)
```

---

### CLI í´ë¼ì´ì–¸íŠ¸ ì‚¬ìš©

#### 1. í—¬ìŠ¤ ì²´í¬
```bash
python api_client.py --health
```

#### 2. ë‹¨ì¼ íŒŒì¼ ë³€í™˜
```bash
python api_client.py --transcribe audio/sample.wav --language ko
```

#### 3. ë³€í™˜ + vLLM ì²˜ë¦¬
```bash
python api_client.py --process audio/sample.wav \
    --instruction "ë‹¤ìŒ ë‚´ìš©ì„ 3ì¤„ë¡œ ìš”ì•½í•´ì£¼ì„¸ìš”:" \
    --language ko
```

#### 4. ë°°ì¹˜ ì²˜ë¦¬
```bash
python api_client.py --batch audio/ --json
```

---

### REST API ì‚¬ìš©

#### 1. í—¬ìŠ¤ ì²´í¬
```bash
curl http://localhost:8001/health
```

#### 2. STT ë³€í™˜
```bash
curl -X POST \
  -F "file=@audio/sample.wav" \
  -F "language=ko" \
  http://localhost:8001/transcribe | jq
```

#### 3. STT + vLLM ì²˜ë¦¬
```bash
curl -X POST \
  -F "file=@audio/sample.wav" \
  -F "language=ko" \
  -F "instruction=ë‹¤ìŒ í…ìŠ¤íŠ¸ë¥¼ ìš”ì•½í•´ì£¼ì„¸ìš”:" \
  http://localhost:8001/transcribe-and-process | jq
```

---

## ğŸ–¥ï¸ Linux ì„œë²„ ë°°í¬

ìì„¸í•œ ë°°í¬ ê°€ì´ë“œëŠ” [DEPLOYMENT.md](DEPLOYMENT.md)ë¥¼ ì°¸ê³ í•˜ì„¸ìš”.

### ë¹ ë¥¸ ë°°í¬ (Docker Compose)
```bash
# ì €ì¥ì†Œ í´ë¡ 
git clone https://github.com/Kuwon-KIS/stt_engine.git
cd stt_engine

# í™˜ê²½ ì„¤ì •
cp .env.example .env
# nano .env  # í•„ìš”ì‹œ ìˆ˜ì •

# ì„œë¹„ìŠ¤ ì‹œì‘
docker-compose up -d

# ìƒíƒœ í™•ì¸
docker-compose ps
docker-compose logs -f stt-engine
```

### ìë™ ì¬ì‹œì‘ ì„¤ì • (Systemd)
```bash
# DEPLOYMENT.mdì˜ "ìë™ ì¬ì‹œì‘ ì„¤ì •" ì„¹ì…˜ ì°¸ê³ 
```

---

## ğŸ“Š ì„±ëŠ¥ ì§€í‘œ

| í•­ëª© | ê°’ |
|-----|-----|
| ëª¨ë¸ í¬ê¸° | ~3GB |
| ì´ˆê¸° ë¡œë“œ ì‹œê°„ | ~5ì´ˆ |
| 1ì‹œê°„ ìŒì„± ì²˜ë¦¬ ì‹œê°„ | CPU: ~30ë¶„ / GPU: ~2ë¶„ |
| ë©”ëª¨ë¦¬ ì‚¬ìš© (CPU) | ~2-3GB |
| ë©”ëª¨ë¦¬ ì‚¬ìš© (GPU) | ~8GB |

---

## ğŸ”§ ì„¤ì • ë° ì»¤ìŠ¤í„°ë§ˆì´ì§•

### í™˜ê²½ ë³€ìˆ˜ (.env)
```bash
# Whisper ì„¤ì •
WHISPER_MODEL="openai/whisper-large-v3-turbo"
WHISPER_DEVICE="cpu"  # cpu ë˜ëŠ” cuda

# vLLM ì„¤ì •
VLLM_API_URL="http://localhost:8000"
VLLM_MODEL_NAME="meta-llama/Llama-2-7b-hf"

# ì„œë²„ ì„¤ì •
SERVER_HOST="0.0.0.0"
SERVER_PORT=8001
DEBUG=True
```

### ëª¨ë¸ ë³€ê²½
ë‹¤ë¥¸ Whisper ëª¨ë¸ì„ ì‚¬ìš©í•˜ë ¤ë©´:
```bash
# download_model.pyì—ì„œ model_id ë³€ê²½
# - openai/whisper-base
# - openai/whisper-small
# - openai/whisper-medium
# - openai/whisper-large
# - openai/whisper-large-v3-turbo
```

---

## ğŸš¨ ë¬¸ì œ í•´ê²°

### Q: ëª¨ë¸ ë‹¤ìš´ë¡œë“œê°€ ì•ˆ ë¨
**A**: Hugging Face í† í° ì„¤ì •
```bash
export HUGGINGFACE_HUB_TOKEN=your_token_here
python download_model.py
```

### Q: GPUê°€ ì¸ì‹ë˜ì§€ ì•ŠìŒ
**A**: GPU ë“œë¼ì´ë²„ í™•ì¸
```bash
nvidia-smi
docker run --gpus all nvidia/cuda:11.0-runtime nvidia-smi
```

### Q: ë©”ëª¨ë¦¬ ë¶€ì¡±
**A**: Swap ì¶”ê°€ ë˜ëŠ” CPU ëª¨ë“œ ì‚¬ìš©
```bash
# CPU ëª¨ë“œ ì‹¤í–‰
export WHISPER_DEVICE=cpu
python stt_engine.py

# Swap ì¶”ê°€ (Linux)
sudo fallocate -l 8G /swapfile
sudo chmod 600 /swapfile
sudo mkswap /swapfile
sudo swapon /swapfile
```

### Q: vLLM ì—°ê²° ì‹¤íŒ¨
**A**: vLLM ì„œë²„ ìƒíƒœ í™•ì¸
```bash
curl http://localhost:8000/health
docker-compose restart vllm-server
```

---

## ğŸ“š ì£¼ìš” íŒŒì¼ ì„¤ëª…

| íŒŒì¼ | ì„¤ëª… |
|------|------|
| `download_model.py` | Hugging Faceì—ì„œ Whisper ëª¨ë¸ ë‹¤ìš´ë¡œë“œ |
| `stt_engine.py` | Whisper STT í•µì‹¬ ëª¨ë“ˆ |
| `vllm_client.py` | vLLM ì„œë²„ í†µì‹  í´ë¼ì´ì–¸íŠ¸ |
| `api_server.py` | FastAPI REST API ì„œë²„ |
| `api_client.py` | CLI í…ŒìŠ¤íŠ¸ í´ë¼ì´ì–¸íŠ¸ |
| `Dockerfile` | ê¸°ë³¸ Docker ì´ë¯¸ì§€ (CPU) |
| `Dockerfile.gpu` | GPU ìµœì í™” Docker ì´ë¯¸ì§€ |
| `docker-compose.yml` | Docker Compose ì„¤ì • |
| `setup.sh` | ë¡œì»¬ í™˜ê²½ ìë™ ì„¤ì • |
| `DEPLOYMENT.md` | Linux ì„œë²„ ë°°í¬ ì™„ë²½ ê°€ì´ë“œ |

---

## ğŸ¤ ê¸°ì—¬ ë° ì§€ì›

- **ì´ìŠˆ ë³´ê³ **: GitHub Issuesì—ì„œ ë¬¸ì œ ë³´ê³ 
- **ê¸°ì—¬**: Pull Request í™˜ì˜
- **ë¬¸ì˜**: í† ë¡  ê²Œì‹œíŒ í™œìš©

---

## ğŸ“ ë¼ì´ì„ ìŠ¤

MIT License - ììœ ë¡­ê²Œ ì‚¬ìš©, ìˆ˜ì •, ë°°í¬ ê°€ëŠ¥

---

## ğŸ“ í•™ìŠµ ìë£Œ

- [Whisper ê³µì‹ ë¬¸ì„œ](https://github.com/openai/whisper)
- [vLLM ê³µì‹ ë¬¸ì„œ](https://docs.vllm.ai/)
- [FastAPI íŠœí† ë¦¬ì–¼](https://fastapi.tiangolo.com/)
- [Docker ê³µì‹ ë¬¸ì„œ](https://docs.docker.com/)

---

**ğŸ‰ í”„ë¡œì íŠ¸ ì„¤ì •ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!**

ë‹¤ìŒ ë‹¨ê³„:
1. âœ… í”„ë¡œì íŠ¸ êµ¬ì¡° ìƒì„± ì™„ë£Œ
2. âœ… ëª¨ë¸ ë‹¤ìš´ë¡œë“œ ìŠ¤í¬ë¦½íŠ¸ ì¤€ë¹„ ì™„ë£Œ
3. âœ… Docker í™˜ê²½ ì„¤ì • ì™„ë£Œ
4. âœ… vLLM í†µí•© ì™„ë£Œ
5. ğŸ“Œ **ë‹¤ìŒ**: ìŒì„± íŒŒì¼ ì¤€ë¹„ ë° ì²« í…ŒìŠ¤íŠ¸ ìˆ˜í–‰

**ì‹œì‘í•˜ê¸°**:
```bash
# ë¡œì»¬ í…ŒìŠ¤íŠ¸
source venv/bin/activate
python download_model.py
python api_server.py

# ë˜ëŠ” Docker
docker-compose up -d
```
