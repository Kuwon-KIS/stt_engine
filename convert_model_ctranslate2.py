#!/usr/bin/env python3
"""
Whisper Large-V3-Turbo ëª¨ë¸ì„ ctranslate2 í¬ë§·ìœ¼ë¡œ ë³€í™˜
"""
import sys
from pathlib import Path

print("ğŸ”„ Whisper ëª¨ë¸ì„ ctranslate2 í¬ë§·ìœ¼ë¡œ ë³€í™˜")
print("=" * 60)

models_dir = Path("/Users/a113211/workspace/stt_engine/models")
output_dir = models_dir / "openai_whisper-large-v3-turbo"

print(f"ğŸ“ ì…ë ¥ ê²½ë¡œ: {models_dir}")
print(f"ğŸ“ ì¶œë ¥ ê²½ë¡œ: {output_dir}")
print()

try:
    from faster_whisper.vad import get_speech_timestamps
    import torch
    from transformers import WhisperProcessor, WhisperForConditionalGeneration
    import ctranslate2
    
    print("1ï¸âƒ£ HuggingFace ëª¨ë¸ ë¡œë“œ ì¤‘...")
    
    # HuggingFaceì—ì„œ ëª¨ë¸ ë¡œë“œ
    model_name = "openai/whisper-large-v3-turbo"
    processor = WhisperProcessor.from_pretrained(model_name, cache_dir=str(models_dir), local_files_only=True)
    hf_model = WhisperForConditionalGeneration.from_pretrained(model_name, cache_dir=str(models_dir), local_files_only=True)
    
    print("âœ… HuggingFace ëª¨ë¸ ë¡œë“œ ì™„ë£Œ")
    
    print("\n2ï¸âƒ£ ctranslate2 í¬ë§·ìœ¼ë¡œ ë³€í™˜ ì¤‘...")
    
    # ctranslate2ë¡œ ë³€í™˜
    converter = ctranslate2.converters.TransformersConverter(
        model_name,
        copy_files=["*.json", "*.txt", "*.md"],
        quantization="int8",
    )
    converter.convert(str(output_dir))
    
    print("âœ… ctranslate2 í¬ë§· ë³€í™˜ ì™„ë£Œ")
    
    print(f"\nğŸ“ ë³€í™˜ëœ ëª¨ë¸ íŒŒì¼:")
    for f in sorted(output_dir.glob("**/*")):
        if f.is_file():
            size = f.stat().st_size
            print(f"   - {f.relative_to(output_dir)}: {size / (1024**2):.1f} MB")
    
    print("\nâœ… ëª¨ë¸ ë³€í™˜ ì™„ë£Œ!")
    
except ImportError as e:
    print(f"âŒ í•„ìš”í•œ íŒ¨í‚¤ì§€ ë¯¸ì„¤ì¹˜: {e}")
    print("\nctranslate2ë¥¼ ì„¤ì¹˜í•´ì•¼ í•©ë‹ˆë‹¤:")
    print("  pip install ctranslate2")
    sys.exit(1)
except Exception as e:
    print(f"âŒ ë³€í™˜ ì‹¤íŒ¨: {e}")
    import traceback
    traceback.print_exc()
    sys.exit(1)
